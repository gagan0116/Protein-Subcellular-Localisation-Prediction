{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"114P4piBP44Gs8FGI6Q5bePr59k8TzzCO","timestamp":1697914883769},{"file_id":"15d06WjXUqjWR4ytMZ4whv8WWbxFHdQnk","timestamp":1697814368612}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxzzOUnzW47y","executionInfo":{"status":"ok","timestamp":1697814664677,"user_tz":-330,"elapsed":22594,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"ba48c0f6-adb6-4e6b-931f-1636218204dd"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["def parse_pssm(fname):\n","    f = open(fname)\n","    # the 4th line should be the start of the PSSM data\n","    f.readline()\n","    f.readline()\n","    f.readline()\n","    seq = []\n","    lprob = np.zeros([0,20])\n","    prob = np.zeros([0,20])\n","    extra = np.zeros([0,2])\n","    line = f.readline()\n","    while len(line.strip())>0:\n","        lineinfo = line.split()\n","        seq.append(lineinfo[1])\n","        lprobs_ = [float(lineinfo[i]) for i in range(2,22)]\n","        lprob = np.concatenate((lprob,np.matrix(lprobs_)),axis=0)\n","        probs_ = [float(lineinfo[i])/100 for i in range(22,42)]\n","        prob = np.concatenate((prob,np.matrix(probs_)),axis=0)\n","        extras_ = [float(lineinfo[i]) for i in range(42,44)]\n","        extra = np.concatenate((extra,np.matrix(extras_)),axis=0)\n","        line = f.readline()\n","\n","    return (''.join(seq),prob,lprob,extra)"],"metadata":{"id":"qQWtKt5jW8ir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## PSSM Profile Extraction"],"metadata":{"id":"ffh5iCwzXeX9"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/HDA/Benchmark_BinaryML.csv')"],"metadata":{"id":"Z0v3XYjZXKox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","pssm_matrices = []\n","\n","for i in df['PDBid']:\n","    pssm_mat = parse_pssm(f'/content/drive/MyDrive/HDA/Benchmark_PSSM/{i}.txt')\n","    pssm_arr = np.array(pssm_mat[1])\n","    pssm_matrices.append(pssm_arr)\n","\n","# Add the list of pssm_arr as a new column 'pssm_matrix' in the DataFrame\n","df['pssm_matrix'] = pssm_matrices"],"metadata":{"id":"kySlTdIxXRlJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Skipxgram Extraction"],"metadata":{"id":"iBokrvfLXocx"}},{"cell_type":"code","source":["import numpy as np\n","\n","def calculate_sxgbg_features(evolutionary_profile, X):\n","\n","    L, _ = evolutionary_profile.shape\n","    sxgbg_matrix = np.zeros((20, 20))\n","\n","    for i in range(20):\n","        for j in range(20):\n","            sxgbg_value = 0.0\n","\n","            for l in range(1,L - X):\n","                sxgbg_value += evolutionary_profile[l-1, i] * evolutionary_profile[l + X , j]\n","\n","            sxgbg_matrix[i, j] = sxgbg_value\n","\n","    return sxgbg_matrix"],"metadata":{"id":"HCyYGKMpXcco"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S0G Matrix"],"metadata":{"id":"ULzAfTllYFrS"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s0g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s0g_mat = calculate_sxgbg_features(i, 0)\n","    s0g_arr = np.array(s0g_mat)\n","    s0g_matrix.append(s0g_arr)\n","\n","df['s0g_matrix'] = s0g_matrix"],"metadata":{"id":"P3bqM6ZUXzq5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S1G Matrix"],"metadata":{"id":"gN9WPqh1YIj3"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s1g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s1g_mat = calculate_sxgbg_features(i, 1)\n","    s1g_arr = np.array(s1g_mat)\n","    s1g_matrix.append(s1g_arr)\n","\n","df['s1g_matrix'] = s1g_matrix"],"metadata":{"id":"lL9lPFGDX-60"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S2G Matrix"],"metadata":{"id":"JEbU3n52YMCb"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s2g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s2g_mat = calculate_sxgbg_features(i, 2)\n","    s2g_arr = np.array(s2g_mat)\n","    s2g_matrix.append(s2g_arr)\n","\n","df['s2g_matrix'] = s2g_matrix"],"metadata":{"id":"NOocfQpIX_wL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S3G Matrix"],"metadata":{"id":"XloXGYwhYOsy"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s3g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s3g_mat = calculate_sxgbg_features(i, 3)\n","    s3g_arr = np.array(s3g_mat)\n","    s3g_matrix.append(s3g_arr)\n","\n","df['s3g_matrix'] = s3g_matrix"],"metadata":{"id":"WpU6cz4OYAVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S4G Matrix"],"metadata":{"id":"3mAX_CfuYQ4d"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s4g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s4g_mat = calculate_sxgbg_features(i, 4)\n","    s4g_arr = np.array(s4g_mat)\n","    s4g_matrix.append(s4g_arr)\n","\n","df['s4g_matrix'] = s4g_matrix"],"metadata":{"id":"BEHJobTTYC55"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S5G Matrix"],"metadata":{"id":"ze0GajZ0YS4D"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s5g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s5g_mat = calculate_sxgbg_features(i, 5)\n","    s5g_arr = np.array(s5g_mat)\n","    s5g_matrix.append(s5g_arr)\n","\n","df['s5g_matrix'] = s5g_matrix"],"metadata":{"id":"pXPVfSNGYDfs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S6G Matrix"],"metadata":{"id":"WUt5nwgnYVUn"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s6g_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s6g_mat = calculate_sxgbg_features(i, 6)\n","    s6g_arr = np.array(s6g_mat)\n","    s6g_matrix.append(s6g_arr)\n","\n","df['s6g_matrix'] = s6g_matrix"],"metadata":{"id":"zDH1dWExYD99"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation Metrics"],"metadata":{"id":"kcXHEqgpZD99"}},{"cell_type":"code","source":["def calculate_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    # Initialize accuracy\n","    accuracy = 0\n","\n","    # Calculate accuracy for each instance\n","    for i in range(len(y_true)):\n","        # Calculate intersection and union\n","        intersection = np.sum(np.logical_and(y_true[i], y_pred[i]))\n","        union = np.sum(np.logical_or(y_true[i], y_pred[i]))\n","\n","        # Add to total accuracy\n","        accuracy += intersection / union\n","\n","    # Calculate average accuracy\n","    accuracy /= len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"oqIY31Q4aOJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def norm_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    acc = []\n","    # Loop over each instance\n","    for i in range(len(y_true)):\n","        # Calculate the number of correct predictions for this instance\n","        print(y_true[i], y_pred[i])\n","        correct_predictions = np.sum(y_true[i] == y_pred[i])\n","        print(correct_predictions/5)\n","        acc.append(correct_predictions/5)\n","\n","    # Calculate accuracy\n","    accuracy = sum(acc) / len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"yUxFza9MaRJY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Matrix Model"],"metadata":{"id":"ZasAhPpLaWUZ"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s0g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkEV6pfCZGdp","executionInfo":{"status":"ok","timestamp":1697815655412,"user_tz":-330,"elapsed":81532,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"616a4373-2d2b-4337-f62e-f7c0f1ae4c1a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.5073 - accuracy: 0.4567 - val_loss: 0.6545 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4401 - accuracy: 0.5476 - val_loss: 0.3579 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.5693 - val_loss: 0.4243 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3205 - accuracy: 0.6147 - val_loss: 0.3566 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.7013 - val_loss: 0.3210 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2831 - accuracy: 0.6883 - val_loss: 0.3047 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.7056 - val_loss: 0.3057 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2602 - accuracy: 0.7316 - val_loss: 0.3237 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.6602 - val_loss: 0.3431 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2537 - accuracy: 0.7468 - val_loss: 0.3132 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2226 - accuracy: 0.7597 - val_loss: 0.3887 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2162 - accuracy: 0.7814 - val_loss: 0.3186 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1887 - accuracy: 0.7987 - val_loss: 0.2872 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2227 - accuracy: 0.7727 - val_loss: 0.3120 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1972 - accuracy: 0.8160 - val_loss: 0.3035 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1826 - accuracy: 0.8355 - val_loss: 0.3665 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.8333 - val_loss: 0.3297 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.8723 - val_loss: 0.3411 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1425 - accuracy: 0.8506 - val_loss: 0.3455 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1696 - accuracy: 0.8247\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1696 - accuracy: 0.8247 - val_loss: 0.3687 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1327 - accuracy: 0.8680 - val_loss: 0.3829 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1115 - accuracy: 0.9004 - val_loss: 0.3531 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1190 - accuracy: 0.8831 - val_loss: 0.3524 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0936 - accuracy: 0.9091 - val_loss: 0.4814 - val_accuracy: 0.6466 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0926 - accuracy: 0.9113 - val_loss: 0.3650 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0879 - accuracy: 0.9199 - val_loss: 0.4060 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0935 - accuracy: 0.9091 - val_loss: 0.3803 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1083 - accuracy: 0.8983 - val_loss: 0.3948 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0912 - accuracy: 0.9113 - val_loss: 0.3954 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0867 - accuracy: 0.9156 - val_loss: 0.4222 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [1 0 0 0 0]\n","0.4\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2369 - accuracy: 0.8139 - val_loss: 0.1696 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1984 - accuracy: 0.8160 - val_loss: 0.1110 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1647 - accuracy: 0.8463 - val_loss: 0.1498 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1254 - accuracy: 0.8788 - val_loss: 0.0745 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.8896 - val_loss: 0.1428 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1629 - accuracy: 0.8312 - val_loss: 0.2912 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1622 - accuracy: 0.8442 - val_loss: 0.0913 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1040 - accuracy: 0.8788 - val_loss: 0.1155 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1156 - accuracy: 0.8874 - val_loss: 0.1788 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1073 - accuracy: 0.8983 - val_loss: 0.1069 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 11/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1582 - accuracy: 0.8588\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1572 - accuracy: 0.8593 - val_loss: 0.1282 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9113 - val_loss: 0.0896 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0708 - accuracy: 0.9329 - val_loss: 0.0911 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 14/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0624 - accuracy: 0.9329Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0609 - accuracy: 0.9351 - val_loss: 0.1070 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.1576 - accuracy: 0.8398 - val_loss: 0.1000 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.8680 - val_loss: 0.1152 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1200 - accuracy: 0.8831 - val_loss: 0.1615 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1068 - accuracy: 0.8918 - val_loss: 0.1675 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1352 - accuracy: 0.8528 - val_loss: 0.1472 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9004 - val_loss: 0.0937 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.8874 - val_loss: 0.2029 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1095 - accuracy: 0.8896 - val_loss: 0.1286 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 9/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.1027 - accuracy: 0.8798\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.8788 - val_loss: 0.1507 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9329 - val_loss: 0.1262 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0482 - accuracy: 0.9632 - val_loss: 0.1194 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 12/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0415 - accuracy: 0.9663Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9697 - val_loss: 0.1308 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 1 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1422 - accuracy: 0.8575 - val_loss: 0.1049 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1248 - accuracy: 0.8661 - val_loss: 0.1237 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.8769 - val_loss: 0.0785 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1294 - accuracy: 0.8683 - val_loss: 0.0987 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1431 - accuracy: 0.8618 - val_loss: 0.0996 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0985 - accuracy: 0.8942 - val_loss: 0.1028 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1056 - accuracy: 0.9028 - val_loss: 0.1725 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0839 - accuracy: 0.9114 - val_loss: 0.0616 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0744 - accuracy: 0.9330 - val_loss: 0.1115 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0651 - accuracy: 0.9417 - val_loss: 0.1727 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0843 - accuracy: 0.9158 - val_loss: 0.0913 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","102/116 [=========================>....] - ETA: 0s - loss: 0.0724 - accuracy: 0.9338\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0838 - accuracy: 0.9330 - val_loss: 0.0677 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0633 - accuracy: 0.9482 - val_loss: 0.1509 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0369 - accuracy: 0.9676 - val_loss: 0.1039 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9719Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0337 - accuracy: 0.9719 - val_loss: 0.1378 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1268 - accuracy: 0.8683 - val_loss: 0.1680 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1230 - accuracy: 0.8877 - val_loss: 0.2362 - val_accuracy: 0.7652 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0911 - accuracy: 0.9179 - val_loss: 0.2360 - val_accuracy: 0.7652 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.8920 - val_loss: 0.1216 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9266 - val_loss: 0.1062 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0762 - accuracy: 0.9244 - val_loss: 0.1893 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0672 - accuracy: 0.9395 - val_loss: 0.2583 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9071 - val_loss: 0.3352 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0945 - accuracy: 0.9158 - val_loss: 0.0940 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0936 - accuracy: 0.9222 - val_loss: 0.2671 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0613 - accuracy: 0.9352 - val_loss: 0.1417 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 12/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0478 - accuracy: 0.9545\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9568 - val_loss: 0.2832 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9525 - val_loss: 0.1300 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0375 - accuracy: 0.9568 - val_loss: 0.1385 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0284 - accuracy: 0.9719 - val_loss: 0.1513 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0302 - accuracy: 0.9698 - val_loss: 0.1750 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9546 - val_loss: 0.1213 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0311 - accuracy: 0.9719 - val_loss: 0.1777 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0349 - accuracy: 0.9546 - val_loss: 0.1682 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0264 - accuracy: 0.9762 - val_loss: 0.1817 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 21/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0217 - accuracy: 0.9761\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0216 - accuracy: 0.9762 - val_loss: 0.2511 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0247 - accuracy: 0.9698 - val_loss: 0.1226 - val_accuracy: 0.9043 - lr: 2.5000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0145 - accuracy: 0.9698 - val_loss: 0.1690 - val_accuracy: 0.9043 - lr: 2.5000e-04\n","Epoch 24/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0109 - accuracy: 0.9825Restoring model weights from the end of the best epoch: 14.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0107 - accuracy: 0.9827 - val_loss: 0.1644 - val_accuracy: 0.9130 - lr: 2.5000e-04\n","Epoch 24: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","Average Accuracy:  0.8237181409295353\n","Accuracy:  0.9485007496251872\n","Average Normalized Accuracy:  0.8470739630184907\n","Average Precision:  0.9087414818283677\n","Average Recall:  0.8481063049188877\n","F1 score: 0.8773775236463871\n","Grand Mean: 0.8755863606611425\n"]}]},{"cell_type":"markdown","source":["## S1G Matrix Model"],"metadata":{"id":"Lsm3iP4pbLbz"}},{"cell_type":"code","source":["# Define the model\n","model_s1g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCqYbphJbNe9","executionInfo":{"status":"ok","timestamp":1697815737453,"user_tz":-330,"elapsed":82057,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"55c98c5c-7a22-484e-e48b-41fb48d8f8c4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.4940 - accuracy: 0.4589 - val_loss: 0.4249 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4201 - accuracy: 0.5584 - val_loss: 0.3805 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3753 - accuracy: 0.5996 - val_loss: 0.3243 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3378 - accuracy: 0.6234 - val_loss: 0.3902 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3276 - accuracy: 0.6320 - val_loss: 0.2883 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2996 - accuracy: 0.6537 - val_loss: 0.2933 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2813 - accuracy: 0.6883 - val_loss: 0.2764 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2793 - accuracy: 0.6883 - val_loss: 0.2779 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2627 - accuracy: 0.7056 - val_loss: 0.2903 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2536 - accuracy: 0.7121 - val_loss: 0.2783 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.6883 - val_loss: 0.2812 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2254 - accuracy: 0.7511 - val_loss: 0.3504 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2478 - accuracy: 0.7056 - val_loss: 0.3546 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2295 - accuracy: 0.7338 - val_loss: 0.3235 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2132 - accuracy: 0.7662 - val_loss: 0.3112 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.7727 - val_loss: 0.2723 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1987 - accuracy: 0.7641 - val_loss: 0.2552 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 18/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.1864 - accuracy: 0.7957\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2011 - accuracy: 0.7771 - val_loss: 0.4642 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.8203 - val_loss: 0.3112 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.8528 - val_loss: 0.2825 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 21/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1404 - accuracy: 0.8634Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1402 - accuracy: 0.8658 - val_loss: 0.3908 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2694 - accuracy: 0.7100 - val_loss: 0.2188 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2501 - accuracy: 0.7316 - val_loss: 0.2462 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2444 - accuracy: 0.7143 - val_loss: 0.2766 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2398 - accuracy: 0.7208 - val_loss: 0.2825 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2293 - accuracy: 0.7165 - val_loss: 0.2412 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2321 - accuracy: 0.7251 - val_loss: 0.2153 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1918 - accuracy: 0.7619 - val_loss: 0.2127 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2029 - accuracy: 0.7727 - val_loss: 0.2324 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.7900 - val_loss: 0.2931 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.7316 - val_loss: 0.2920 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1663 - accuracy: 0.8268 - val_loss: 0.2310 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1632 - accuracy: 0.8528 - val_loss: 0.3471 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1618 - accuracy: 0.8355 - val_loss: 0.3270 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1555 - accuracy: 0.8398 - val_loss: 0.3344 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1709 - accuracy: 0.8312 - val_loss: 0.2372 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1542 - accuracy: 0.8506 - val_loss: 0.3052 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1458 - accuracy: 0.8442 - val_loss: 0.2448 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 18/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1128 - accuracy: 0.8739\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1125 - accuracy: 0.8766 - val_loss: 0.3442 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0932 - accuracy: 0.9134 - val_loss: 0.2055 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0822 - accuracy: 0.9156 - val_loss: 0.2388 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0772 - accuracy: 0.9307 - val_loss: 0.2467 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9351 - val_loss: 0.2464 - val_accuracy: 0.7759 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0801 - accuracy: 0.9264 - val_loss: 0.2385 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0841 - accuracy: 0.9177 - val_loss: 0.2407 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0621 - accuracy: 0.9372 - val_loss: 0.2669 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 26/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0557 - accuracy: 0.9393\n","Epoch 26: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9394 - val_loss: 0.2896 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0440 - accuracy: 0.9545 - val_loss: 0.2374 - val_accuracy: 0.8190 - lr: 2.5000e-04\n","Epoch 28/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9545 - val_loss: 0.2554 - val_accuracy: 0.8103 - lr: 2.5000e-04\n","Epoch 29/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0379 - accuracy: 0.9653Restoring model weights from the end of the best epoch: 19.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9632 - val_loss: 0.2642 - val_accuracy: 0.8362 - lr: 2.5000e-04\n","Epoch 29: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1584 - accuracy: 0.8485 - val_loss: 0.1769 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1215 - accuracy: 0.8701 - val_loss: 0.1827 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1439 - accuracy: 0.8485 - val_loss: 0.2401 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.8810 - val_loss: 0.1421 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1117 - accuracy: 0.8766 - val_loss: 0.1920 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1016 - accuracy: 0.8831 - val_loss: 0.1326 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0966 - accuracy: 0.8983 - val_loss: 0.1561 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0899 - accuracy: 0.9069 - val_loss: 0.1779 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.8571 - val_loss: 0.2088 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1374 - accuracy: 0.8896 - val_loss: 0.1277 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 11/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0943 - accuracy: 0.9136\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0919 - accuracy: 0.9177 - val_loss: 0.1822 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0562 - accuracy: 0.9481 - val_loss: 0.1739 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0493 - accuracy: 0.9610 - val_loss: 0.1343 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0446 - accuracy: 0.9567 - val_loss: 0.1806 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0425 - accuracy: 0.9610 - val_loss: 0.1620 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0416 - accuracy: 0.9610 - val_loss: 0.2269 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0575 - accuracy: 0.9416 - val_loss: 0.1663 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0419 - accuracy: 0.9654 - val_loss: 0.1765 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9589 - val_loss: 0.1418 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 20/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0413 - accuracy: 0.9667\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0427 - accuracy: 0.9654 - val_loss: 0.1586 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0269 - accuracy: 0.9740 - val_loss: 0.1438 - val_accuracy: 0.8879 - lr: 2.5000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0250 - accuracy: 0.9740 - val_loss: 0.1480 - val_accuracy: 0.8966 - lr: 2.5000e-04\n","Epoch 23/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0238 - accuracy: 0.9676Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9697 - val_loss: 0.1547 - val_accuracy: 0.8879 - lr: 2.5000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1350 - accuracy: 0.8942 - val_loss: 0.1320 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1140 - accuracy: 0.9028 - val_loss: 0.0461 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1093 - accuracy: 0.9050 - val_loss: 0.0852 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1221 - accuracy: 0.8920 - val_loss: 0.0475 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9266 - val_loss: 0.0493 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9201 - val_loss: 0.0632 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0852 - accuracy: 0.9071 - val_loss: 0.0770 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9352 - val_loss: 0.0944 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0668 - accuracy: 0.9460 - val_loss: 0.0653 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9374 - val_loss: 0.0654 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0732 - accuracy: 0.9287 - val_loss: 0.1005 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0624 - accuracy: 0.9500\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0649 - accuracy: 0.9460 - val_loss: 0.2794 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0500 - accuracy: 0.9568 - val_loss: 0.0802 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0555 - accuracy: 0.9482 - val_loss: 0.1124 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 15/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0426 - accuracy: 0.9636Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0400 - accuracy: 0.9611 - val_loss: 0.0756 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0963 - accuracy: 0.9201 - val_loss: 0.1122 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0798 - accuracy: 0.9287 - val_loss: 0.1559 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1081 - accuracy: 0.9309 - val_loss: 0.1662 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0663 - accuracy: 0.9438 - val_loss: 0.1027 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1018 - accuracy: 0.9201 - val_loss: 0.1431 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0690 - accuracy: 0.9395 - val_loss: 0.1027 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0593 - accuracy: 0.9546 - val_loss: 0.1578 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9460 - val_loss: 0.1606 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0802 - accuracy: 0.9352 - val_loss: 0.1649 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1363 - accuracy: 0.8963 - val_loss: 0.1926 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 11/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.1088 - accuracy: 0.9190\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1013 - accuracy: 0.9222 - val_loss: 0.1558 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0404 - accuracy: 0.9654 - val_loss: 0.1367 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0316 - accuracy: 0.9741 - val_loss: 0.1434 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 14/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0270 - accuracy: 0.9705Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9698 - val_loss: 0.1554 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8031184407796103\n","Accuracy:  0.946116941529235\n","Average Normalized Accuracy:  0.8201224387806099\n","Average Precision:  0.9079960137782148\n","Average Recall:  0.8115808546735414\n","F1 score: 0.8570854777382307\n","Grand Mean: 0.857670027879907\n"]}]},{"cell_type":"markdown","source":["## S2G Matrix Model"],"metadata":{"id":"en9uKQn3b0zH"}},{"cell_type":"code","source":["# Define the model\n","model_s2g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGdchURLbpOK","executionInfo":{"status":"ok","timestamp":1697815810837,"user_tz":-330,"elapsed":73397,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"7a9c1af4-11c2-4d3e-ff51-af512584675f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.6369 - accuracy: 0.3160 - val_loss: 0.5012 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.5000 - val_loss: 0.4588 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3894 - accuracy: 0.5476 - val_loss: 0.3642 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3695 - accuracy: 0.5909 - val_loss: 0.3635 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3561 - accuracy: 0.6190 - val_loss: 0.3527 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.6602 - val_loss: 0.3432 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3100 - accuracy: 0.6580 - val_loss: 0.3510 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2872 - accuracy: 0.6905 - val_loss: 0.3153 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.7100 - val_loss: 0.3224 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2687 - accuracy: 0.7056 - val_loss: 0.3358 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2724 - accuracy: 0.7165 - val_loss: 0.3543 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2595 - accuracy: 0.7338 - val_loss: 0.3140 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2466 - accuracy: 0.7251 - val_loss: 0.3710 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2616 - accuracy: 0.7186 - val_loss: 0.3405 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2650 - accuracy: 0.7251 - val_loss: 0.2894 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2355 - accuracy: 0.7532 - val_loss: 0.3136 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2248 - accuracy: 0.7706 - val_loss: 0.3034 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2037 - accuracy: 0.7987 - val_loss: 0.2851 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1911 - accuracy: 0.8160 - val_loss: 0.2723 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2026 - accuracy: 0.7987 - val_loss: 0.3610 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.8463 - val_loss: 0.4046 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1678 - accuracy: 0.8355 - val_loss: 0.3475 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1550 - accuracy: 0.8420 - val_loss: 0.4158 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1317 - accuracy: 0.8853 - val_loss: 0.3137 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1372 - accuracy: 0.8831 - val_loss: 0.3979 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 26/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1237 - accuracy: 0.8853 - val_loss: 0.4271 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.8701 - val_loss: 0.3117 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 28/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1140 - accuracy: 0.8983 - val_loss: 0.3815 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 29/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.9091 - val_loss: 0.6277 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1701 - accuracy: 0.8506 - val_loss: 0.3399 - val_accuracy: 0.6983 - lr: 0.0010\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 1 1 0]\n","0.4\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 1 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 1 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 1 1 0]\n","0.4\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 1 1 0]\n","0.4\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1964 - accuracy: 0.8355 - val_loss: 0.1396 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1548 - accuracy: 0.8658 - val_loss: 0.0934 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1522 - accuracy: 0.8636 - val_loss: 0.1038 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1223 - accuracy: 0.8788 - val_loss: 0.1095 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1291 - accuracy: 0.8939 - val_loss: 0.1181 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1182 - accuracy: 0.8788 - val_loss: 0.1511 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1220 - accuracy: 0.8918 - val_loss: 0.1237 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1097 - accuracy: 0.8939 - val_loss: 0.1637 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 9/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1311 - accuracy: 0.8783\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1305 - accuracy: 0.8788 - val_loss: 0.1032 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0750 - accuracy: 0.9351 - val_loss: 0.0987 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0772 - accuracy: 0.9264 - val_loss: 0.1014 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 12/30\n","101/116 [=========================>....] - ETA: 0s - loss: 0.0629 - accuracy: 0.9356Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0624 - accuracy: 0.9372 - val_loss: 0.0844 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.1676 - accuracy: 0.8247 - val_loss: 0.0962 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.8506 - val_loss: 0.3466 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.8312 - val_loss: 0.1854 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.8420 - val_loss: 0.1572 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1206 - accuracy: 0.8831 - val_loss: 0.1463 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1075 - accuracy: 0.8874 - val_loss: 0.1377 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1004 - accuracy: 0.9004 - val_loss: 0.0864 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.8831 - val_loss: 0.1903 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1253 - accuracy: 0.8831 - val_loss: 0.1843 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1012 - accuracy: 0.9134 - val_loss: 0.1211 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0981 - accuracy: 0.9156 - val_loss: 0.1325 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1134 - accuracy: 0.9113 - val_loss: 0.3205 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0872 - accuracy: 0.9134 - val_loss: 0.1380 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9264\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0806 - accuracy: 0.9264 - val_loss: 0.1161 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0628 - accuracy: 0.9524 - val_loss: 0.1392 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0464 - accuracy: 0.9545 - val_loss: 0.2440 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 17/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0531 - accuracy: 0.9514Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0514 - accuracy: 0.9524 - val_loss: 0.1585 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1249 - accuracy: 0.8855 - val_loss: 0.1463 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1606 - accuracy: 0.8488 - val_loss: 0.0694 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1290 - accuracy: 0.8920 - val_loss: 0.0769 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1102 - accuracy: 0.8898 - val_loss: 0.0859 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.8942 - val_loss: 0.0585 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1025 - accuracy: 0.9050 - val_loss: 0.2084 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1312 - accuracy: 0.8747 - val_loss: 0.0521 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0904 - accuracy: 0.9244 - val_loss: 0.1014 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9266 - val_loss: 0.1186 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9438 - val_loss: 0.1282 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0773 - accuracy: 0.9330 - val_loss: 0.0692 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9201 - val_loss: 0.1487 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1183 - accuracy: 0.8747 - val_loss: 0.0805 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0717 - accuracy: 0.9330 - val_loss: 0.0649 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0882 - accuracy: 0.9136 - val_loss: 0.2368 - val_accuracy: 0.7304 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0842 - accuracy: 0.9244 - val_loss: 0.1532 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0648 - accuracy: 0.9374 - val_loss: 0.0761 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 18/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0501 - accuracy: 0.9527\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0500 - accuracy: 0.9546 - val_loss: 0.1308 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0438 - accuracy: 0.9590 - val_loss: 0.0654 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0255 - accuracy: 0.9741 - val_loss: 0.0871 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 21/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0263 - accuracy: 0.9685Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0266 - accuracy: 0.9676 - val_loss: 0.1099 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0837 - accuracy: 0.9244 - val_loss: 0.0929 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0929 - accuracy: 0.9071 - val_loss: 0.1201 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0647 - accuracy: 0.9417 - val_loss: 0.0815 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0774 - accuracy: 0.9266 - val_loss: 0.1179 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0590 - accuracy: 0.9460 - val_loss: 0.1742 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0685 - accuracy: 0.9352 - val_loss: 0.1086 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0772 - accuracy: 0.9417 - val_loss: 0.1695 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 8/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0775 - accuracy: 0.9476\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0759 - accuracy: 0.9460 - val_loss: 0.1677 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0355 - accuracy: 0.9633 - val_loss: 0.1325 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9676 - val_loss: 0.1268 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 11/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0249 - accuracy: 0.9717Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9719 - val_loss: 0.1520 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8358170914542729\n","Accuracy:  0.9509355322338827\n","Average Normalized Accuracy:  0.8632483758120941\n","Average Precision:  0.9154826933599122\n","Average Recall:  0.8598837010822024\n","F1 score: 0.8868126028603737\n","Grand Mean: 0.8853633328004564\n"]}]},{"cell_type":"markdown","source":["## S3G Matrix Model"],"metadata":{"id":"AjHed8xjb-1B"}},{"cell_type":"code","source":["# Define the model\n","model_s3g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s3g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s3g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s3g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s3g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdYxc5pxb4-4","executionInfo":{"status":"ok","timestamp":1697815870948,"user_tz":-330,"elapsed":60125,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"ed6356cc-3675-456d-84be-e2f54a46b7b9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5024 - accuracy: 0.4697 - val_loss: 0.4539 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4084 - accuracy: 0.5476 - val_loss: 0.3575 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3707 - accuracy: 0.5866 - val_loss: 0.3221 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3436 - accuracy: 0.6299 - val_loss: 0.3555 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3509 - accuracy: 0.6190 - val_loss: 0.3162 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2997 - accuracy: 0.6558 - val_loss: 0.2852 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2757 - accuracy: 0.7056 - val_loss: 0.3855 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2850 - accuracy: 0.7359 - val_loss: 0.3732 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2645 - accuracy: 0.7359 - val_loss: 0.3337 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 10/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.2447 - accuracy: 0.7457\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2437 - accuracy: 0.7468 - val_loss: 0.3412 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2110 - accuracy: 0.7879 - val_loss: 0.2884 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2102 - accuracy: 0.7814 - val_loss: 0.2832 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1796 - accuracy: 0.8355 - val_loss: 0.2801 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1699 - accuracy: 0.8398 - val_loss: 0.3320 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1804 - accuracy: 0.8290 - val_loss: 0.3627 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.8680 - val_loss: 0.2735 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.8766 - val_loss: 0.3059 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1243 - accuracy: 0.8788 - val_loss: 0.3182 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1225 - accuracy: 0.8961 - val_loss: 0.3294 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1293 - accuracy: 0.8810 - val_loss: 0.3557 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1183 - accuracy: 0.8918 - val_loss: 0.2963 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1107 - accuracy: 0.8896 - val_loss: 0.3442 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.8701 - val_loss: 0.2787 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1082 - accuracy: 0.8939 - val_loss: 0.3755 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1297 - accuracy: 0.8723 - val_loss: 0.3320 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0975 - accuracy: 0.8983 - val_loss: 0.3748 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9307 - val_loss: 0.3367 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0844 - accuracy: 0.9199 - val_loss: 0.3592 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 29/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0842 - accuracy: 0.9245\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0865 - accuracy: 0.9199 - val_loss: 0.3104 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0696 - accuracy: 0.9286 - val_loss: 0.3592 - val_accuracy: 0.7586 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [1 0 0 0 0]\n","0.4\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2143 - accuracy: 0.8182 - val_loss: 0.1019 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1869 - accuracy: 0.8290 - val_loss: 0.1196 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1632 - accuracy: 0.8377 - val_loss: 0.1439 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1554 - accuracy: 0.8766 - val_loss: 0.1534 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.8745 - val_loss: 0.0924 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1224 - accuracy: 0.8745 - val_loss: 0.1665 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1292 - accuracy: 0.8831 - val_loss: 0.0890 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1200 - accuracy: 0.8913\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1200 - accuracy: 0.8918 - val_loss: 0.1753 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0932 - accuracy: 0.9026 - val_loss: 0.1003 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9242 - val_loss: 0.1297 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0614 - accuracy: 0.9364Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0621 - accuracy: 0.9351 - val_loss: 0.1078 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2394 - accuracy: 0.7987 - val_loss: 0.1409 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1760 - accuracy: 0.8355 - val_loss: 0.2691 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1596 - accuracy: 0.8333 - val_loss: 0.3312 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.8485 - val_loss: 0.2304 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1245 - accuracy: 0.8766 - val_loss: 0.1730 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1658 - accuracy: 0.8550 - val_loss: 0.2469 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1487 - accuracy: 0.8615 - val_loss: 0.1547 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 8/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1378 - accuracy: 0.8604\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1402 - accuracy: 0.8615 - val_loss: 0.3365 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0947 - accuracy: 0.9199 - val_loss: 0.1770 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0732 - accuracy: 0.9177 - val_loss: 0.1115 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0555 - accuracy: 0.9500Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0624 - accuracy: 0.9437 - val_loss: 0.2007 - val_accuracy: 0.7845 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 1 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.1829 - accuracy: 0.8229 - val_loss: 0.0741 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.8575 - val_loss: 0.0977 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1619 - accuracy: 0.8402 - val_loss: 0.0843 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1347 - accuracy: 0.8618 - val_loss: 0.1527 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1399 - accuracy: 0.8618 - val_loss: 0.1625 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1643 - accuracy: 0.8531 - val_loss: 0.1551 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1245 - accuracy: 0.8726 - val_loss: 0.1190 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 8/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1250 - accuracy: 0.8879\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1271 - accuracy: 0.8855 - val_loss: 0.1635 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0889 - accuracy: 0.9158 - val_loss: 0.1103 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0686 - accuracy: 0.9374 - val_loss: 0.0996 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 11/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0610 - accuracy: 0.9434Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0595 - accuracy: 0.9438 - val_loss: 0.1755 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1779 - accuracy: 0.8272 - val_loss: 0.2254 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.8618 - val_loss: 0.1591 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.8380 - val_loss: 0.1975 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1275 - accuracy: 0.8769 - val_loss: 0.2359 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1252 - accuracy: 0.8812 - val_loss: 0.2062 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0917 - accuracy: 0.9222 - val_loss: 0.1759 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1477 - accuracy: 0.8596 - val_loss: 0.3568 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1429 - accuracy: 0.8639 - val_loss: 0.3907 - val_accuracy: 0.7043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1309 - accuracy: 0.8769 - val_loss: 0.2079 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1282 - accuracy: 0.8790 - val_loss: 0.1785 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9287 - val_loss: 0.1665 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1021 - accuracy: 0.9050 - val_loss: 0.5700 - val_accuracy: 0.6348 - lr: 0.0010\n","Epoch 13/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0982 - accuracy: 0.9151\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.9071 - val_loss: 0.2926 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9525 - val_loss: 0.2565 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0396 - accuracy: 0.9568 - val_loss: 0.2550 - val_accuracy: 0.8087 - lr: 5.0000e-04\n","Epoch 16/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0337 - accuracy: 0.9580Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0340 - accuracy: 0.9568 - val_loss: 0.3642 - val_accuracy: 0.7826 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","Average Accuracy:  0.8011694152923539\n","Accuracy:  0.9460539730134929\n","Average Normalized Accuracy:  0.8225212393803097\n","Average Precision:  0.9108241397279864\n","Average Recall:  0.8223068115859098\n","F1 score: 0.8643050240230216\n","Grand Mean: 0.8611967671705124\n"]}]},{"cell_type":"markdown","source":["## S4G Matrix Model"],"metadata":{"id":"Wz7E6Uetca8S"}},{"cell_type":"code","source":["# Define the model\n","model_s4g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s4g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s4g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s4g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s4g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1uLQEFPcQuL","executionInfo":{"status":"ok","timestamp":1697815945496,"user_tz":-330,"elapsed":74562,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"1769c8c0-71ce-4397-fc07-32c85c841ee4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5099 - accuracy: 0.4026 - val_loss: 0.4375 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4249 - accuracy: 0.5152 - val_loss: 0.3908 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3571 - accuracy: 0.6147 - val_loss: 0.3912 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3618 - accuracy: 0.6190 - val_loss: 0.4396 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3243 - accuracy: 0.6494 - val_loss: 0.3280 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3007 - accuracy: 0.6645 - val_loss: 0.3083 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2847 - accuracy: 0.6818 - val_loss: 0.3624 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2858 - accuracy: 0.6948 - val_loss: 0.3389 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2534 - accuracy: 0.7165 - val_loss: 0.3019 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2451 - accuracy: 0.7338 - val_loss: 0.3111 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2334 - accuracy: 0.7532 - val_loss: 0.3312 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2328 - accuracy: 0.7359 - val_loss: 0.3062 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2454 - accuracy: 0.7403 - val_loss: 0.3056 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2414 - accuracy: 0.7597 - val_loss: 0.3218 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2920 - accuracy: 0.6926 - val_loss: 0.3211 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 16/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.2175 - accuracy: 0.7738\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2104 - accuracy: 0.7792 - val_loss: 0.3457 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1780 - accuracy: 0.8290 - val_loss: 0.3009 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.8615 - val_loss: 0.3554 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.8615 - val_loss: 0.3185 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.8680 - val_loss: 0.3163 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.8766 - val_loss: 0.3221 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1259 - accuracy: 0.8766 - val_loss: 0.3682 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1321 - accuracy: 0.8701 - val_loss: 0.3498 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1279 - accuracy: 0.8918 - val_loss: 0.3366 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1474 - accuracy: 0.8506 - val_loss: 0.3570 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1304 - accuracy: 0.8788 - val_loss: 0.3504 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1172 - accuracy: 0.8896 - val_loss: 0.3342 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 28/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0978 - accuracy: 0.9198\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0985 - accuracy: 0.9199 - val_loss: 0.3516 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9307 - val_loss: 0.3611 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","Epoch 30/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0779 - accuracy: 0.9351 - val_loss: 0.3853 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2219 - accuracy: 0.7965 - val_loss: 0.1230 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2195 - accuracy: 0.8117 - val_loss: 0.1374 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2013 - accuracy: 0.7965 - val_loss: 0.1546 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1513 - accuracy: 0.8593 - val_loss: 0.1280 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1343 - accuracy: 0.8550 - val_loss: 0.0958 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.8506 - val_loss: 0.1670 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1563 - accuracy: 0.8463 - val_loss: 0.2056 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.8745 - val_loss: 0.2151 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1519 - accuracy: 0.8528 - val_loss: 0.1601 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1291 - accuracy: 0.8918 - val_loss: 0.2394 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1862 - accuracy: 0.8420 - val_loss: 0.1670 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 12/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1141 - accuracy: 0.8738\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1210 - accuracy: 0.8658 - val_loss: 0.1488 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0964 - accuracy: 0.9091 - val_loss: 0.1473 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0805 - accuracy: 0.9307 - val_loss: 0.1602 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 15/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0716 - accuracy: 0.9404Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0729 - accuracy: 0.9372 - val_loss: 0.1391 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1597 - accuracy: 0.8312 - val_loss: 0.1854 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1470 - accuracy: 0.8442 - val_loss: 0.1438 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1196 - accuracy: 0.8766 - val_loss: 0.0978 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1408 - accuracy: 0.8615 - val_loss: 0.1512 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1865 - accuracy: 0.8203 - val_loss: 0.2015 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1388 - accuracy: 0.8701 - val_loss: 0.1197 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1109 - accuracy: 0.9048 - val_loss: 0.1393 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.8723 - val_loss: 0.1558 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1414 - accuracy: 0.8723 - val_loss: 0.1794 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 10/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.1043 - accuracy: 0.9068\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1015 - accuracy: 0.9091 - val_loss: 0.1296 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0724 - accuracy: 0.9351 - val_loss: 0.1991 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9459 - val_loss: 0.1167 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 13/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0665 - accuracy: 0.9491Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0652 - accuracy: 0.9481 - val_loss: 0.1474 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 1 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.1556 - accuracy: 0.8359 - val_loss: 0.1363 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1437 - accuracy: 0.8790 - val_loss: 0.0911 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1339 - accuracy: 0.9006 - val_loss: 0.0967 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1283 - accuracy: 0.8790 - val_loss: 0.1132 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1342 - accuracy: 0.8726 - val_loss: 0.1236 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1185 - accuracy: 0.9028 - val_loss: 0.1239 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1001 - accuracy: 0.9114 - val_loss: 0.0922 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1566 - accuracy: 0.8618 - val_loss: 0.1139 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 9/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1046 - accuracy: 0.9054\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1045 - accuracy: 0.9050 - val_loss: 0.1325 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0697 - accuracy: 0.9482 - val_loss: 0.1024 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9546 - val_loss: 0.1032 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0775 - accuracy: 0.9287 - val_loss: 0.0786 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0554 - accuracy: 0.9590 - val_loss: 0.0987 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9503 - val_loss: 0.1416 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0453 - accuracy: 0.9611 - val_loss: 0.1074 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0492 - accuracy: 0.9568 - val_loss: 0.1171 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9460\n","Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0525 - accuracy: 0.9460 - val_loss: 0.1707 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9546 - val_loss: 0.0942 - val_accuracy: 0.9217 - lr: 2.5000e-04\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9741 - val_loss: 0.1185 - val_accuracy: 0.9130 - lr: 2.5000e-04\n","Epoch 20/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0210 - accuracy: 0.9806Restoring model weights from the end of the best epoch: 10.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9806 - val_loss: 0.1182 - val_accuracy: 0.9304 - lr: 2.5000e-04\n","Epoch 20: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 8ms/step - loss: 0.1135 - accuracy: 0.8985 - val_loss: 0.2073 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.8920 - val_loss: 0.1042 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.8920 - val_loss: 0.4837 - val_accuracy: 0.6435 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1113 - accuracy: 0.8790 - val_loss: 0.1714 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9266 - val_loss: 0.3154 - val_accuracy: 0.7043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0808 - accuracy: 0.9374 - val_loss: 0.1358 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9179 - val_loss: 0.2513 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0970 - accuracy: 0.9222 - val_loss: 0.1725 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 9/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0790 - accuracy: 0.9283\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9287 - val_loss: 0.1128 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0398 - accuracy: 0.9525 - val_loss: 0.1009 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9611 - val_loss: 0.1179 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0465 - accuracy: 0.9546 - val_loss: 0.1066 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9654 - val_loss: 0.1038 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0278 - accuracy: 0.9719 - val_loss: 0.1293 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9784 - val_loss: 0.1224 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9719 - val_loss: 0.1708 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0229 - accuracy: 0.9762 - val_loss: 0.1094 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0178 - accuracy: 0.9784 - val_loss: 0.1110 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0187 - accuracy: 0.9784 - val_loss: 0.1760 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9762 - val_loss: 0.1759 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9806 - val_loss: 0.1577 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0359 - accuracy: 0.9460 - val_loss: 0.1346 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0315 - accuracy: 0.9633 - val_loss: 0.1288 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0294 - accuracy: 0.9741 - val_loss: 0.2090 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 25/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0206 - accuracy: 0.9732\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0204 - accuracy: 0.9741 - val_loss: 0.1415 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0104 - accuracy: 0.9784 - val_loss: 0.1904 - val_accuracy: 0.9217 - lr: 2.5000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0080 - accuracy: 0.9827 - val_loss: 0.1801 - val_accuracy: 0.9130 - lr: 2.5000e-04\n","Epoch 28/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0066 - accuracy: 0.9841Restoring model weights from the end of the best epoch: 18.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9827 - val_loss: 0.1899 - val_accuracy: 0.9217 - lr: 2.5000e-04\n","Epoch 28: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","Average Accuracy:  0.8289355322338829\n","Accuracy:  0.9509265367316339\n","Average Normalized Accuracy:  0.8511269365317341\n","Average Precision:  0.9155405783172744\n","Average Recall:  0.8435244284285431\n","F1 score: 0.8780583322010341\n","Grand Mean: 0.8780187240740172\n"]}]},{"cell_type":"markdown","source":["## S5G Matrix Model"],"metadata":{"id":"1Zj7uaIMceME"}},{"cell_type":"code","source":["# Define the model\n","model_s5g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s5g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s5g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s5g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s5g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QB_KoJnwcV9H","executionInfo":{"status":"ok","timestamp":1697816030825,"user_tz":-330,"elapsed":85349,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"507c718e-3134-4280-82b0-6b75bfdb58b3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5330 - accuracy: 0.4048 - val_loss: 0.4249 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4512 - accuracy: 0.5108 - val_loss: 0.4253 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3807 - accuracy: 0.5714 - val_loss: 0.3762 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.6234 - val_loss: 0.3367 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3440 - accuracy: 0.6255 - val_loss: 0.3120 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.6732 - val_loss: 0.3203 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2880 - accuracy: 0.6991 - val_loss: 0.3071 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2791 - accuracy: 0.7056 - val_loss: 0.3450 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2638 - accuracy: 0.6905 - val_loss: 0.3057 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2471 - accuracy: 0.7316 - val_loss: 0.4172 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2487 - accuracy: 0.7208 - val_loss: 0.2993 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2271 - accuracy: 0.7424 - val_loss: 0.3318 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2262 - accuracy: 0.7749 - val_loss: 0.3858 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2069 - accuracy: 0.7532 - val_loss: 0.3130 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2370 - accuracy: 0.7338 - val_loss: 0.3219 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1908 - accuracy: 0.7944 - val_loss: 0.3652 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.8052 - val_loss: 0.3492 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2052 - accuracy: 0.7792 - val_loss: 0.3709 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1757 - accuracy: 0.8268 - val_loss: 0.3939 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1749 - accuracy: 0.8268 - val_loss: 0.3738 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 21/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.1943 - accuracy: 0.7898\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1978 - accuracy: 0.7879 - val_loss: 0.4048 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1375 - accuracy: 0.8550 - val_loss: 0.3643 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1394 - accuracy: 0.8442 - val_loss: 0.3760 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.8701 - val_loss: 0.4118 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1135 - accuracy: 0.8831 - val_loss: 0.4109 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1057 - accuracy: 0.8896 - val_loss: 0.4200 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1039 - accuracy: 0.8831 - val_loss: 0.4083 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0971 - accuracy: 0.8961 - val_loss: 0.4901 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 29/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0958 - accuracy: 0.9123\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0950 - accuracy: 0.9134 - val_loss: 0.4616 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0924 - accuracy: 0.9113 - val_loss: 0.4604 - val_accuracy: 0.7155 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2093 - accuracy: 0.8160 - val_loss: 0.1123 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1848 - accuracy: 0.8203 - val_loss: 0.1906 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1685 - accuracy: 0.8355 - val_loss: 0.1250 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1536 - accuracy: 0.8268 - val_loss: 0.1047 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1440 - accuracy: 0.8571 - val_loss: 0.1092 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1471 - accuracy: 0.8398 - val_loss: 0.1486 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1825 - accuracy: 0.8203 - val_loss: 0.4267 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1549 - accuracy: 0.8435\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1565 - accuracy: 0.8420 - val_loss: 0.1535 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1105 - accuracy: 0.8939 - val_loss: 0.1257 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1128 - accuracy: 0.8853 - val_loss: 0.1736 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0961 - accuracy: 0.9013Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0972 - accuracy: 0.8983 - val_loss: 0.1176 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1947 - accuracy: 0.8182 - val_loss: 0.1935 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1871 - accuracy: 0.7944 - val_loss: 0.1712 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1724 - accuracy: 0.8095 - val_loss: 0.4667 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.8203 - val_loss: 0.2071 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1512 - accuracy: 0.8506 - val_loss: 0.1632 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1662 - accuracy: 0.8290 - val_loss: 0.2311 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1214 - accuracy: 0.8550 - val_loss: 0.1530 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1176 - accuracy: 0.8810 - val_loss: 0.1768 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1529 - accuracy: 0.8442 - val_loss: 0.1238 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1245 - accuracy: 0.8788 - val_loss: 0.1513 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1191 - accuracy: 0.8636 - val_loss: 0.2162 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1006 - accuracy: 0.8961 - val_loss: 0.2380 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1057 - accuracy: 0.8658 - val_loss: 0.1734 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0824 - accuracy: 0.9177 - val_loss: 0.2454 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1581 - accuracy: 0.8442 - val_loss: 0.1903 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 16/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.1181 - accuracy: 0.9053\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1185 - accuracy: 0.9048 - val_loss: 0.2275 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0786 - accuracy: 0.9156 - val_loss: 0.1776 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0636 - accuracy: 0.9351 - val_loss: 0.1569 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 19/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0852 - accuracy: 0.9159Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0795 - accuracy: 0.9221 - val_loss: 0.1788 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [1 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 1 0 0 0]\n","0.6\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1597 - accuracy: 0.8531 - val_loss: 0.1220 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1265 - accuracy: 0.8834 - val_loss: 0.1183 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1353 - accuracy: 0.8704 - val_loss: 0.0937 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1406 - accuracy: 0.8639 - val_loss: 0.1539 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1457 - accuracy: 0.8596 - val_loss: 0.0768 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1527 - accuracy: 0.8596 - val_loss: 0.1393 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1212 - accuracy: 0.8920 - val_loss: 0.4613 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1071 - accuracy: 0.8985 - val_loss: 0.1028 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1085 - accuracy: 0.8963 - val_loss: 0.1115 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0914 - accuracy: 0.9006 - val_loss: 0.1080 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0961 - accuracy: 0.8985 - val_loss: 0.0847 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1234 - accuracy: 0.8942 - val_loss: 0.1111 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1206 - accuracy: 0.8683 - val_loss: 0.1187 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1060 - accuracy: 0.9050 - val_loss: 0.1068 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1046 - accuracy: 0.9071 - val_loss: 0.0964 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9222 - val_loss: 0.1047 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1061 - accuracy: 0.8942 - val_loss: 0.1449 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 18/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0820 - accuracy: 0.9279\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0787 - accuracy: 0.9266 - val_loss: 0.1045 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0460 - accuracy: 0.9611 - val_loss: 0.1437 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0405 - accuracy: 0.9719 - val_loss: 0.1458 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 21/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0335 - accuracy: 0.9722Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0353 - accuracy: 0.9719 - val_loss: 0.1721 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 1 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 6ms/step - loss: 0.1033 - accuracy: 0.9028 - val_loss: 0.0989 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1055 - accuracy: 0.8942 - val_loss: 0.1190 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0883 - accuracy: 0.8985 - val_loss: 0.1633 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1200 - accuracy: 0.8877 - val_loss: 0.2198 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0753 - accuracy: 0.9222 - val_loss: 0.1559 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9244 - val_loss: 0.1509 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0921 - accuracy: 0.8963 - val_loss: 0.1806 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.1437 - accuracy: 0.8750\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1512 - accuracy: 0.8726 - val_loss: 0.1723 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0919 - accuracy: 0.9330 - val_loss: 0.2197 - val_accuracy: 0.7739 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0769 - accuracy: 0.9352 - val_loss: 0.1896 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 11/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0423 - accuracy: 0.9595Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0430 - accuracy: 0.9590 - val_loss: 0.1594 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8133733133433283\n","Accuracy:  0.9460899550224884\n","Average Normalized Accuracy:  0.8358370814592704\n","Average Precision:  0.9031640961177777\n","Average Recall:  0.8386615368757067\n","F1 score: 0.8697185005818862\n","Grand Mean: 0.8678074139000763\n"]}]},{"cell_type":"markdown","source":["## S6G Matrix Model"],"metadata":{"id":"JlC0wh1QclCg"}},{"cell_type":"code","source":["# Define the model\n","model_s6g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s6g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s6g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s6g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s6g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuAunMY9clhs","executionInfo":{"status":"ok","timestamp":1697816101176,"user_tz":-330,"elapsed":70370,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"0cb394df-4e56-4573-91af-78e94e067ee4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5040 - accuracy: 0.3377 - val_loss: 0.4327 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.4870 - val_loss: 0.4375 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3852 - accuracy: 0.5649 - val_loss: 0.4653 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3848 - accuracy: 0.5498 - val_loss: 0.3896 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3355 - accuracy: 0.6342 - val_loss: 0.3717 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3507 - accuracy: 0.5909 - val_loss: 0.3699 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3855 - accuracy: 0.5108 - val_loss: 0.3360 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3262 - accuracy: 0.6364 - val_loss: 0.2964 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3002 - accuracy: 0.6688 - val_loss: 0.2908 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2809 - accuracy: 0.6818 - val_loss: 0.2772 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2810 - accuracy: 0.6970 - val_loss: 0.3004 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.7143 - val_loss: 0.2720 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.6948 - val_loss: 0.2561 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2498 - accuracy: 0.7186 - val_loss: 0.3817 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.7186 - val_loss: 0.2728 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2341 - accuracy: 0.7381 - val_loss: 0.2815 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2294 - accuracy: 0.7338 - val_loss: 0.2961 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2176 - accuracy: 0.7424 - val_loss: 0.3749 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1992 - accuracy: 0.7576\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1992 - accuracy: 0.7576 - val_loss: 0.3075 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1718 - accuracy: 0.8139 - val_loss: 0.3014 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1649 - accuracy: 0.8312 - val_loss: 0.3028 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 22/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1513 - accuracy: 0.8378Restoring model weights from the end of the best epoch: 12.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1524 - accuracy: 0.8355 - val_loss: 0.3447 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 22: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.2695 - accuracy: 0.6970 - val_loss: 0.2704 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2812 - accuracy: 0.6948 - val_loss: 0.2698 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2588 - accuracy: 0.7208 - val_loss: 0.2992 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2575 - accuracy: 0.7035 - val_loss: 0.2514 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2508 - accuracy: 0.7165 - val_loss: 0.3872 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2692 - accuracy: 0.6926 - val_loss: 0.3248 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2524 - accuracy: 0.6991 - val_loss: 0.2476 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2220 - accuracy: 0.7403 - val_loss: 0.2539 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2182 - accuracy: 0.7576 - val_loss: 0.2591 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2141 - accuracy: 0.7792 - val_loss: 0.2395 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2009 - accuracy: 0.7597 - val_loss: 0.2684 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1866 - accuracy: 0.7792 - val_loss: 0.2726 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2212 - accuracy: 0.7468 - val_loss: 0.2638 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 14/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1654 - accuracy: 0.8201\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1713 - accuracy: 0.8139 - val_loss: 0.2577 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1451 - accuracy: 0.8268 - val_loss: 0.3124 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1428 - accuracy: 0.8160 - val_loss: 0.2693 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 17/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1379 - accuracy: 0.8378Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1378 - accuracy: 0.8377 - val_loss: 0.2442 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.2517 - accuracy: 0.7273 - val_loss: 0.2540 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2320 - accuracy: 0.7446 - val_loss: 0.2143 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2018 - accuracy: 0.7814 - val_loss: 0.2765 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1923 - accuracy: 0.7879 - val_loss: 0.2364 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2025 - accuracy: 0.7576 - val_loss: 0.2305 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.7900 - val_loss: 0.2542 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1836 - accuracy: 0.7792 - val_loss: 0.2575 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1790 - accuracy: 0.7792 - val_loss: 0.2512 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 9/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.7957\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1760 - accuracy: 0.7944 - val_loss: 0.2685 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1956 - accuracy: 0.7987 - val_loss: 0.2238 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1398 - accuracy: 0.8290 - val_loss: 0.2200 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.1268 - accuracy: 0.8296Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1285 - accuracy: 0.8268 - val_loss: 0.2231 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3020 - accuracy: 0.6566 - val_loss: 0.2114 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2779 - accuracy: 0.7084 - val_loss: 0.1626 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2341 - accuracy: 0.7387 - val_loss: 0.1583 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2130 - accuracy: 0.7646 - val_loss: 0.1229 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1897 - accuracy: 0.7624 - val_loss: 0.1420 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2089 - accuracy: 0.7495 - val_loss: 0.1185 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1929 - accuracy: 0.7754 - val_loss: 0.2028 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2087 - accuracy: 0.7538 - val_loss: 0.1672 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 9/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1869 - accuracy: 0.7703\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1847 - accuracy: 0.7732 - val_loss: 0.1284 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.8078 - val_loss: 0.1491 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1434 - accuracy: 0.8164 - val_loss: 0.1206 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 12/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1337 - accuracy: 0.8248Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1336 - accuracy: 0.8272 - val_loss: 0.1314 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2076 - accuracy: 0.7624 - val_loss: 0.2621 - val_accuracy: 0.6957 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2027 - accuracy: 0.7797 - val_loss: 0.2507 - val_accuracy: 0.6957 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1955 - accuracy: 0.7754 - val_loss: 0.2555 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1880 - accuracy: 0.7905 - val_loss: 0.4274 - val_accuracy: 0.5913 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1951 - accuracy: 0.7970 - val_loss: 0.2709 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1677 - accuracy: 0.8056 - val_loss: 0.2685 - val_accuracy: 0.6783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2008 - accuracy: 0.7862 - val_loss: 0.2768 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1831 - accuracy: 0.8078 - val_loss: 0.2859 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1438 - accuracy: 0.8143 - val_loss: 0.3182 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1487 - accuracy: 0.8251 - val_loss: 0.3385 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.8467 - val_loss: 0.3198 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1324 - accuracy: 0.8294 - val_loss: 0.3026 - val_accuracy: 0.7304 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1559 - accuracy: 0.8207 - val_loss: 0.3795 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1931 - accuracy: 0.8035 - val_loss: 0.2881 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1417 - accuracy: 0.8445 - val_loss: 0.2987 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1472 - accuracy: 0.8467 - val_loss: 0.3678 - val_accuracy: 0.6609 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1567 - accuracy: 0.8380 - val_loss: 0.3414 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 18/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1232 - accuracy: 0.8819\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.8812 - val_loss: 0.3523 - val_accuracy: 0.7304 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.9006 - val_loss: 0.3788 - val_accuracy: 0.7217 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.8877 - val_loss: 0.3531 - val_accuracy: 0.7391 - lr: 5.0000e-04\n","Epoch 21/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0940 - accuracy: 0.9243Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0949 - accuracy: 0.9222 - val_loss: 0.3702 - val_accuracy: 0.7217 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","Average Accuracy:  0.667976011994003\n","Accuracy:  0.9052443778110938\n","Average Normalized Accuracy:  0.6833083458270865\n","Average Precision:  0.7650829595492012\n","Average Recall:  0.6727886721068467\n","F1 score: 0.7159737170888337\n","Grand Mean: 0.7350623473961776\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["# Standardizing SkipGram"],"metadata":{"id":"P_mQUI-Be9za"}},{"cell_type":"code","source":["# standardize the sxgbg_matrix\n","import numpy as np\n","\n","def calculate_sxgbg_stan_features(evolutionary_profile, X):\n","    L, _ = evolutionary_profile.shape\n","    sxgbg_matrix = np.zeros((20, 20))\n","\n","    for i in range(20):\n","        for j in range(20):\n","            sxgbg_value = 0.0\n","\n","            for l in range(1, L - X):\n","                sxgbg_value += evolutionary_profile[l - 1, i] * evolutionary_profile[l + X, j]\n","\n","            sxgbg_matrix[i, j] = sxgbg_value\n","\n","    # Standardize the sxgbg_matrix (z-score normalization)\n","    mean = np.mean(sxgbg_matrix)\n","    std = np.std(sxgbg_matrix)\n","\n","    if std != 0:\n","        sxgbg_matrix = (sxgbg_matrix - mean) / std\n","    else:\n","        sxgbg_matrix = np.zeros_like(sxgbg_matrix)  # Handle the case of zero standard deviation\n","\n","    return sxgbg_matrix"],"metadata":{"id":"_6Ir9uBOfBeF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Stan"],"metadata":{"id":"O3fP4RaxfJWk"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s0g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s0g_mat = calculate_sxgbg_stan_features(i, 0)\n","    s0g_arr = np.array(s0g_mat)\n","    s0g_stan_matrix.append(s0g_arr)\n","\n","df['s0g_stan_matrix'] = s0g_stan_matrix"],"metadata":{"id":"6GOdizvWfCNk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S1G Stan"],"metadata":{"id":"o45MENkxfSjV"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s1g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s1g_mat = calculate_sxgbg_stan_features(i, 1)\n","    s1g_arr = np.array(s1g_mat)\n","    s1g_stan_matrix.append(s1g_arr)\n","\n","df['s1g_stan_matrix'] = s1g_stan_matrix"],"metadata":{"id":"K8UEDzpffR4A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S2G Stan"],"metadata":{"id":"Ou_4eSXLfhmX"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s2g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s2g_mat = calculate_sxgbg_stan_features(i, 2)\n","    s2g_arr = np.array(s2g_mat)\n","    s2g_stan_matrix.append(s2g_arr)\n","\n","df['s2g_stan_matrix'] = s2g_stan_matrix"],"metadata":{"id":"rZqYeKImfax9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3G Stan"],"metadata":{"id":"cH5KByK2fpsT"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s3g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s3g_mat = calculate_sxgbg_stan_features(i, 3)\n","    s3g_arr = np.array(s3g_mat)\n","    s3g_stan_matrix.append(s3g_arr)\n","\n","df['s3g_stan_matrix'] = s3g_stan_matrix"],"metadata":{"id":"zU1ctHJefjYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S4G Stan"],"metadata":{"id":"8-8iUCqKfyVk"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s4g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s4g_mat = calculate_sxgbg_stan_features(i, 4)\n","    s4g_arr = np.array(s4g_mat)\n","    s4g_stan_matrix.append(s4g_arr)\n","\n","df['s4g_stan_matrix'] = s4g_stan_matrix"],"metadata":{"id":"7awNJJx9fsIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S5G Stan"],"metadata":{"id":"enK9ZSyYf2oJ"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s5g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s5g_mat = calculate_sxgbg_stan_features(i, 5)\n","    s5g_arr = np.array(s5g_mat)\n","    s5g_stan_matrix.append(s5g_arr)\n","\n","df['s5g_stan_matrix'] = s5g_stan_matrix"],"metadata":{"id":"x2iGPewVf19F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S6G Stan"],"metadata":{"id":"oA0OrXLuf_Iv"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store pssm_arr for each PDBid\n","s6g_stan_matrix = []\n","\n","for i in df['pssm_matrix']:\n","    s6g_mat = calculate_sxgbg_stan_features(i, 6)\n","    s6g_arr = np.array(s6g_mat)\n","    s6g_stan_matrix.append(s6g_arr)\n","\n","df['s6g_stan_matrix'] = s6g_stan_matrix"],"metadata":{"id":"2Vssn4gOf4q9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Stan Matrix Model"],"metadata":{"id":"rD59vdL8g12Z"}},{"cell_type":"code","source":["# Define the model\n","model_s0g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrwlgOdEgKKT","executionInfo":{"status":"ok","timestamp":1697816597627,"user_tz":-330,"elapsed":61350,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"9b516829-b850-4560-ade9-b92ea4e24189"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4265 - accuracy: 0.5108 - val_loss: 0.3494 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.6883 - val_loss: 0.3091 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.6948 - val_loss: 0.2894 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1974 - accuracy: 0.8052 - val_loss: 0.3141 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1523 - accuracy: 0.8723 - val_loss: 0.3962 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1384 - accuracy: 0.8723 - val_loss: 0.2629 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1154 - accuracy: 0.9004 - val_loss: 0.2842 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.8983 - val_loss: 0.3841 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0905 - accuracy: 0.9156 - val_loss: 0.3285 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0719 - accuracy: 0.9307 - val_loss: 0.3816 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0646 - accuracy: 0.9481 - val_loss: 0.4602 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0568 - accuracy: 0.9286 - val_loss: 0.4018 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0704 - accuracy: 0.9264 - val_loss: 0.3899 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0477 - accuracy: 0.9481 - val_loss: 0.4738 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0370 - accuracy: 0.9589 - val_loss: 0.4528 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 16/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0315 - accuracy: 0.9543\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9545 - val_loss: 0.5389 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9632 - val_loss: 0.4420 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0193 - accuracy: 0.9589 - val_loss: 0.4285 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0129 - accuracy: 0.9675 - val_loss: 0.4305 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0134 - accuracy: 0.9719 - val_loss: 0.5888 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0192 - accuracy: 0.9632 - val_loss: 0.4114 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9675 - val_loss: 0.5150 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9697 - val_loss: 0.4476 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9675 - val_loss: 0.5196 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9632 - val_loss: 0.4474 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0116 - accuracy: 0.9740 - val_loss: 0.5094 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0122 - accuracy: 0.9784 - val_loss: 0.6001 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 28/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0120 - accuracy: 0.9745\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0124 - accuracy: 0.9675 - val_loss: 0.4707 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9675 - val_loss: 0.5094 - val_accuracy: 0.7155 - lr: 2.5000e-04\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0054 - accuracy: 0.9762 - val_loss: 0.4938 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [1 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1355 - accuracy: 0.8680 - val_loss: 0.0340 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0654 - accuracy: 0.9329 - val_loss: 0.0233 - val_accuracy: 0.9828 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9567 - val_loss: 0.0174 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0455 - accuracy: 0.9589 - val_loss: 0.0266 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0320 - accuracy: 0.9545 - val_loss: 0.0274 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0256 - accuracy: 0.9675 - val_loss: 0.0495 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9632 - val_loss: 0.0231 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0518 - accuracy: 0.9416 - val_loss: 0.0362 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 9/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0255 - accuracy: 0.9688\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0249 - accuracy: 0.9697 - val_loss: 0.0305 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0130 - accuracy: 0.9740 - val_loss: 0.0515 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9632 - val_loss: 0.0325 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 12/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0073 - accuracy: 0.9699Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9697 - val_loss: 0.0284 - val_accuracy: 0.9741 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0636 - accuracy: 0.9307 - val_loss: 0.0337 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0453 - accuracy: 0.9589 - val_loss: 0.0235 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0272 - accuracy: 0.9697 - val_loss: 0.0366 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0228 - accuracy: 0.9827 - val_loss: 0.0484 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0251 - accuracy: 0.9719 - val_loss: 0.2439 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0354 - accuracy: 0.9697 - val_loss: 0.0569 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0629 - accuracy: 0.9545 - val_loss: 0.0716 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0287 - accuracy: 0.9697\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0287 - accuracy: 0.9697 - val_loss: 0.1235 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0138 - accuracy: 0.9805 - val_loss: 0.0678 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9805 - val_loss: 0.0539 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9827Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0093 - accuracy: 0.9827 - val_loss: 0.0543 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0571 - accuracy: 0.9503 - val_loss: 0.0234 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0557 - accuracy: 0.9460 - val_loss: 0.0631 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0343 - accuracy: 0.9611 - val_loss: 0.1547 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0465 - accuracy: 0.9482 - val_loss: 0.0644 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0425 - accuracy: 0.9633 - val_loss: 0.0920 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9806 - val_loss: 0.1072 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0184 - accuracy: 0.9654 - val_loss: 0.0652 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0291 - accuracy: 0.9698\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0291 - accuracy: 0.9698 - val_loss: 0.0994 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9762 - val_loss: 0.0419 - val_accuracy: 0.9826 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0064 - accuracy: 0.9806 - val_loss: 0.0513 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0054 - accuracy: 0.9741 - val_loss: 0.0527 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0123 - accuracy: 0.9741 - val_loss: 0.0771 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0077 - accuracy: 0.9806 - val_loss: 0.1041 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9762 - val_loss: 0.0799 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0059 - accuracy: 0.9762 - val_loss: 0.0598 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 16/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0062 - accuracy: 0.9833\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9762 - val_loss: 0.0720 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0031 - accuracy: 0.9806 - val_loss: 0.0612 - val_accuracy: 0.9565 - lr: 2.5000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0017 - accuracy: 0.9784 - val_loss: 0.0603 - val_accuracy: 0.9565 - lr: 2.5000e-04\n","Epoch 19/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0012 - accuracy: 0.9835    Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9784 - val_loss: 0.0663 - val_accuracy: 0.9565 - lr: 2.5000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.0571 - accuracy: 0.9525 - val_loss: 0.0335 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0380 - accuracy: 0.9633 - val_loss: 0.0393 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9676 - val_loss: 0.0299 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9698 - val_loss: 0.1999 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0485 - accuracy: 0.9590 - val_loss: 0.0943 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9849 - val_loss: 0.0642 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0060 - accuracy: 0.9762 - val_loss: 0.1401 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0243 - accuracy: 0.9719 - val_loss: 0.0802 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 9/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0117 - accuracy: 0.9732\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0118 - accuracy: 0.9741 - val_loss: 0.0577 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0030 - accuracy: 0.9849 - val_loss: 0.0725 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 7.6340e-04 - accuracy: 0.9806 - val_loss: 0.0783 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 5.1332e-04 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 5.2802e-04 - accuracy: 0.9806 - val_loss: 0.0861 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.9050674662668665\n","Accuracy:  0.9710014992503746\n","Average Normalized Accuracy:  0.9177261369315343\n","Average Precision:  0.9389192676557707\n","Average Recall:  0.9181507745365295\n","F1 score: 0.9284188891526466\n","Grand Mean: 0.9298806722989538\n"]}]},{"cell_type":"markdown","source":["## S1G Stan Matrix Model"],"metadata":{"id":"Wdu9UxNshPwF"}},{"cell_type":"code","source":["# Define the model\n","model_s1g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fqQtZnjhDV6","executionInfo":{"status":"ok","timestamp":1697816662693,"user_tz":-330,"elapsed":65098,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"7155d571-a896-4463-ec9b-6863689ea23c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.4050 - accuracy: 0.5195 - val_loss: 0.3241 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3132 - accuracy: 0.6299 - val_loss: 0.3036 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.7619 - val_loss: 0.3609 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2124 - accuracy: 0.7684 - val_loss: 0.2726 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1840 - accuracy: 0.8095 - val_loss: 0.2619 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1276 - accuracy: 0.8766 - val_loss: 0.2849 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1160 - accuracy: 0.8983 - val_loss: 0.2839 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1096 - accuracy: 0.9048 - val_loss: 0.3118 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0980 - accuracy: 0.9069 - val_loss: 0.3065 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0903 - accuracy: 0.9156 - val_loss: 0.3559 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0966 - accuracy: 0.9091 - val_loss: 0.3846 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9481 - val_loss: 0.4138 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0528 - accuracy: 0.9524 - val_loss: 0.4485 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0599 - accuracy: 0.9351 - val_loss: 0.4318 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 15/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0532 - accuracy: 0.9571\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0567 - accuracy: 0.9567 - val_loss: 0.4046 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0386 - accuracy: 0.9524 - val_loss: 0.3726 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0227 - accuracy: 0.9697 - val_loss: 0.3950 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0218 - accuracy: 0.9740 - val_loss: 0.4122 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9589 - val_loss: 0.4165 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0133 - accuracy: 0.9762 - val_loss: 0.4564 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0226 - accuracy: 0.9567 - val_loss: 0.4410 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0127 - accuracy: 0.9719 - val_loss: 0.4696 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0195 - accuracy: 0.9675 - val_loss: 0.4704 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9632 - val_loss: 0.4924 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 25/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0179 - accuracy: 0.9712\n","Epoch 25: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9719 - val_loss: 0.4582 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0079 - accuracy: 0.9675 - val_loss: 0.5006 - val_accuracy: 0.7328 - lr: 2.5000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9870 - val_loss: 0.4876 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","Epoch 28/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0052 - accuracy: 0.9762Restoring model weights from the end of the best epoch: 18.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9762 - val_loss: 0.5061 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","Epoch 28: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1424 - accuracy: 0.8810 - val_loss: 0.0584 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0820 - accuracy: 0.9048 - val_loss: 0.0453 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9286 - val_loss: 0.0497 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0608 - accuracy: 0.9351 - val_loss: 0.0267 - val_accuracy: 0.9914 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9481 - val_loss: 0.0500 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0517 - accuracy: 0.9524 - val_loss: 0.0404 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0381 - accuracy: 0.9459 - val_loss: 0.0653 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9567 - val_loss: 0.0530 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0339 - accuracy: 0.9567 - val_loss: 0.0470 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0197 - accuracy: 0.9675 - val_loss: 0.0507 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0228 - accuracy: 0.9583\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0230 - accuracy: 0.9589 - val_loss: 0.0848 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0147 - accuracy: 0.9697 - val_loss: 0.0574 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0093 - accuracy: 0.9697 - val_loss: 0.0670 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 14/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0097 - accuracy: 0.9730Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0093 - accuracy: 0.9740 - val_loss: 0.0549 - val_accuracy: 0.9655 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0540 - accuracy: 0.9567 - val_loss: 0.1504 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9394 - val_loss: 0.0350 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0677 - accuracy: 0.9481 - val_loss: 0.0739 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9545 - val_loss: 0.0797 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0312 - accuracy: 0.9697 - val_loss: 0.0813 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0412 - accuracy: 0.9545 - val_loss: 0.0784 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0182 - accuracy: 0.9870 - val_loss: 0.1101 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0270 - accuracy: 0.9675 - val_loss: 0.0982 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0220 - accuracy: 0.9762\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0220 - accuracy: 0.9762 - val_loss: 0.1062 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9827 - val_loss: 0.0890 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0068 - accuracy: 0.9848 - val_loss: 0.0832 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 12/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0100 - accuracy: 0.9733Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9762 - val_loss: 0.0720 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0488 - accuracy: 0.9503 - val_loss: 0.0417 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0422 - accuracy: 0.9460 - val_loss: 0.0457 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0535 - accuracy: 0.9525 - val_loss: 0.0774 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0490 - accuracy: 0.9525 - val_loss: 0.0701 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0413 - accuracy: 0.9633 - val_loss: 0.0578 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0143 - accuracy: 0.9806 - val_loss: 0.0998 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0155 - accuracy: 0.9849 - val_loss: 0.0667 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0160 - accuracy: 0.9784 - val_loss: 0.0489 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 9/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0180 - accuracy: 0.9660\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9676 - val_loss: 0.0738 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9784 - val_loss: 0.0723 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9870 - val_loss: 0.0741 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0033 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0032 - accuracy: 0.9827 - val_loss: 0.0776 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9568 - val_loss: 0.0624 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0402 - accuracy: 0.9568 - val_loss: 0.0932 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0462 - accuracy: 0.9568 - val_loss: 0.3036 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0516 - accuracy: 0.9503 - val_loss: 0.0577 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0306 - accuracy: 0.9568 - val_loss: 0.0375 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0284 - accuracy: 0.9611 - val_loss: 0.1028 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0217 - accuracy: 0.9784 - val_loss: 0.0467 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0304 - accuracy: 0.9546 - val_loss: 0.1609 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0193 - accuracy: 0.9762 - val_loss: 0.0495 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0061 - accuracy: 0.9892 - val_loss: 0.0569 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0105 - accuracy: 0.9784 - val_loss: 0.0975 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0194 - accuracy: 0.9784 - val_loss: 0.1142 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0145 - accuracy: 0.9633 - val_loss: 0.1385 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9827 - val_loss: 0.0799 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0023 - accuracy: 0.9849 - val_loss: 0.0837 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0362 - accuracy: 0.9503 - val_loss: 0.1530 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 17/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0261 - accuracy: 0.9615\n","Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0310 - accuracy: 0.9590 - val_loss: 0.1837 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0208 - accuracy: 0.9741 - val_loss: 0.0935 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0035 - accuracy: 0.9806 - val_loss: 0.0987 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 20/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0017 - accuracy: 0.9771Restoring model weights from the end of the best epoch: 10.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9784 - val_loss: 0.1096 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 20: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8997901049475262\n","Accuracy:  0.9699490254872561\n","Average Normalized Accuracy:  0.9127811094452773\n","Average Precision:  0.9441298332237655\n","Average Recall:  0.9129327555412496\n","F1 score: 0.928269252149301\n","Grand Mean: 0.9279753467990628\n"]}]},{"cell_type":"markdown","source":["## S2G Stan Matrix Model"],"metadata":{"id":"rpUjtyQ0hYYf"}},{"cell_type":"code","source":["# Define the model\n","model_s2g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEc9ZxmlhGJH","executionInfo":{"status":"ok","timestamp":1697816723212,"user_tz":-330,"elapsed":60578,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"200ea1d1-67cb-4f27-903e-cfcf67c0cc02"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.4361 - accuracy: 0.4719 - val_loss: 0.4086 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3138 - accuracy: 0.6450 - val_loss: 0.3183 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2322 - accuracy: 0.7619 - val_loss: 0.3138 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2015 - accuracy: 0.7965 - val_loss: 0.2940 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1759 - accuracy: 0.8160 - val_loss: 0.2911 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1475 - accuracy: 0.8485 - val_loss: 0.2907 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1263 - accuracy: 0.8918 - val_loss: 0.3210 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0843 - accuracy: 0.9177 - val_loss: 0.3558 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0877 - accuracy: 0.9113 - val_loss: 0.3281 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0837 - accuracy: 0.9199 - val_loss: 0.4059 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0812 - accuracy: 0.9242 - val_loss: 0.3637 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0721 - accuracy: 0.9242 - val_loss: 0.4424 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0497 - accuracy: 0.9351 - val_loss: 0.4813 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9481 - val_loss: 0.4529 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 15/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0344 - accuracy: 0.9537\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0357 - accuracy: 0.9502 - val_loss: 0.4820 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9632 - val_loss: 0.4980 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9524 - val_loss: 0.4966 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 18/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0176 - accuracy: 0.9636Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0162 - accuracy: 0.9675 - val_loss: 0.5929 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [1 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1738 - accuracy: 0.8420 - val_loss: 0.0817 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1101 - accuracy: 0.8983 - val_loss: 0.1016 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9026 - val_loss: 0.1154 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0794 - accuracy: 0.9091 - val_loss: 0.0898 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0704 - accuracy: 0.9177 - val_loss: 0.0933 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0547 - accuracy: 0.9437 - val_loss: 0.1221 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0361 - accuracy: 0.9632 - val_loss: 0.1333 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 8/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9496\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0449 - accuracy: 0.9502 - val_loss: 0.1220 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9697 - val_loss: 0.0946 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0138 - accuracy: 0.9719 - val_loss: 0.1093 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 11/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0090 - accuracy: 0.9766Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0088 - accuracy: 0.9784 - val_loss: 0.1132 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1579 - accuracy: 0.8442 - val_loss: 0.2374 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1005 - accuracy: 0.9004 - val_loss: 0.0831 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0746 - accuracy: 0.9351 - val_loss: 0.1155 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0640 - accuracy: 0.9351 - val_loss: 0.1142 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0611 - accuracy: 0.9372 - val_loss: 0.1354 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0507 - accuracy: 0.9481 - val_loss: 0.0954 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0505 - accuracy: 0.9502 - val_loss: 0.1910 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0549 - accuracy: 0.9394 - val_loss: 0.1357 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0377 - accuracy: 0.9654 - val_loss: 0.1289 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0376 - accuracy: 0.9697 - val_loss: 0.3516 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0413 - accuracy: 0.9654 - val_loss: 0.1567 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0258 - accuracy: 0.9654 - val_loss: 0.2408 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0300 - accuracy: 0.9589\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0300 - accuracy: 0.9589 - val_loss: 0.1861 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0140 - accuracy: 0.9784 - val_loss: 0.2050 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9697 - val_loss: 0.1897 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 16/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0111 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9762 - val_loss: 0.2208 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0903 - accuracy: 0.9244 - val_loss: 0.0714 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9546 - val_loss: 0.0808 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9438 - val_loss: 0.0442 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0418 - accuracy: 0.9568 - val_loss: 0.1516 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0494 - accuracy: 0.9482 - val_loss: 0.1019 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0509 - accuracy: 0.9482 - val_loss: 0.0596 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0260 - accuracy: 0.9611 - val_loss: 0.0770 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0235 - accuracy: 0.9633 - val_loss: 0.1372 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9676 - val_loss: 0.1096 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0233 - accuracy: 0.9698\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0233 - accuracy: 0.9698 - val_loss: 0.1175 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0174 - accuracy: 0.9698 - val_loss: 0.0941 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0078 - accuracy: 0.9849 - val_loss: 0.0963 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9806Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0060 - accuracy: 0.9806 - val_loss: 0.0965 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0652 - accuracy: 0.9503 - val_loss: 0.1010 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0572 - accuracy: 0.9417 - val_loss: 0.0779 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0415 - accuracy: 0.9568 - val_loss: 0.1857 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0505 - accuracy: 0.9546 - val_loss: 0.1575 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0384 - accuracy: 0.9546 - val_loss: 0.0770 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0248 - accuracy: 0.9633 - val_loss: 0.0562 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0283 - accuracy: 0.9654 - val_loss: 0.1134 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9784 - val_loss: 0.1278 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0427 - accuracy: 0.9546\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9546 - val_loss: 0.2147 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0151 - accuracy: 0.9654 - val_loss: 0.0853 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0083 - accuracy: 0.9741 - val_loss: 0.0873 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9757Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9762 - val_loss: 0.0949 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8479160419790105\n","Accuracy:  0.9550704647676158\n","Average Normalized Accuracy:  0.867248875562219\n","Average Precision:  0.9194185007261986\n","Average Recall:  0.8701437309986734\n","F1 score: 0.8941027368464237\n","Grand Mean: 0.89231672514669\n"]}]},{"cell_type":"markdown","source":["## S3G Stan Matrix Model"],"metadata":{"id":"67ZpxwcJhlVB"}},{"cell_type":"code","source":["# Define the model\n","model_s3g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s3g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s3g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s3g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s3g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5CEDkxXhHLu","executionInfo":{"status":"ok","timestamp":1697816778794,"user_tz":-330,"elapsed":55620,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"756f2660-d04a-4410-863d-e6ab55943312"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.4161 - accuracy: 0.5022 - val_loss: 0.3048 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3012 - accuracy: 0.6602 - val_loss: 0.2788 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2438 - accuracy: 0.7511 - val_loss: 0.2561 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1990 - accuracy: 0.7965 - val_loss: 0.2908 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1610 - accuracy: 0.8268 - val_loss: 0.2959 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1471 - accuracy: 0.8485 - val_loss: 0.2644 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1231 - accuracy: 0.8874 - val_loss: 0.2688 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0968 - accuracy: 0.9134 - val_loss: 0.3098 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0791 - accuracy: 0.9307 - val_loss: 0.3006 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0760 - accuracy: 0.9264 - val_loss: 0.3102 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0591 - accuracy: 0.9610 - val_loss: 0.3302 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0470 - accuracy: 0.9589 - val_loss: 0.4382 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 13/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0423 - accuracy: 0.9358\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0427 - accuracy: 0.9372 - val_loss: 0.3183 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9610 - val_loss: 0.4137 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0199 - accuracy: 0.9632 - val_loss: 0.3731 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 16/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0177 - accuracy: 0.9623Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0196 - accuracy: 0.9632 - val_loss: 0.3713 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1940 - accuracy: 0.8074 - val_loss: 0.1128 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1269 - accuracy: 0.8745 - val_loss: 0.0930 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1012 - accuracy: 0.8853 - val_loss: 0.1013 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0947 - accuracy: 0.9069 - val_loss: 0.1378 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0693 - accuracy: 0.9329 - val_loss: 0.1661 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0548 - accuracy: 0.9481 - val_loss: 0.1042 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0551 - accuracy: 0.9524 - val_loss: 0.1140 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0308 - accuracy: 0.9697 - val_loss: 0.2195 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0848 - accuracy: 0.9234\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0829 - accuracy: 0.9242 - val_loss: 0.1101 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0283 - accuracy: 0.9524 - val_loss: 0.1216 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0188 - accuracy: 0.9632 - val_loss: 0.1363 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0205 - accuracy: 0.9668Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0201 - accuracy: 0.9654 - val_loss: 0.1361 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1168 - accuracy: 0.8810 - val_loss: 0.0904 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0931 - accuracy: 0.9242 - val_loss: 0.0864 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9264 - val_loss: 0.1217 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0638 - accuracy: 0.9329 - val_loss: 0.1407 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9286 - val_loss: 0.1105 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0462 - accuracy: 0.9545 - val_loss: 0.1789 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0522 - accuracy: 0.9545 - val_loss: 0.1237 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0332 - accuracy: 0.9654 - val_loss: 0.2120 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0311 - accuracy: 0.9690\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0346 - accuracy: 0.9654 - val_loss: 0.3159 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0236 - accuracy: 0.9654 - val_loss: 0.1607 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0133 - accuracy: 0.9675 - val_loss: 0.1514 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0102 - accuracy: 0.9735Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9740 - val_loss: 0.1863 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0933 - accuracy: 0.8855 - val_loss: 0.0891 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0683 - accuracy: 0.9374 - val_loss: 0.0746 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0558 - accuracy: 0.9438 - val_loss: 0.0834 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9266 - val_loss: 0.1155 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9525 - val_loss: 0.1297 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0493 - accuracy: 0.9482 - val_loss: 0.0765 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0390 - accuracy: 0.9611 - val_loss: 0.1574 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0268 - accuracy: 0.9611 - val_loss: 0.1613 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0249 - accuracy: 0.9590\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0249 - accuracy: 0.9590 - val_loss: 0.1983 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9611 - val_loss: 0.1464 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9827 - val_loss: 0.1584 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0079 - accuracy: 0.9779Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0079 - accuracy: 0.9784 - val_loss: 0.1513 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 9ms/step - loss: 0.0717 - accuracy: 0.9352 - val_loss: 0.1094 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0612 - accuracy: 0.9374 - val_loss: 0.1456 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9482 - val_loss: 0.0779 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0564 - accuracy: 0.9395 - val_loss: 0.1100 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0552 - accuracy: 0.9525 - val_loss: 0.0807 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0320 - accuracy: 0.9698 - val_loss: 0.1652 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0241 - accuracy: 0.9698 - val_loss: 0.1321 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0342 - accuracy: 0.9568 - val_loss: 0.1946 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0348 - accuracy: 0.9590 - val_loss: 0.1996 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 10/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0306 - accuracy: 0.9626\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0296 - accuracy: 0.9611 - val_loss: 0.1265 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0128 - accuracy: 0.9849 - val_loss: 0.1383 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0094 - accuracy: 0.9762 - val_loss: 0.1366 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 13/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0059 - accuracy: 0.9845Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9849 - val_loss: 0.1467 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8600449775112444\n","Accuracy:  0.9599220389805094\n","Average Normalized Accuracy:  0.8802298850574711\n","Average Precision:  0.9295868154692529\n","Average Recall:  0.8750771312144231\n","F1 score: 0.9015087437086918\n","Grand Mean: 0.901061598656932\n"]}]},{"cell_type":"markdown","source":["## S4G Stan Matrix Model"],"metadata":{"id":"mRzR808Thu9h"}},{"cell_type":"code","source":["# Define the model\n","model_s4g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s4g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s4g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s4g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s4g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okX5aJI7hIJb","executionInfo":{"status":"ok","timestamp":1697816851924,"user_tz":-330,"elapsed":73185,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"14b39517-9630-4338-ab68-ead8c08c96f5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.3969 - accuracy: 0.5173 - val_loss: 0.2974 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.3212 - accuracy: 0.6342 - val_loss: 0.2923 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2448 - accuracy: 0.7424 - val_loss: 0.3495 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2184 - accuracy: 0.7965 - val_loss: 0.2841 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1851 - accuracy: 0.7965 - val_loss: 0.2841 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1505 - accuracy: 0.8463 - val_loss: 0.3170 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1158 - accuracy: 0.8918 - val_loss: 0.3464 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1142 - accuracy: 0.9004 - val_loss: 0.3840 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0829 - accuracy: 0.9177 - val_loss: 0.3649 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0792 - accuracy: 0.9242 - val_loss: 0.3803 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0590 - accuracy: 0.9351 - val_loss: 0.3812 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0661 - accuracy: 0.9437 - val_loss: 0.4108 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0487 - accuracy: 0.9481 - val_loss: 0.4378 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0440 - accuracy: 0.9481 - val_loss: 0.4815 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0383 - accuracy: 0.9524 - val_loss: 0.4865 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 16/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0395 - accuracy: 0.9575\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0386 - accuracy: 0.9589 - val_loss: 0.4673 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0271 - accuracy: 0.9524 - val_loss: 0.4946 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9697 - val_loss: 0.4888 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 19/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0123 - accuracy: 0.9640Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9654 - val_loss: 0.5072 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 1 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 3s 12ms/step - loss: 0.1720 - accuracy: 0.8268 - val_loss: 0.0749 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1133 - accuracy: 0.8853 - val_loss: 0.0945 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9113 - val_loss: 0.1170 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9329 - val_loss: 0.1514 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0606 - accuracy: 0.9372 - val_loss: 0.1256 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9567 - val_loss: 0.0854 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0438 - accuracy: 0.9545 - val_loss: 0.0929 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 8/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0339 - accuracy: 0.9617\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0344 - accuracy: 0.9589 - val_loss: 0.1126 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0191 - accuracy: 0.9675 - val_loss: 0.1180 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0147 - accuracy: 0.9762 - val_loss: 0.1026 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0176 - accuracy: 0.9737Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0173 - accuracy: 0.9740 - val_loss: 0.1073 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.1420 - accuracy: 0.8636 - val_loss: 0.1209 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1018 - accuracy: 0.9048 - val_loss: 0.0844 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9307 - val_loss: 0.1378 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0730 - accuracy: 0.9286 - val_loss: 0.1926 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.9329 - val_loss: 0.1280 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9654 - val_loss: 0.1497 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0399 - accuracy: 0.9589 - val_loss: 0.1209 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0366 - accuracy: 0.9675 - val_loss: 0.1345 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 9/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0352 - accuracy: 0.9670\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9654 - val_loss: 0.3701 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0200 - accuracy: 0.9719 - val_loss: 0.1805 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0142 - accuracy: 0.9784 - val_loss: 0.1479 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0115 - accuracy: 0.9762 - val_loss: 0.1277 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0160 - accuracy: 0.9719 - val_loss: 0.2133 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0153 - accuracy: 0.9719 - val_loss: 0.1469 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0115 - accuracy: 0.9740 - val_loss: 0.2166 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0108 - accuracy: 0.9740 - val_loss: 0.1829 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0089 - accuracy: 0.9697 - val_loss: 0.1867 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.9675 - val_loss: 0.1808 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 19/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0097 - accuracy: 0.9797\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0099 - accuracy: 0.9805 - val_loss: 0.1692 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0104 - accuracy: 0.9805 - val_loss: 0.1991 - val_accuracy: 0.8707 - lr: 2.5000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0049 - accuracy: 0.9805 - val_loss: 0.1875 - val_accuracy: 0.9138 - lr: 2.5000e-04\n","Epoch 22/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0036 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 12.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0035 - accuracy: 0.9827 - val_loss: 0.2048 - val_accuracy: 0.9138 - lr: 2.5000e-04\n","Epoch 22: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 1 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0810 - accuracy: 0.9266 - val_loss: 0.0579 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0540 - accuracy: 0.9503 - val_loss: 0.0719 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0544 - accuracy: 0.9590 - val_loss: 0.0941 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0435 - accuracy: 0.9460 - val_loss: 0.0834 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0234 - accuracy: 0.9719 - val_loss: 0.0646 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0292 - accuracy: 0.9654 - val_loss: 0.1319 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0444 - accuracy: 0.9546 - val_loss: 0.1279 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 8/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9715\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0275 - accuracy: 0.9719 - val_loss: 0.0632 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0181 - accuracy: 0.9719 - val_loss: 0.0721 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0071 - accuracy: 0.9762 - val_loss: 0.0938 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0048 - accuracy: 0.9825Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0047 - accuracy: 0.9806 - val_loss: 0.0901 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 6ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0675 - accuracy: 0.9352 - val_loss: 0.0530 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0604 - accuracy: 0.9525 - val_loss: 0.0750 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0309 - accuracy: 0.9590 - val_loss: 0.0492 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0318 - accuracy: 0.9784 - val_loss: 0.1780 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0396 - accuracy: 0.9676 - val_loss: 0.0478 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9611 - val_loss: 0.0805 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0312 - accuracy: 0.9741 - val_loss: 0.0916 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0143 - accuracy: 0.9762 - val_loss: 0.0958 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0092 - accuracy: 0.9806 - val_loss: 0.0786 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0204 - accuracy: 0.9654 - val_loss: 0.0741 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9676 - val_loss: 0.0840 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0082 - accuracy: 0.9735\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0080 - accuracy: 0.9741 - val_loss: 0.0809 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0090 - accuracy: 0.9676 - val_loss: 0.0685 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9870 - val_loss: 0.0696 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 15/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0013 - accuracy: 0.9841Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0013 - accuracy: 0.9849 - val_loss: 0.0987 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8446176911544228\n","Accuracy:  0.955454272863568\n","Average Normalized Accuracy:  0.864215392303848\n","Average Precision:  0.91769785834837\n","Average Recall:  0.866624008969904\n","F1 score: 0.891429973024144\n","Grand Mean: 0.8900065327773761\n"]}]},{"cell_type":"markdown","source":["## S5G Stan Matrix Model"],"metadata":{"id":"uB-yyawBiAiV"}},{"cell_type":"code","source":["# Define the model\n","model_s5g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s5g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s5g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s5g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s5g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPB49B3ChMbY","executionInfo":{"status":"ok","timestamp":1697816908470,"user_tz":-330,"elapsed":56572,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"062945ce-b895-44bd-f151-66b4e5d0a1c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.4223 - accuracy: 0.4913 - val_loss: 0.3329 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2985 - accuracy: 0.6558 - val_loss: 0.3203 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2468 - accuracy: 0.7359 - val_loss: 0.2647 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1994 - accuracy: 0.7900 - val_loss: 0.2588 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1745 - accuracy: 0.8247 - val_loss: 0.2599 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1473 - accuracy: 0.8550 - val_loss: 0.4035 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1326 - accuracy: 0.8571 - val_loss: 0.3671 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1135 - accuracy: 0.8961 - val_loss: 0.3505 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0948 - accuracy: 0.9048 - val_loss: 0.4295 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0755 - accuracy: 0.9286 - val_loss: 0.4168 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 11/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0651 - accuracy: 0.9404\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0745 - accuracy: 0.9286 - val_loss: 0.3100 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0424 - accuracy: 0.9502 - val_loss: 0.3512 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0337 - accuracy: 0.9567 - val_loss: 0.3433 - val_accuracy: 0.7759 - lr: 5.0000e-04\n","Epoch 14/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0343 - accuracy: 0.9523Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0347 - accuracy: 0.9524 - val_loss: 0.3517 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 12ms/step - loss: 0.2208 - accuracy: 0.7749 - val_loss: 0.1526 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1772 - accuracy: 0.8290 - val_loss: 0.1463 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1347 - accuracy: 0.8571 - val_loss: 0.1797 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1379 - accuracy: 0.8571 - val_loss: 0.1810 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1087 - accuracy: 0.9026 - val_loss: 0.1740 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0743 - accuracy: 0.9221 - val_loss: 0.1775 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0880 - accuracy: 0.9069 - val_loss: 0.1917 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0645 - accuracy: 0.9329 - val_loss: 0.1892 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0572 - accuracy: 0.9564\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0591 - accuracy: 0.9502 - val_loss: 0.2104 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0352 - accuracy: 0.9654 - val_loss: 0.1858 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0220 - accuracy: 0.9567 - val_loss: 0.1739 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 12/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0126 - accuracy: 0.9690Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0157 - accuracy: 0.9675 - val_loss: 0.2013 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1732 - accuracy: 0.8182 - val_loss: 0.1424 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1219 - accuracy: 0.8874 - val_loss: 0.1274 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1131 - accuracy: 0.8723 - val_loss: 0.2812 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1027 - accuracy: 0.8961 - val_loss: 0.1513 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0749 - accuracy: 0.9307 - val_loss: 0.2252 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0707 - accuracy: 0.9264 - val_loss: 0.1902 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0589 - accuracy: 0.9459 - val_loss: 0.1831 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0398 - accuracy: 0.9610 - val_loss: 0.2196 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0550 - accuracy: 0.9425\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0558 - accuracy: 0.9437 - val_loss: 0.2857 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0348 - accuracy: 0.9654 - val_loss: 0.1852 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0175 - accuracy: 0.9762 - val_loss: 0.2589 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 12/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0149 - accuracy: 0.9773Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9784 - val_loss: 0.1986 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 1]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1334 - accuracy: 0.8639 - val_loss: 0.0873 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1161 - accuracy: 0.8898 - val_loss: 0.1471 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0866 - accuracy: 0.9136 - val_loss: 0.0923 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0672 - accuracy: 0.9309 - val_loss: 0.1055 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0476 - accuracy: 0.9568 - val_loss: 0.1186 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0534 - accuracy: 0.9374 - val_loss: 0.1971 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0849 - accuracy: 0.9287 - val_loss: 0.1071 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0599 - accuracy: 0.9266 - val_loss: 0.0968 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0316 - accuracy: 0.9633 - val_loss: 0.1821 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9568\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0404 - accuracy: 0.9568 - val_loss: 0.1099 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0160 - accuracy: 0.9698 - val_loss: 0.1190 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0118 - accuracy: 0.9676 - val_loss: 0.1589 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 13/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 0.9710Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0099 - accuracy: 0.9698 - val_loss: 0.1423 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 6ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0954 - accuracy: 0.9050 - val_loss: 0.0790 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0654 - accuracy: 0.9395 - val_loss: 0.1070 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0497 - accuracy: 0.9438 - val_loss: 0.1094 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0495 - accuracy: 0.9568 - val_loss: 0.1266 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0480 - accuracy: 0.9503 - val_loss: 0.1827 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0506 - accuracy: 0.9438 - val_loss: 0.1390 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9676 - val_loss: 0.1458 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0362 - accuracy: 0.9665\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0388 - accuracy: 0.9654 - val_loss: 0.2324 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0188 - accuracy: 0.9698 - val_loss: 0.1368 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0084 - accuracy: 0.9806 - val_loss: 0.1713 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 11/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9818Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0069 - accuracy: 0.9827 - val_loss: 0.1431 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8168215892053972\n","Accuracy:  0.9492023988005993\n","Average Normalized Accuracy:  0.8341229385307347\n","Average Precision:  0.9160583095881798\n","Average Recall:  0.8314679805020073\n","F1 score: 0.8717158156814427\n","Grand Mean: 0.8698981720513936\n"]}]},{"cell_type":"markdown","source":["## S6G Stan Matrix Model"],"metadata":{"id":"i_eM-FWOiJVW"}},{"cell_type":"code","source":["# Define the model\n","model_s6g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s6g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s6g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s6g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s6g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thv6y-T0hNRv","executionInfo":{"status":"ok","timestamp":1697817007431,"user_tz":-330,"elapsed":98979,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"101dd269-cde0-4fd9-a99b-0e53e6ccbe4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 12ms/step - loss: 0.4178 - accuracy: 0.4784 - val_loss: 0.3459 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3073 - accuracy: 0.6645 - val_loss: 0.2754 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2468 - accuracy: 0.7532 - val_loss: 0.2635 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2007 - accuracy: 0.8009 - val_loss: 0.3368 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1660 - accuracy: 0.8225 - val_loss: 0.2627 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1452 - accuracy: 0.8680 - val_loss: 0.2454 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1133 - accuracy: 0.9004 - val_loss: 0.2762 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1141 - accuracy: 0.8896 - val_loss: 0.2620 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0753 - accuracy: 0.9351 - val_loss: 0.3895 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0848 - accuracy: 0.9091 - val_loss: 0.2672 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0517 - accuracy: 0.9545 - val_loss: 0.3535 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0436 - accuracy: 0.9545 - val_loss: 0.4419 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0535 - accuracy: 0.9416 - val_loss: 0.3723 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0396 - accuracy: 0.9589 - val_loss: 0.3298 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 15/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0387 - accuracy: 0.9397\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0378 - accuracy: 0.9394 - val_loss: 0.4714 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0207 - accuracy: 0.9654 - val_loss: 0.4084 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9719 - val_loss: 0.4397 - val_accuracy: 0.7586 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0122 - accuracy: 0.9589 - val_loss: 0.4612 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0134 - accuracy: 0.9762 - val_loss: 0.4954 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0119 - accuracy: 0.9654 - val_loss: 0.4769 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0109 - accuracy: 0.9740 - val_loss: 0.4526 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0104 - accuracy: 0.9740 - val_loss: 0.4870 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 23/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0090 - accuracy: 0.9817\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0086 - accuracy: 0.9827 - val_loss: 0.4968 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0073 - accuracy: 0.9805 - val_loss: 0.4904 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9870 - val_loss: 0.4905 - val_accuracy: 0.7586 - lr: 2.5000e-04\n","Epoch 26/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0052 - accuracy: 0.9696Restoring model weights from the end of the best epoch: 16.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0049 - accuracy: 0.9697 - val_loss: 0.5046 - val_accuracy: 0.7500 - lr: 2.5000e-04\n","Epoch 26: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.1420 - accuracy: 0.8961 - val_loss: 0.0774 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0776 - accuracy: 0.9113 - val_loss: 0.0610 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0599 - accuracy: 0.9351 - val_loss: 0.0425 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0415 - accuracy: 0.9545 - val_loss: 0.0463 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0291 - accuracy: 0.9610 - val_loss: 0.0575 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9394 - val_loss: 0.1350 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0500 - accuracy: 0.9416 - val_loss: 0.0743 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0219 - accuracy: 0.9697 - val_loss: 0.0966 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0336 - accuracy: 0.9632 - val_loss: 0.1366 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0583 - accuracy: 0.9502 - val_loss: 0.1159 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0271 - accuracy: 0.9609\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0270 - accuracy: 0.9610 - val_loss: 0.1439 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0160 - accuracy: 0.9719 - val_loss: 0.1032 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0063 - accuracy: 0.9719 - val_loss: 0.1104 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 14/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0075 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0074 - accuracy: 0.9784 - val_loss: 0.0985 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 3s 13ms/step - loss: 0.0827 - accuracy: 0.9286 - val_loss: 0.0545 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0491 - accuracy: 0.9416 - val_loss: 0.0568 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0232 - accuracy: 0.9610 - val_loss: 0.0446 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0424 - accuracy: 0.9459 - val_loss: 0.0435 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0257 - accuracy: 0.9697 - val_loss: 0.0925 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0376 - accuracy: 0.9675 - val_loss: 0.0758 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0219 - accuracy: 0.9632 - val_loss: 0.1036 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0341 - accuracy: 0.9654 - val_loss: 0.1563 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0266 - accuracy: 0.9675 - val_loss: 0.1049 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0304 - accuracy: 0.9524 - val_loss: 0.0868 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 11/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0235 - accuracy: 0.9685\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0230 - accuracy: 0.9675 - val_loss: 0.0762 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0100 - accuracy: 0.9719 - val_loss: 0.0810 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0098 - accuracy: 0.9740 - val_loss: 0.0774 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 14/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0064 - accuracy: 0.9797Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0074 - accuracy: 0.9784 - val_loss: 0.0918 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.0621 - accuracy: 0.9525 - val_loss: 0.0297 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0361 - accuracy: 0.9525 - val_loss: 0.0617 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0307 - accuracy: 0.9654 - val_loss: 0.0254 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0202 - accuracy: 0.9741 - val_loss: 0.0598 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0190 - accuracy: 0.9762 - val_loss: 0.0386 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0362 - accuracy: 0.9611 - val_loss: 0.0702 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0363 - accuracy: 0.9503 - val_loss: 0.0448 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 8/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0201 - accuracy: 0.9794\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0194 - accuracy: 0.9806 - val_loss: 0.0487 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0089 - accuracy: 0.9827 - val_loss: 0.0422 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9784 - val_loss: 0.0477 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0060 - accuracy: 0.9781Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0060 - accuracy: 0.9762 - val_loss: 0.0388 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0531 - accuracy: 0.9482 - val_loss: 0.0390 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0461 - accuracy: 0.9546 - val_loss: 0.0484 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0367 - accuracy: 0.9741 - val_loss: 0.0567 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0222 - accuracy: 0.9654 - val_loss: 0.0659 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0650 - accuracy: 0.9438 - val_loss: 0.0366 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9741 - val_loss: 0.0327 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0116 - accuracy: 0.9741 - val_loss: 0.0331 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0105 - accuracy: 0.9806 - val_loss: 0.0611 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 9/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0091 - accuracy: 0.9864\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0096 - accuracy: 0.9870 - val_loss: 0.0515 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0085 - accuracy: 0.9870 - val_loss: 0.1088 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0023 - accuracy: 0.9870 - val_loss: 0.0519 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0012 - accuracy: 0.9870 - val_loss: 0.0526 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0010 - accuracy: 0.9870 - val_loss: 0.0616 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0129 - accuracy: 0.9741 - val_loss: 0.0615 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0056 - accuracy: 0.9827 - val_loss: 0.0589 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9870 - val_loss: 0.0654 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9784 - val_loss: 0.0621 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 7.6005e-04 - accuracy: 0.9892 - val_loss: 0.0677 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 19/30\n","113/116 [============================>.] - ETA: 0s - loss: 5.8142e-04 - accuracy: 0.9889\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 5.7132e-04 - accuracy: 0.9870 - val_loss: 0.0708 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 4.1624e-04 - accuracy: 0.9870 - val_loss: 0.0703 - val_accuracy: 0.9391 - lr: 2.5000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 6ms/step - loss: 3.7650e-04 - accuracy: 0.9870 - val_loss: 0.0709 - val_accuracy: 0.9478 - lr: 2.5000e-04\n","Epoch 22/30\n","110/116 [===========================>..] - ETA: 0s - loss: 3.6018e-04 - accuracy: 0.9886Restoring model weights from the end of the best epoch: 12.\n","116/116 [==============================] - 1s 6ms/step - loss: 3.4791e-04 - accuracy: 0.9870 - val_loss: 0.0717 - val_accuracy: 0.9478 - lr: 2.5000e-04\n","Epoch 22: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8912143928035983\n","Accuracy:  0.9678920539730133\n","Average Normalized Accuracy:  0.9076536731634182\n","Average Precision:  0.9316560472030713\n","Average Recall:  0.9131197981002088\n","F1 score: 0.9222947968305062\n","Grand Mean: 0.9223051270123027\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Cc6JkuzbiWCp"},"execution_count":null,"outputs":[]}]}
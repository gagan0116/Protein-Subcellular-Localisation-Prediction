{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"17apa7TZ7ZAx2FzXCk0V90iKZ5uLbfiXS","timestamp":1697828018767}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q8gpyAe-ertT","executionInfo":{"status":"ok","timestamp":1697883171288,"user_tz":-330,"elapsed":26212,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"62a2fe7b-4604-4268-ac27-e83601a433cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/HDA/Benchmark_BinaryML.csv')"],"metadata":{"id":"Pwe5y1yseubg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"Sr0oUsFBPGXi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Word2Vec"],"metadata":{"id":"not-08lMB1oZ"}},{"cell_type":"markdown","source":["**Bi-gram**"],"metadata":{"id":"xwaxAHkxDQHn"}},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","\n","# Define a function to generate 2-grams from a protein sequence\n","def generate_ngrams(sequence):\n","    n = 2  # Length of the n-grams\n","    return [sequence[i:i+n] for i in range(len(sequence) - n + 1)]\n","\n","# Apply the function to create a new column '2grams' in your DataFrame\n","df['2grams'] = df['Sequence'].apply(generate_ngrams)\n","\n","# Train a Word2Vec model on the 2-grams\n","bigrams = list(df['2grams'])\n","model = Word2Vec(bigrams, vector_size=20, window=7, min_count=1, sg=0, epochs=30)  # Adjust parameters as needed\n","\n","# Extract embeddings for each token in the 2-grams\n","def get_embedding(token):\n","    try:\n","        return model.wv[token].tolist()\n","    except KeyError:\n","        # Handle the case where the token is not in the vocabulary\n","        return [0.0] * 100  # Return a vector of zeros of the same dimension as your model\n","\n","# Create a new column 'embeddings' containing embeddings for each 2-gram\n","df['2gramembeddings'] = df['2grams'].apply(lambda tokens: [get_embedding(token) for token in tokens])\n","\n","# Print the DataFrame with 2-grams and embeddings\n","print(df[['2grams', '2gramembeddings']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pzg-F09fe_LW","executionInfo":{"status":"ok","timestamp":1697875929088,"user_tz":-330,"elapsed":9227,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"b5b59635-3b14-4b5c-b959-f5b2f20aab19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                2grams  \\\n","0    [MI, IF, FS, ST, TF, FE, EH, HI, IL, LT, TH, H...   \n","1    [MS, SQ, QS, SI, IQ, QF, FS, ST, TP, PS, SH, H...   \n","2    [MA, AL, LA, AQ, QK, KV, VA, AS, SR, RP, PA, A...   \n","3    [MI, IG, GR, RL, LY, YM, MK, KK, KL, LK, KN, N...   \n","4    [ME, EQ, QY, YI, IL, LK, KL, LE, EN, NS, SI, I...   \n","..                                                 ...   \n","573  [MD, DS, SQ, QD, DI, IR, RY, YR, RG, GG, GD, D...   \n","574  [MQ, QV, VL, LV, VV, VS, SP, PP, PL, LI, IA, A...   \n","575  [ML, LA, AA, AK, KS, SI, IA, AG, GP, PR, RA, A...   \n","576  [MA, AT, TS, SL, LS, SV, VS, SR, RF, FM, MS, S...   \n","577  [MG, GF, FV, VL, LI, IC, CT, TC, CP, PP, PS, S...   \n","\n","                                       2gramembeddings  \n","0    [[-0.3510728180408478, 4.808881759643555, 0.12...  \n","1    [[4.771347522735596, 8.573156356811523, 5.7716...  \n","2    [[2.648731231689453, 6.069174766540527, -2.254...  \n","3    [[-0.3510728180408478, 4.808881759643555, 0.12...  \n","4    [[-3.2245898246765137, 7.409628868103027, -5.1...  \n","..                                                 ...  \n","573  [[-0.5218017101287842, 0.58638596534729, 8.287...  \n","574  [[2.82314133644104, -2.3556456565856934, -3.76...  \n","575  [[-0.04845952242612839, 5.440380573272705, 4.9...  \n","576  [[2.648731231689453, 6.069174766540527, -2.254...  \n","577  [[-4.85889196395874, 1.5205631256103516, 1.206...  \n","\n","[578 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["**Tri-gram**"],"metadata":{"id":"yi0GYreKMNZt"}},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","\n","# Define a function to generate 3-grams from a protein sequence\n","def generate_ngrams(sequence):\n","    n = 3  # Length of the n-grams\n","    return [sequence[i:i+n] for i in range(len(sequence) - n + 1)]\n","\n","# Apply the function to create a new column '3grams' in your DataFrame\n","df['3grams'] = df['Sequence'].apply(generate_ngrams)\n","\n","# Train a Word2Vec model on the 3-grams\n","trigrams = list(df['3grams'])\n","model = Word2Vec(trigrams, vector_size=20, window=7, min_count=1, sg=0, epochs=30)  # Adjust parameters as needed\n","\n","# Extract embeddings for each token in the 3-grams\n","def get_embedding(token):\n","    try:\n","        return model.wv[token].tolist()\n","    except KeyError:\n","        # Handle the case where the token is not in the vocabulary\n","        return [0.0] * 100  # Return a vector of zeros of the same dimension as your model\n","\n","# Create a new column 'embeddings' containing embeddings for each 3-gram\n","df['3gramembeddings'] = df['3grams'].apply(lambda tokens: [get_embedding(token) for token in tokens])\n","\n","# Print the DataFrame with 3-grams and embeddings\n","print(df[['3grams', '3gramembeddings']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PJKCuTByMYj5","executionInfo":{"status":"ok","timestamp":1697883195003,"user_tz":-330,"elapsed":21419,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"0d9a011a-61a8-4321-c477-f8abda437e5d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                3grams  \\\n","0    [MIF, IFS, FST, STF, TFE, FEH, EHI, HIL, ILT, ...   \n","1    [MSQ, SQS, QSI, SIQ, IQF, QFS, FST, STP, TPS, ...   \n","2    [MAL, ALA, LAQ, AQK, QKV, KVA, VAS, ASR, SRP, ...   \n","3    [MIG, IGR, GRL, RLY, LYM, YMK, MKK, KKL, KLK, ...   \n","4    [MEQ, EQY, QYI, YIL, ILK, LKL, KLE, LEN, ENS, ...   \n","..                                                 ...   \n","573  [MDS, DSQ, SQD, QDI, DIR, IRY, RYR, YRG, RGG, ...   \n","574  [MQV, QVL, VLV, LVV, VVS, VSP, SPP, PPL, PLI, ...   \n","575  [MLA, LAA, AAK, AKS, KSI, SIA, IAG, AGP, GPR, ...   \n","576  [MAT, ATS, TSL, SLS, LSV, SVS, VSR, SRF, RFM, ...   \n","577  [MGF, GFV, FVL, VLI, LIC, ICT, CTC, TCP, CPP, ...   \n","\n","                                       3gramembeddings  \n","0    [[1.9285818338394165, -0.5312661528587341, -0....  \n","1    [[1.356009840965271, 2.3489632606506348, 1.912...  \n","2    [[1.443404197692871, -0.10230518877506256, 0.6...  \n","3    [[2.17508864402771, -1.224699854850769, -1.963...  \n","4    [[-0.2088177651166916, 0.5881282687187195, -0....  \n","..                                                 ...  \n","573  [[-1.7284294366836548, 0.2747676372528076, 1.9...  \n","574  [[0.9654263854026794, 0.1107693612575531, 0.39...  \n","575  [[2.8973968029022217, -3.0233476161956787, -0....  \n","576  [[3.1573293209075928, 0.06667527556419373, 2.8...  \n","577  [[1.5026062726974487, -1.8221253156661987, -0....  \n","\n","[578 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["**4-gram**"],"metadata":{"id":"vrfhw3WOMeqm"}},{"cell_type":"code","source":["import pandas as pd\n","from gensim.models import Word2Vec\n","\n","# Define a function to generate 4-grams from a protein sequence\n","def generate_ngrams(sequence):\n","    n = 4  # Length of the n-grams\n","    return [sequence[i:i+n] for i in range(len(sequence) - n + 1)]\n","\n","# Apply the function to create a new column '4grams' in your DataFrame\n","df['4grams'] = df['Sequence'].apply(generate_ngrams)\n","\n","# Train a Word2Vec model on the 4-grams\n","fourgrams = list(df['4grams'])\n","model = Word2Vec(fourgrams, vector_size=20, window=7, min_count=1, sg=0, epochs=30)  # Adjust parameters as needed\n","\n","# Extract embeddings for each token in the 4-grams\n","def get_embedding(token):\n","    try:\n","        return model.wv[token].tolist()\n","    except KeyError:\n","        # Handle the case where the token is not in the vocabulary\n","        return [0.0] * 100  # Return a vector of zeros of the same dimension as your model\n","\n","# Create a new column 'embeddings' containing embeddings for each 4-gram\n","df['4gramembeddings'] = df['4grams'].apply(lambda tokens: [get_embedding(token) for token in tokens])\n","\n","# Print the DataFrame with 4-grams and embeddings\n","print(df[['4grams', '4gramembeddings']])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FN6DVWKmMiZq","executionInfo":{"status":"ok","timestamp":1697875967812,"user_tz":-330,"elapsed":20295,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"e9ca7152-d0b4-4853-920e-5a8e73c38628"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["                                                4grams  \\\n","0    [MIFS, IFST, FSTF, STFE, TFEH, FEHI, EHIL, HIL...   \n","1    [MSQS, SQSI, QSIQ, SIQF, IQFS, QFST, FSTP, STP...   \n","2    [MALA, ALAQ, LAQK, AQKV, QKVA, KVAS, VASR, ASR...   \n","3    [MIGR, IGRL, GRLY, RLYM, LYMK, YMKK, MKKL, KKL...   \n","4    [MEQY, EQYI, QYIL, YILK, ILKL, LKLE, KLEN, LEN...   \n","..                                                 ...   \n","573  [MDSQ, DSQD, SQDI, QDIR, DIRY, IRYR, RYRG, YRG...   \n","574  [MQVL, QVLV, VLVV, LVVS, VVSP, VSPP, SPPL, PPL...   \n","575  [MLAA, LAAK, AAKS, AKSI, KSIA, SIAG, IAGP, AGP...   \n","576  [MATS, ATSL, TSLS, SLSV, LSVS, SVSR, VSRF, SRF...   \n","577  [MGFV, GFVL, FVLI, VLIC, LICT, ICTC, CTCP, TCP...   \n","\n","                                       4gramembeddings  \n","0    [[0.041435107588768005, 0.10089678317308426, 0...  \n","1    [[0.04310250282287598, 0.11480894684791565, 0....  \n","2    [[0.36205345392227173, 0.24876828491687775, 0....  \n","3    [[0.01865660399198532, 0.008067392744123936, 0...  \n","4    [[0.02855313941836357, 0.0441574789583683, 0.0...  \n","..                                                 ...  \n","573  [[0.009670479223132133, 0.03125005215406418, 0...  \n","574  [[0.13958419859409332, 0.10633557289838791, 0....  \n","575  [[0.2337772250175476, 0.20275969803333282, 0.7...  \n","576  [[0.13888409733772278, 0.07393410801887512, 0....  \n","577  [[0.03998652845621109, 0.07307624816894531, 0....  \n","\n","[578 rows x 2 columns]\n"]}]},{"cell_type":"markdown","source":["# Feature Extraction using SXG on Word2Vec Embeddings"],"metadata":{"id":"obeBbEm6MsZv"}},{"cell_type":"code","source":["def calculate_sxgbg_stan_features(evolutionary_profile, X):\n","    L, _ = evolutionary_profile.shape\n","    sxgbg_matrix = np.zeros((20, 20))\n","\n","    for i in range(20):\n","        for j in range(20):\n","            sxgbg_value = 0.0\n","\n","            for l in range(1, L - X):\n","                sxgbg_value += evolutionary_profile[l - 1, i] * evolutionary_profile[l + X, j]\n","\n","            sxgbg_matrix[i, j] = sxgbg_value\n","\n","    # Standardize the sxgbg_matrix (z-score normalization)\n","    mean = np.mean(sxgbg_matrix)\n","    std = np.std(sxgbg_matrix)\n","\n","    if std != 0:\n","        sxgbg_matrix = (sxgbg_matrix - mean) / std\n","    else:\n","        sxgbg_matrix = np.zeros_like(sxgbg_matrix)  # Handle the case of zero standard deviation\n","\n","    return sxgbg_matrix"],"metadata":{"id":"hOPlzLxnM3cp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S0G on bi-gram embeddings**"],"metadata":{"id":"yN13gQQjOBVj"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s0g_matrix_2g = []\n","\n","for i in df['2gramembeddings']:\n","    s0g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 0)\n","    s0g_arr_2g = np.array(s0g_mat_2g)\n","    s0g_matrix_2g.append(s0g_arr_2g)\n","\n","df['s0g_matrix_2g'] = s0g_matrix_2g"],"metadata":{"id":"IMyiJqZNOIyf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S1G on bi-gram embeddings**"],"metadata":{"id":"PuUAniHPNwd5"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s1g_matrix_2g = []\n","\n","for i in df['2gramembeddings']:\n","    s1g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 1)\n","    s1g_arr_2g = np.array(s1g_mat_2g)\n","    s1g_matrix_2g.append(s1g_arr_2g)\n","\n","df['s1g_matrix_2g'] = s1g_matrix_2g"],"metadata":{"id":"KKo0F8AxNDfT"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S2G on bi-gram embeddings**"],"metadata":{"id":"BfwS-xwqQjg0"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s2g_matrix_2g = []\n","\n","for i in df['2gramembeddings']:\n","    s2g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 2)\n","    s2g_arr_2g = np.array(s2g_mat_2g)\n","    s2g_matrix_2g.append(s2g_arr_2g)\n","\n","df['s2g_matrix_2g'] = s2g_matrix_2g"],"metadata":{"id":"mRz2CE6ONFGO"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S3G on bi-gram embeddings**"],"metadata":{"id":"UxyNIvS6SROz"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s3g_matrix_2g = []\n","\n","for i in df['2gramembeddings']:\n","    s3g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 3)\n","    s3g_arr_2g = np.array(s3g_mat_2g)\n","    s3g_matrix_2g.append(s3g_arr_2g)\n","\n","df['s3g_matrix_2g'] = s3g_matrix_2g"],"metadata":{"id":"hedj6YbLNHSj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S4G on bi-gram embeddings**"],"metadata":{"id":"iKrRWwhSTUQF"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s4g_matrix_2g = []\n","\n","for i in df['2gramembeddings']:\n","    s4g_mat_2g = calculate_sxgbg_stan_features(np.array(i), 4)\n","    s4g_arr_2g = np.array(s4g_mat_2g)\n","    s4g_matrix_2g.append(s4g_arr_2g)\n","\n","df['s4g_matrix_2g'] = s4g_matrix_2g"],"metadata":{"id":"IVJL-tvVSo8u"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S0G on Tri-gram embeddings**"],"metadata":{"id":"pIFdsum4UYGv"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s0g_matrix_3gram = []\n","\n","for i in df['3gramembeddings']:\n","    s0g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 0)\n","    s0g_arr_3 = np.array(s0g_mat_3)\n","    s0g_matrix_3gram.append(s0g_arr_3)\n","\n","df['s0g_matrix_3gram'] = s0g_matrix_3gram"],"metadata":{"id":"2xCe5hDDUeuf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S1G on Tri-gram embeddings**"],"metadata":{"id":"DU6CkCZuWF9a"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s1g_matrix_3gram = []\n","\n","for i in df['3gramembeddings']:\n","    s1g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 1)\n","    s1g_arr_3 = np.array(s1g_mat_3)\n","    s1g_matrix_3gram.append(s1g_arr_3)\n","\n","df['s1g_matrix_3gram'] = s1g_matrix_3gram"],"metadata":{"id":"250O-mDuWFC9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S2G on Tri-gram embeddings**"],"metadata":{"id":"6wRXhbZeXbGl"}},{"cell_type":"code","source":["# Create an empty list to store hmm_arr for each PDBid\n","s2g_matrix_3gram = []\n","\n","for i in df['3gramembeddings']:\n","    s2g_mat_3 = calculate_sxgbg_stan_features(np.array(i), 2)\n","    s2g_arr_3 = np.array(s2g_mat_3)\n","    s2g_matrix_3gram.append(s2g_arr_3)\n","\n","df['s2g_matrix_3gram'] = s2g_matrix_3gram"],"metadata":{"id":"-RD-YPFIXe9M"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S0G on 4-gram embeddings**"],"metadata":{"id":"n4LMouqYYagz"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s0g_matrix_4gram = []\n","\n","for i in df['4gramembeddings']:\n","    s0g_mat_4 = calculate_sxgbg_stan_features(np.array(i), 0)\n","    s0g_arr_4 = np.array(s0g_mat_4)\n","    s0g_matrix_4gram.append(s0g_arr_4)\n","\n","df['s0g_matrix_4gram'] = s0g_matrix_4gram"],"metadata":{"id":"m4e3QxuVYeku"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**S1G on 4-gram embeddings**"],"metadata":{"id":"pIVPpS6dZSEc"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s1g_matrix_4gram = []\n","\n","for i in df['4gramembeddings']:\n","    s1g_mat_4 = calculate_sxgbg_stan_features(np.array(i), 1)\n","    s1g_arr_4 = np.array(s1g_mat_4)\n","    s1g_matrix_4gram.append(s1g_arr_4)\n","\n","df['s1g_matrix_4gram'] = s1g_matrix_4gram"],"metadata":{"id":"sm8-t-K3ZRKH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Evaluation Metrics"],"metadata":{"id":"TEB6LZ07MSzv"}},{"cell_type":"code","source":["def calculate_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    # Initialize accuracy\n","    accuracy = 0\n","\n","    # Calculate accuracy for each instance\n","    for i in range(len(y_true)):\n","        # Calculate intersection and union\n","        intersection = np.sum(np.logical_and(y_true[i], y_pred[i]))\n","        union = np.sum(np.logical_or(y_true[i], y_pred[i]))\n","\n","        # Add to total accuracy\n","        accuracy += intersection / union\n","\n","    # Calculate average accuracy\n","    accuracy /= len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"gUXDuw0ZLaIF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def norm_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    acc = []\n","    # Loop over each instance\n","    for i in range(len(y_true)):\n","        # Calculate the number of correct predictions for this instance\n","        correct_predictions = np.sum(y_true[i] == y_pred[i])\n","        acc.append(correct_predictions/5)\n","\n","    # Calculate accuracy\n","    accuracy = sum(acc) / len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"8On1L-8aPofS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Models"],"metadata":{"id":"Eb_wK5KZNMqS"}},{"cell_type":"markdown","source":["**bi-gram+S0G Matrix Model**"],"metadata":{"id":"btBssHqOOlfc"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s0g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_matrix_2g'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-MNXpmgzOrGs","executionInfo":{"status":"ok","timestamp":1697876426899,"user_tz":-330,"elapsed":62686,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"6cca6f59-b91e-4328-910d-e8a0f0cd3fe5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.4800 - accuracy: 0.3593 - val_loss: 0.3874 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.4321 - accuracy: 0.4394 - val_loss: 0.3745 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3820 - accuracy: 0.5649 - val_loss: 0.3706 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3511 - accuracy: 0.5909 - val_loss: 0.4002 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.3251 - accuracy: 0.6169 - val_loss: 0.3784 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3102 - accuracy: 0.6558 - val_loss: 0.3592 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.6861 - val_loss: 0.3960 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.7251 - val_loss: 0.3774 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2307 - accuracy: 0.7597 - val_loss: 0.4044 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1988 - accuracy: 0.7944 - val_loss: 0.4156 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.8203 - val_loss: 0.4253 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1471 - accuracy: 0.8485 - val_loss: 0.4273 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1062 - accuracy: 0.9221 - val_loss: 0.4310 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1038 - accuracy: 0.9307 - val_loss: 0.4529 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0981 - accuracy: 0.9177 - val_loss: 0.4813 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0780 - accuracy: 0.9394 - val_loss: 0.5116 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9416 - val_loss: 0.6903 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0605 - accuracy: 0.9524 - val_loss: 0.6438 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0468 - accuracy: 0.9610 - val_loss: 0.6466 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 20/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0521 - accuracy: 0.9435\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0526 - accuracy: 0.9437 - val_loss: 0.5912 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9892 - val_loss: 0.5952 - val_accuracy: 0.5948 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0191 - accuracy: 0.9784 - val_loss: 0.6931 - val_accuracy: 0.5776 - lr: 5.0000e-04\n","Epoch 23/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0183 - accuracy: 0.9720Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0177 - accuracy: 0.9740 - val_loss: 0.6558 - val_accuracy: 0.5690 - lr: 5.0000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2144 - accuracy: 0.7792 - val_loss: 0.1429 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1538 - accuracy: 0.8550 - val_loss: 0.0823 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.8766 - val_loss: 0.0876 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1266 - accuracy: 0.8918 - val_loss: 0.1082 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0940 - accuracy: 0.9221 - val_loss: 0.0642 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0748 - accuracy: 0.9416 - val_loss: 0.0814 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0756 - accuracy: 0.9264 - val_loss: 0.1000 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0607 - accuracy: 0.9437 - val_loss: 0.1284 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0571 - accuracy: 0.9437 - val_loss: 0.0913 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 10/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9649\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0517 - accuracy: 0.9632 - val_loss: 0.1954 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9697 - val_loss: 0.1252 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0209 - accuracy: 0.9762 - val_loss: 0.2032 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 13/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0296 - accuracy: 0.9811Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0282 - accuracy: 0.9827 - val_loss: 0.1066 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.1272 - accuracy: 0.8831 - val_loss: 0.0797 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0986 - accuracy: 0.9091 - val_loss: 0.0709 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0841 - accuracy: 0.9394 - val_loss: 0.0703 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0883 - accuracy: 0.9156 - val_loss: 0.0922 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0664 - accuracy: 0.9416 - val_loss: 0.1042 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0742 - accuracy: 0.9264 - val_loss: 0.1154 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0495 - accuracy: 0.9567 - val_loss: 0.1143 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0396 - accuracy: 0.9598\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0389 - accuracy: 0.9610 - val_loss: 0.0973 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9784 - val_loss: 0.0882 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0140 - accuracy: 0.9870 - val_loss: 0.0925 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11/30\n"," 97/116 [========================>.....] - ETA: 0s - loss: 0.0129 - accuracy: 0.9820Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0152 - accuracy: 0.9805 - val_loss: 0.0939 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.1029 - accuracy: 0.8985 - val_loss: 0.0660 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1000 - accuracy: 0.8985 - val_loss: 0.0564 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9158 - val_loss: 0.0411 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0574 - accuracy: 0.9611 - val_loss: 0.0775 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0605 - accuracy: 0.9460 - val_loss: 0.0549 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0535 - accuracy: 0.9568 - val_loss: 0.0728 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0524 - accuracy: 0.9374 - val_loss: 0.0797 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0439 - accuracy: 0.9525 - val_loss: 0.0570 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0353 - accuracy: 0.9719 - val_loss: 0.0844 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 10/30\n","100/116 [========================>.....] - ETA: 0s - loss: 0.0232 - accuracy: 0.9800\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0243 - accuracy: 0.9806 - val_loss: 0.0791 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0227 - accuracy: 0.9676 - val_loss: 0.0954 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9870 - val_loss: 0.0731 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 13/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0123 - accuracy: 0.9748Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0118 - accuracy: 0.9762 - val_loss: 0.0897 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 7ms/step - loss: 0.0774 - accuracy: 0.9309 - val_loss: 0.0547 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0878 - accuracy: 0.9222 - val_loss: 0.0846 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0848 - accuracy: 0.9158 - val_loss: 0.0452 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0486 - accuracy: 0.9676 - val_loss: 0.1098 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0550 - accuracy: 0.9503 - val_loss: 0.0634 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0358 - accuracy: 0.9676 - val_loss: 0.0832 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0447 - accuracy: 0.9503 - val_loss: 0.0533 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0221 - accuracy: 0.9654 - val_loss: 0.0610 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0180 - accuracy: 0.9762 - val_loss: 0.1331 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 10/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0422 - accuracy: 0.9639\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0462 - accuracy: 0.9568 - val_loss: 0.1157 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0253 - accuracy: 0.9741 - val_loss: 0.0791 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0134 - accuracy: 0.9892 - val_loss: 0.0964 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 13/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0130 - accuracy: 0.9795Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9806 - val_loss: 0.0869 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Average Accuracy:  0.8411844077961019\n","Accuracy:  0.9527136431784106\n","Average Normalized Accuracy:  0.8633833083458272\n","Average Precision:  0.9093230951481382\n","Average Recall:  0.853061633927482\n","F1 score: 0.8802943336009602\n","Grand Mean: 0.8833267369994866\n"]}]},{"cell_type":"markdown","source":["**2-gram+S1G Matrix Model**"],"metadata":{"id":"4eWHgBSONQ-S"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s1g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_matrix_2g'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bATLxBu-kgqi","executionInfo":{"status":"ok","timestamp":1697876605533,"user_tz":-330,"elapsed":56899,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"8b6ddb1b-2ce8-4963-a4a6-c05839e624ed"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.5183 - accuracy: 0.3745 - val_loss: 0.4440 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3414 - accuracy: 0.6234 - val_loss: 0.4345 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2273 - accuracy: 0.7597 - val_loss: 0.4763 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1320 - accuracy: 0.8983 - val_loss: 0.5152 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9416 - val_loss: 0.6974 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0450 - accuracy: 0.9675 - val_loss: 0.6778 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0337 - accuracy: 0.9654 - val_loss: 0.7475 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0267 - accuracy: 0.9740 - val_loss: 0.8885 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0253 - accuracy: 0.9654 - val_loss: 0.8654 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0164 - accuracy: 0.9654 - val_loss: 0.9711 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0173 - accuracy: 0.9870 - val_loss: 0.9715 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0125 - accuracy: 0.9827 - val_loss: 1.0403 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0170 - accuracy: 0.9719 - val_loss: 1.0686 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9805 - val_loss: 1.0569 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0145 - accuracy: 0.9762 - val_loss: 1.1941 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 16/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0164 - accuracy: 0.9519\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0177 - accuracy: 0.9545 - val_loss: 1.2304 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9719 - val_loss: 1.1507 - val_accuracy: 0.4310 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0082 - accuracy: 0.9762 - val_loss: 1.1643 - val_accuracy: 0.4569 - lr: 5.0000e-04\n","Epoch 19/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0048 - accuracy: 0.9862Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0051 - accuracy: 0.9870 - val_loss: 1.1453 - val_accuracy: 0.4741 - lr: 5.0000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 3s 14ms/step - loss: 0.2143 - accuracy: 0.8312 - val_loss: 0.0220 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0581 - accuracy: 0.9459 - val_loss: 0.0202 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0330 - accuracy: 0.9675 - val_loss: 0.0176 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9740 - val_loss: 0.0244 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9762 - val_loss: 0.0267 - val_accuracy: 0.9828 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9697 - val_loss: 0.0461 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9740 - val_loss: 0.0235 - val_accuracy: 0.9828 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0129 - accuracy: 0.9784 - val_loss: 0.0439 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0150 - accuracy: 0.9762 - val_loss: 0.0261 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0055 - accuracy: 0.9740 - val_loss: 0.0411 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0072 - accuracy: 0.9654 - val_loss: 0.0389 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 12/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0071 - accuracy: 0.9720\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9697 - val_loss: 0.0548 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0091 - accuracy: 0.9740 - val_loss: 0.0387 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0033 - accuracy: 0.9740 - val_loss: 0.0407 - val_accuracy: 0.9655 - lr: 5.0000e-04\n","Epoch 15/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0028 - accuracy: 0.9759Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0028 - accuracy: 0.9762 - val_loss: 0.0429 - val_accuracy: 0.9483 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0224 - accuracy: 0.9675 - val_loss: 0.0083 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0323 - accuracy: 0.9784 - val_loss: 0.0040 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9740 - val_loss: 0.0196 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0182 - accuracy: 0.9719 - val_loss: 0.0132 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0126 - accuracy: 0.9827 - val_loss: 0.0401 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0145 - accuracy: 0.9719 - val_loss: 0.0242 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0089 - accuracy: 0.9762 - val_loss: 0.0411 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0217 - accuracy: 0.9754\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9762 - val_loss: 0.0901 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0128 - accuracy: 0.9697 - val_loss: 0.0741 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0077 - accuracy: 0.9762 - val_loss: 0.0692 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0044 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0042 - accuracy: 0.9762 - val_loss: 0.0587 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.0381 - accuracy: 0.9654 - val_loss: 0.0152 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0240 - accuracy: 0.9719 - val_loss: 0.0121 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0210 - accuracy: 0.9806 - val_loss: 0.0097 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0194 - accuracy: 0.9719 - val_loss: 0.0048 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0128 - accuracy: 0.9806 - val_loss: 0.0339 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0205 - accuracy: 0.9654 - val_loss: 0.0185 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9762 - val_loss: 0.0288 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0058 - accuracy: 0.9806 - val_loss: 0.0272 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0035 - accuracy: 0.9870 - val_loss: 0.0323 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0015 - accuracy: 0.9827 - val_loss: 0.0314 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 11/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0027 - accuracy: 0.9881\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0026 - accuracy: 0.9870 - val_loss: 0.0321 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0039 - accuracy: 0.9741 - val_loss: 0.0441 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0028 - accuracy: 0.9784 - val_loss: 0.0440 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 14/30\n","113/116 [============================>.] - ETA: 0s - loss: 9.4330e-04 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 9.2153e-04 - accuracy: 0.9806 - val_loss: 0.0306 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 6ms/step - loss: 0.0236 - accuracy: 0.9676 - val_loss: 0.0096 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0531 - accuracy: 0.9568 - val_loss: 0.0119 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0126 - accuracy: 0.9762 - val_loss: 0.0070 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0097 - accuracy: 0.9806 - val_loss: 0.0075 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0083 - accuracy: 0.9741 - val_loss: 0.0156 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0068 - accuracy: 0.9870 - val_loss: 0.0051 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0058 - accuracy: 0.9741 - val_loss: 0.0107 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0052 - accuracy: 0.9762 - val_loss: 0.0176 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0017 - accuracy: 0.9784 - val_loss: 0.0236 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 10/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0013 - accuracy: 0.9858\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0012 - accuracy: 0.9870 - val_loss: 0.0148 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 8.9550e-04 - accuracy: 0.9827 - val_loss: 0.0178 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0063 - accuracy: 0.9849 - val_loss: 0.0094 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 13/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0015 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9827 - val_loss: 0.0126 - val_accuracy: 0.9652 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Average Accuracy:  0.8620389805097451\n","Accuracy:  0.9565457271364316\n","Average Normalized Accuracy:  0.8689505247376312\n","Average Precision:  0.8936413970313344\n","Average Recall:  0.8690139088770176\n","F1 score: 0.8811556076397126\n","Grand Mean: 0.8885576909886453\n"]}]},{"cell_type":"markdown","source":["**Bi-gram+S2G Matrix Model**"],"metadata":{"id":"M1ggqcOpQ2iu"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s2g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_matrix_2g'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"I16iyTSvm8fX","executionInfo":{"status":"ok","timestamp":1697876641976,"user_tz":-330,"elapsed":36471,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"ee7ee324-c548-4288-8a52-0c592a4e0496"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5296 - accuracy: 0.3333 - val_loss: 0.4392 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3458 - accuracy: 0.6342 - val_loss: 0.4220 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.2414 - accuracy: 0.7446 - val_loss: 0.4414 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1442 - accuracy: 0.8853 - val_loss: 0.5104 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1074 - accuracy: 0.9264 - val_loss: 0.5522 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0829 - accuracy: 0.9437 - val_loss: 0.6282 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0411 - accuracy: 0.9719 - val_loss: 0.7658 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0395 - accuracy: 0.9632 - val_loss: 0.7950 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9697 - val_loss: 0.8083 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0270 - accuracy: 0.9740 - val_loss: 0.8315 - val_accuracy: 0.4397 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0196 - accuracy: 0.9762 - val_loss: 0.8896 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 12/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0137 - accuracy: 0.9786\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.9805 - val_loss: 0.9712 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.9719 - val_loss: 0.9406 - val_accuracy: 0.4138 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0076 - accuracy: 0.9719 - val_loss: 0.9763 - val_accuracy: 0.4397 - lr: 5.0000e-04\n","Epoch 15/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0069 - accuracy: 0.9743Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9740 - val_loss: 0.9932 - val_accuracy: 0.4569 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.2087 - accuracy: 0.8095 - val_loss: 0.0727 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0912 - accuracy: 0.9177 - val_loss: 0.0667 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0557 - accuracy: 0.9437 - val_loss: 0.0819 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0466 - accuracy: 0.9610 - val_loss: 0.0915 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0306 - accuracy: 0.9740 - val_loss: 0.0961 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0223 - accuracy: 0.9740 - val_loss: 0.1112 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9805 - val_loss: 0.0994 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 8/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0164 - accuracy: 0.9693\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0163 - accuracy: 0.9697 - val_loss: 0.1300 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0130 - accuracy: 0.9675 - val_loss: 0.1216 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9740 - val_loss: 0.1347 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0100 - accuracy: 0.9781Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9762 - val_loss: 0.1426 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1115 - accuracy: 0.8918 - val_loss: 0.0601 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0647 - accuracy: 0.9459 - val_loss: 0.0802 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0329 - accuracy: 0.9762 - val_loss: 0.0692 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0279 - accuracy: 0.9784 - val_loss: 0.0803 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0249 - accuracy: 0.9805 - val_loss: 0.1088 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0275 - accuracy: 0.9719 - val_loss: 0.1614 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9805 - val_loss: 0.2110 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0142 - accuracy: 0.9821\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0138 - accuracy: 0.9805 - val_loss: 0.1661 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0218 - accuracy: 0.9719 - val_loss: 0.1520 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0056 - accuracy: 0.9805 - val_loss: 0.1678 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 11/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0089 - accuracy: 0.9842Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0086 - accuracy: 0.9827 - val_loss: 0.1641 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0798 - accuracy: 0.9330 - val_loss: 0.0303 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0532 - accuracy: 0.9611 - val_loss: 0.0427 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0328 - accuracy: 0.9633 - val_loss: 0.0405 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0344 - accuracy: 0.9611 - val_loss: 0.0541 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0271 - accuracy: 0.9762 - val_loss: 0.0550 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0213 - accuracy: 0.9741 - val_loss: 0.0787 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0148 - accuracy: 0.9741 - val_loss: 0.0892 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0194 - accuracy: 0.9784 - val_loss: 0.1493 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0168 - accuracy: 0.9757\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0169 - accuracy: 0.9762 - val_loss: 0.1372 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0155 - accuracy: 0.9762 - val_loss: 0.1176 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0131 - accuracy: 0.9827 - val_loss: 0.1174 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12/30\n","102/116 [=========================>....] - ETA: 0s - loss: 0.0053 - accuracy: 0.9828Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9849 - val_loss: 0.1247 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 10ms/step - loss: 0.0515 - accuracy: 0.9590 - val_loss: 0.0189 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0384 - accuracy: 0.9611 - val_loss: 0.0329 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0268 - accuracy: 0.9698 - val_loss: 0.0363 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0215 - accuracy: 0.9762 - val_loss: 0.0430 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0167 - accuracy: 0.9719 - val_loss: 0.0365 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0172 - accuracy: 0.9741 - val_loss: 0.0538 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0143 - accuracy: 0.9741 - val_loss: 0.0605 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 8/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0125 - accuracy: 0.9714\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9741 - val_loss: 0.0958 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0077 - accuracy: 0.9784 - val_loss: 0.0828 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0053 - accuracy: 0.9849 - val_loss: 0.0818 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 0.9801Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0054 - accuracy: 0.9806 - val_loss: 0.0915 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Average Accuracy:  0.8343478260869566\n","Accuracy:  0.9520389805097448\n","Average Normalized Accuracy:  0.8516491754122939\n","Average Precision:  0.8842955982708982\n","Average Recall:  0.8542149570382176\n","F1 score: 0.8689950419676918\n","Grand Mean: 0.8742569298809671\n"]}]},{"cell_type":"markdown","source":["BiGram S2G LSTM"],"metadata":{"id":"TEHMi0KjPZES"}},{"cell_type":"markdown","source":["**Bi-gram+S3G Matrix Model**"],"metadata":{"id":"7vhvyvRfRpPq"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s3g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s3g_matrix_2g'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s3g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s3g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OF2NztRJgdeK","executionInfo":{"status":"ok","timestamp":1697877039528,"user_tz":-330,"elapsed":46426,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"377a9bc8-b0e1-4d0b-e092-ef481ee640ae"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5360 - accuracy: 0.3355 - val_loss: 0.4267 - val_accuracy: 0.3534 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.3765 - accuracy: 0.5584 - val_loss: 0.4109 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2543 - accuracy: 0.7576 - val_loss: 0.4406 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.1487 - accuracy: 0.9004 - val_loss: 0.4969 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0919 - accuracy: 0.9286 - val_loss: 0.6099 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0534 - accuracy: 0.9654 - val_loss: 0.7419 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0334 - accuracy: 0.9567 - val_loss: 0.8274 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0339 - accuracy: 0.9675 - val_loss: 0.8452 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0201 - accuracy: 0.9762 - val_loss: 0.8847 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0137 - accuracy: 0.9719 - val_loss: 0.9932 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 11/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0156 - accuracy: 0.9860\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0154 - accuracy: 0.9827 - val_loss: 0.9846 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0129 - accuracy: 0.9805 - val_loss: 1.0054 - val_accuracy: 0.3879 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0095 - accuracy: 0.9784 - val_loss: 1.0360 - val_accuracy: 0.4052 - lr: 5.0000e-04\n","Epoch 14/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0069 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9762 - val_loss: 1.0904 - val_accuracy: 0.4052 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.2156 - accuracy: 0.8139 - val_loss: 0.0837 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0836 - accuracy: 0.9329 - val_loss: 0.0837 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0489 - accuracy: 0.9545 - val_loss: 0.1020 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0349 - accuracy: 0.9654 - val_loss: 0.1282 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0219 - accuracy: 0.9719 - val_loss: 0.1510 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9848 - val_loss: 0.1516 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0158 - accuracy: 0.9805 - val_loss: 0.1686 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 8/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9759\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9762 - val_loss: 0.2317 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9784 - val_loss: 0.2081 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0048 - accuracy: 0.9870 - val_loss: 0.2027 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 11/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0025 - accuracy: 0.9810Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0026 - accuracy: 0.9827 - val_loss: 0.2213 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1246 - accuracy: 0.9069 - val_loss: 0.0627 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9719 - val_loss: 0.0577 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9784 - val_loss: 0.0913 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0260 - accuracy: 0.9805 - val_loss: 0.0956 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0156 - accuracy: 0.9870 - val_loss: 0.1013 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0183 - accuracy: 0.9740 - val_loss: 0.0962 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0095 - accuracy: 0.9848 - val_loss: 0.1104 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 8/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0127 - accuracy: 0.9836\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0121 - accuracy: 0.9827 - val_loss: 0.1302 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9827 - val_loss: 0.1225 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0044 - accuracy: 0.9913 - val_loss: 0.1502 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 11/30\n","101/116 [=========================>....] - ETA: 0s - loss: 0.0032 - accuracy: 0.9926Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0030 - accuracy: 0.9848 - val_loss: 0.1541 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0769 - accuracy: 0.9158 - val_loss: 0.0345 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0456 - accuracy: 0.9654 - val_loss: 0.0440 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0205 - accuracy: 0.9784 - val_loss: 0.0458 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0144 - accuracy: 0.9762 - val_loss: 0.0448 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0201 - accuracy: 0.9849 - val_loss: 0.0502 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0144 - accuracy: 0.9892 - val_loss: 0.0476 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0100 - accuracy: 0.9827 - val_loss: 0.1034 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0070 - accuracy: 0.9892\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0070 - accuracy: 0.9892 - val_loss: 0.0862 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0170 - accuracy: 0.9762 - val_loss: 0.0771 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0066 - accuracy: 0.9827 - val_loss: 0.0756 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 11/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0043 - accuracy: 0.9842Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0042 - accuracy: 0.9849 - val_loss: 0.0749 - val_accuracy: 0.9565 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 6ms/step - loss: 0.0520 - accuracy: 0.9633 - val_loss: 0.0476 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0317 - accuracy: 0.9762 - val_loss: 0.0405 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0182 - accuracy: 0.9698 - val_loss: 0.0552 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0176 - accuracy: 0.9806 - val_loss: 0.0326 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0119 - accuracy: 0.9762 - val_loss: 0.0547 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0117 - accuracy: 0.9762 - val_loss: 0.0965 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9719 - val_loss: 0.0826 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0080 - accuracy: 0.9827 - val_loss: 0.0848 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0111 - accuracy: 0.9784 - val_loss: 0.1039 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9849 - val_loss: 0.1209 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0138 - accuracy: 0.9779\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0135 - accuracy: 0.9784 - val_loss: 0.2147 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0139 - accuracy: 0.9719 - val_loss: 0.2079 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0051 - accuracy: 0.9806 - val_loss: 0.2309 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0036 - accuracy: 0.9806Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0036 - accuracy: 0.9806 - val_loss: 0.1829 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Average Accuracy:  0.8222638680659671\n","Accuracy:  0.9513493253373309\n","Average Normalized Accuracy:  0.8378260869565217\n","Average Precision:  0.8800033344922598\n","Average Recall:  0.8457428888892855\n","F1 score: 0.8625330332606388\n","Grand Mean: 0.8666197561670006\n"]}]},{"cell_type":"markdown","source":["**Bi-gram+S4G Matrix Model**"],"metadata":{"id":"3wvWQpl5Tepc"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s4g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s4g_matrix_2g'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s4g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s4g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s4g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qPlyExNgSzqw","executionInfo":{"status":"ok","timestamp":1697877077876,"user_tz":-330,"elapsed":38386,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"956bec4c-7b65-4807-a799-ba39a70f5b93"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.5206 - accuracy: 0.3550 - val_loss: 0.4322 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.3692 - accuracy: 0.5931 - val_loss: 0.4348 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2587 - accuracy: 0.7359 - val_loss: 0.4364 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1651 - accuracy: 0.8636 - val_loss: 0.5310 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1003 - accuracy: 0.9134 - val_loss: 0.5856 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0656 - accuracy: 0.9610 - val_loss: 0.6547 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0353 - accuracy: 0.9719 - val_loss: 0.7359 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0257 - accuracy: 0.9762 - val_loss: 0.8233 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0212 - accuracy: 0.9740 - val_loss: 0.9868 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 10/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0232 - accuracy: 0.9670\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0229 - accuracy: 0.9654 - val_loss: 0.9273 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0136 - accuracy: 0.9848 - val_loss: 0.9676 - val_accuracy: 0.4397 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0104 - accuracy: 0.9740 - val_loss: 0.9760 - val_accuracy: 0.4483 - lr: 5.0000e-04\n","Epoch 13/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9781Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9762 - val_loss: 1.0621 - val_accuracy: 0.4310 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.2461 - accuracy: 0.7771 - val_loss: 0.1964 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.1415 - accuracy: 0.8831 - val_loss: 0.2136 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9264 - val_loss: 0.2393 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0524 - accuracy: 0.9654 - val_loss: 0.2472 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0310 - accuracy: 0.9697 - val_loss: 0.3022 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0158 - accuracy: 0.9762 - val_loss: 0.3716 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0083 - accuracy: 0.9762 - val_loss: 0.4478 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 8/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0077 - accuracy: 0.9794\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0078 - accuracy: 0.9805 - val_loss: 0.4851 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9827 - val_loss: 0.4531 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0091 - accuracy: 0.9740 - val_loss: 0.4399 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 11/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0066 - accuracy: 0.9811Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0064 - accuracy: 0.9805 - val_loss: 0.4582 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1828 - accuracy: 0.8398 - val_loss: 0.1176 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0869 - accuracy: 0.9416 - val_loss: 0.1300 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0548 - accuracy: 0.9567 - val_loss: 0.1364 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0408 - accuracy: 0.9719 - val_loss: 0.1294 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0266 - accuracy: 0.9805 - val_loss: 0.2164 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0220 - accuracy: 0.9827 - val_loss: 0.2076 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0111 - accuracy: 0.9870 - val_loss: 0.2073 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 8/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0109 - accuracy: 0.9794\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0104 - accuracy: 0.9805 - val_loss: 0.2644 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9827 - val_loss: 0.2589 - val_accuracy: 0.7759 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9827 - val_loss: 0.2812 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0050 - accuracy: 0.9826Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0050 - accuracy: 0.9827 - val_loss: 0.2792 - val_accuracy: 0.7586 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1138 - accuracy: 0.9050 - val_loss: 0.0596 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0632 - accuracy: 0.9633 - val_loss: 0.0698 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0392 - accuracy: 0.9762 - val_loss: 0.0715 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0365 - accuracy: 0.9719 - val_loss: 0.0921 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0282 - accuracy: 0.9741 - val_loss: 0.1322 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9741 - val_loss: 0.1417 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0190 - accuracy: 0.9698 - val_loss: 0.1626 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 8/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0214 - accuracy: 0.9797\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0206 - accuracy: 0.9806 - val_loss: 0.1627 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9806 - val_loss: 0.1623 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0068 - accuracy: 0.9784 - val_loss: 0.1509 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9827 - val_loss: 0.1563 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 6ms/step - loss: 0.0798 - accuracy: 0.9352 - val_loss: 0.0435 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0504 - accuracy: 0.9590 - val_loss: 0.0482 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0228 - accuracy: 0.9784 - val_loss: 0.0558 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0180 - accuracy: 0.9654 - val_loss: 0.0710 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0170 - accuracy: 0.9870 - val_loss: 0.0676 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.9762 - val_loss: 0.0768 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9806 - val_loss: 0.1100 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0113 - accuracy: 0.9784 - val_loss: 0.1366 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0094 - accuracy: 0.9892 - val_loss: 0.1333 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 10/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0072 - accuracy: 0.9777\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0073 - accuracy: 0.9784 - val_loss: 0.1526 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9762 - val_loss: 0.1470 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0066 - accuracy: 0.9827 - val_loss: 0.1251 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 13/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0041 - accuracy: 0.9781Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0041 - accuracy: 0.9784 - val_loss: 0.1485 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","Average Accuracy:  0.7221289355322339\n","Accuracy:  0.9261379310344824\n","Average Normalized Accuracy:  0.7474887556221889\n","Average Precision:  0.8450171151459754\n","Average Recall:  0.7556278582085181\n","F1 score: 0.7978264805706943\n","Grand Mean: 0.7990378460190155\n"]}]},{"cell_type":"markdown","source":["**Tri-gram+S0G Matrix Model**"],"metadata":{"id":"VuYRONGOWbLM"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s0g_3g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_matrix_3gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_3g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_3g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BSP0DWeWhKYt","executionInfo":{"status":"ok","timestamp":1697877122077,"user_tz":-330,"elapsed":44217,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"a612a653-8bf0-4916-8760-95b823843313"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4882 - accuracy: 0.4221 - val_loss: 0.4500 - val_accuracy: 0.3017 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4168 - accuracy: 0.4589 - val_loss: 0.3760 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3908 - accuracy: 0.5390 - val_loss: 0.3820 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3559 - accuracy: 0.5909 - val_loss: 0.3691 - val_accuracy: 0.4397 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3240 - accuracy: 0.6212 - val_loss: 0.3647 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2971 - accuracy: 0.6580 - val_loss: 0.4141 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2770 - accuracy: 0.6905 - val_loss: 0.3751 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2353 - accuracy: 0.7576 - val_loss: 0.4484 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2477 - accuracy: 0.7251 - val_loss: 0.4029 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2112 - accuracy: 0.7944 - val_loss: 0.4155 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1757 - accuracy: 0.8420 - val_loss: 0.3833 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1543 - accuracy: 0.8550 - val_loss: 0.4890 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1344 - accuracy: 0.8723 - val_loss: 0.4430 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1050 - accuracy: 0.9221 - val_loss: 0.5048 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0953 - accuracy: 0.9199 - val_loss: 0.5355 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0805 - accuracy: 0.9307 - val_loss: 0.5874 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9156 - val_loss: 0.5991 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 18/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0522 - accuracy: 0.9615\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0515 - accuracy: 0.9567 - val_loss: 0.6416 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9610 - val_loss: 0.6104 - val_accuracy: 0.5776 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0267 - accuracy: 0.9632 - val_loss: 0.6524 - val_accuracy: 0.5603 - lr: 5.0000e-04\n","Epoch 21/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0160 - accuracy: 0.9792Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9784 - val_loss: 0.7392 - val_accuracy: 0.5862 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.2433 - accuracy: 0.7900 - val_loss: 0.1509 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.1834 - accuracy: 0.8312 - val_loss: 0.1504 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1586 - accuracy: 0.8398 - val_loss: 0.1464 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1329 - accuracy: 0.8701 - val_loss: 0.1392 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.8939 - val_loss: 0.1482 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0978 - accuracy: 0.8961 - val_loss: 0.1512 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0906 - accuracy: 0.9069 - val_loss: 0.1695 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 8/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0689 - accuracy: 0.9404\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0705 - accuracy: 0.9416 - val_loss: 0.1386 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0439 - accuracy: 0.9567 - val_loss: 0.1713 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0322 - accuracy: 0.9654 - val_loss: 0.1595 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 11/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0231 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0238 - accuracy: 0.9740 - val_loss: 0.2146 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2066 - accuracy: 0.7771 - val_loss: 0.1091 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1610 - accuracy: 0.8485 - val_loss: 0.1371 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1414 - accuracy: 0.8550 - val_loss: 0.1307 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1278 - accuracy: 0.8810 - val_loss: 0.1237 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1001 - accuracy: 0.9242 - val_loss: 0.1107 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0862 - accuracy: 0.9177 - val_loss: 0.1156 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0868 - accuracy: 0.9264 - val_loss: 0.1239 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 8/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0601 - accuracy: 0.9500\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0596 - accuracy: 0.9502 - val_loss: 0.1683 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0498 - accuracy: 0.9545 - val_loss: 0.1077 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0316 - accuracy: 0.9784 - val_loss: 0.1396 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0191 - accuracy: 0.9848Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0191 - accuracy: 0.9848 - val_loss: 0.1270 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.8121 - val_loss: 0.1036 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.1464 - accuracy: 0.8596 - val_loss: 0.0836 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1341 - accuracy: 0.8834 - val_loss: 0.0778 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0965 - accuracy: 0.9006 - val_loss: 0.0798 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0731 - accuracy: 0.9287 - val_loss: 0.0741 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1136 - accuracy: 0.8920 - val_loss: 0.0923 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0698 - accuracy: 0.9309 - val_loss: 0.1573 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0626 - accuracy: 0.9417 - val_loss: 0.0912 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0898 - accuracy: 0.9093 - val_loss: 0.1099 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9525\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0530 - accuracy: 0.9525 - val_loss: 0.0990 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0279 - accuracy: 0.9784 - val_loss: 0.1285 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0180 - accuracy: 0.9784 - val_loss: 0.1093 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 13/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0212 - accuracy: 0.9759Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0211 - accuracy: 0.9762 - val_loss: 0.1108 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 9ms/step - loss: 0.1099 - accuracy: 0.9006 - val_loss: 0.1195 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0835 - accuracy: 0.9222 - val_loss: 0.1366 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0797 - accuracy: 0.9244 - val_loss: 0.1121 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0888 - accuracy: 0.9330 - val_loss: 0.1234 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0529 - accuracy: 0.9525 - val_loss: 0.1518 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0614 - accuracy: 0.9417 - val_loss: 0.1626 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0391 - accuracy: 0.9719 - val_loss: 0.1835 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 8/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0335 - accuracy: 0.9518\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0330 - accuracy: 0.9525 - val_loss: 0.2137 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0314 - accuracy: 0.9654 - val_loss: 0.1230 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0149 - accuracy: 0.9849 - val_loss: 0.1586 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 11/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0144 - accuracy: 0.9773Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0141 - accuracy: 0.9762 - val_loss: 0.1762 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Average Accuracy:  0.7926986506746626\n","Accuracy:  0.9388425787106442\n","Average Normalized Accuracy:  0.8097101449275362\n","Average Precision:  0.8967798429819893\n","Average Recall:  0.7946488402282457\n","F1 score: 0.8426309299818476\n","Grand Mean: 0.8458851645841543\n"]}]},{"cell_type":"markdown","source":["**Tri-gram+S1G Matrix Model**"],"metadata":{"id":"JwLYGoZdXDtI"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s1g_3g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_matrix_3gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g_3g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_3g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"brTvSHmRXMjt","executionInfo":{"status":"ok","timestamp":1697877170488,"user_tz":-330,"elapsed":48437,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"55dc5bb3-bfce-4b9e-b3b6-b999f4ad3275"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4745 - accuracy: 0.3745 - val_loss: 0.3835 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.3960 - accuracy: 0.5390 - val_loss: 0.3601 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3289 - accuracy: 0.6753 - val_loss: 0.3776 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2599 - accuracy: 0.7424 - val_loss: 0.3689 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2146 - accuracy: 0.7792 - val_loss: 0.4384 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1589 - accuracy: 0.8571 - val_loss: 0.4444 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1321 - accuracy: 0.8918 - val_loss: 0.5031 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 8/30\n","100/116 [========================>.....] - ETA: 0s - loss: 0.0865 - accuracy: 0.9325\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0881 - accuracy: 0.9286 - val_loss: 0.5274 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0495 - accuracy: 0.9632 - val_loss: 0.4999 - val_accuracy: 0.5776 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0305 - accuracy: 0.9697 - val_loss: 0.5806 - val_accuracy: 0.5259 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0203 - accuracy: 0.9827 - val_loss: 0.6132 - val_accuracy: 0.5345 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9762 - val_loss: 0.6024 - val_accuracy: 0.5517 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0164 - accuracy: 0.9719 - val_loss: 0.6417 - val_accuracy: 0.5259 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0138 - accuracy: 0.9762 - val_loss: 0.7175 - val_accuracy: 0.5086 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0158 - accuracy: 0.9719 - val_loss: 0.7691 - val_accuracy: 0.5086 - lr: 5.0000e-04\n","Epoch 16/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0128 - accuracy: 0.9882\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0125 - accuracy: 0.9892 - val_loss: 0.6834 - val_accuracy: 0.5517 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0086 - accuracy: 0.9697 - val_loss: 0.7143 - val_accuracy: 0.5345 - lr: 2.5000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0108 - accuracy: 0.9784 - val_loss: 0.7499 - val_accuracy: 0.5172 - lr: 2.5000e-04\n","Epoch 19/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0062 - accuracy: 0.9808Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0060 - accuracy: 0.9827 - val_loss: 0.7902 - val_accuracy: 0.5086 - lr: 2.5000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.1795 - accuracy: 0.8420 - val_loss: 0.0519 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0928 - accuracy: 0.9156 - val_loss: 0.0629 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0573 - accuracy: 0.9481 - val_loss: 0.0427 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0559 - accuracy: 0.9481 - val_loss: 0.0960 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0391 - accuracy: 0.9632 - val_loss: 0.1222 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0228 - accuracy: 0.9762 - val_loss: 0.1169 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0334 - accuracy: 0.9632 - val_loss: 0.1249 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 8/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0605 - accuracy: 0.9403\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0596 - accuracy: 0.9416 - val_loss: 0.0951 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0178 - accuracy: 0.9762 - val_loss: 0.0828 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0102 - accuracy: 0.9784 - val_loss: 0.0764 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 11/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9750Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9762 - val_loss: 0.1058 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1231 - accuracy: 0.8680 - val_loss: 0.0717 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0734 - accuracy: 0.9351 - val_loss: 0.0335 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0542 - accuracy: 0.9524 - val_loss: 0.0419 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0341 - accuracy: 0.9740 - val_loss: 0.0750 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0559 - accuracy: 0.9502 - val_loss: 0.0736 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0230 - accuracy: 0.9784 - val_loss: 0.0460 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9848 - val_loss: 0.0446 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 8/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9735\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0206 - accuracy: 0.9719 - val_loss: 0.4670 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0297 - accuracy: 0.9697 - val_loss: 0.0486 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0082 - accuracy: 0.9848 - val_loss: 0.0695 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0084 - accuracy: 0.9825Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0082 - accuracy: 0.9827 - val_loss: 0.0420 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 2s 4ms/step - loss: 0.0780 - accuracy: 0.9158 - val_loss: 0.0646 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0544 - accuracy: 0.9654 - val_loss: 0.0319 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0423 - accuracy: 0.9611 - val_loss: 0.0491 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0308 - accuracy: 0.9654 - val_loss: 0.0184 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0205 - accuracy: 0.9698 - val_loss: 0.0173 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0241 - accuracy: 0.9806 - val_loss: 0.0424 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0166 - accuracy: 0.9806 - val_loss: 0.0205 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9827 - val_loss: 0.0277 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0394 - accuracy: 0.9590 - val_loss: 0.0707 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0246 - accuracy: 0.9611 - val_loss: 0.0651 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0131 - accuracy: 0.9914 - val_loss: 0.0343 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 0.9654 - val_loss: 0.0606 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0069 - accuracy: 0.9827 - val_loss: 0.0312 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 14/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0029 - accuracy: 0.9813\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0029 - accuracy: 0.9827 - val_loss: 0.0299 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9870 - val_loss: 0.0319 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0018 - accuracy: 0.9892 - val_loss: 0.0331 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 17/30\n","101/116 [=========================>....] - ETA: 0s - loss: 0.0025 - accuracy: 0.9876Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0024 - accuracy: 0.9870 - val_loss: 0.0359 - val_accuracy: 0.9826 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 7ms/step - loss: 0.0286 - accuracy: 0.9698 - val_loss: 0.0323 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0301 - accuracy: 0.9741 - val_loss: 0.0406 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0099 - accuracy: 0.9892 - val_loss: 0.0107 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0676 - accuracy: 0.9482 - val_loss: 0.0343 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0388 - accuracy: 0.9611 - val_loss: 0.0505 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0121 - accuracy: 0.9762 - val_loss: 0.0483 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9870 - val_loss: 0.0461 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0061 - accuracy: 0.9849 - val_loss: 0.0556 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0033 - accuracy: 0.9827 - val_loss: 0.0427 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0015 - accuracy: 0.9870 - val_loss: 0.0453 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 11/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0011 - accuracy: 0.9884\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9870 - val_loss: 0.0407 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0015 - accuracy: 0.9870 - val_loss: 0.0281 - val_accuracy: 0.9826 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0044 - accuracy: 0.9806 - val_loss: 0.0280 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 14/30\n"," 97/116 [========================>.....] - ETA: 0s - loss: 6.6335e-04 - accuracy: 0.9820Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 3ms/step - loss: 6.0699e-04 - accuracy: 0.9849 - val_loss: 0.0306 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Average Accuracy:  0.8532833583208397\n","Accuracy:  0.954446776611694\n","Average Normalized Accuracy:  0.8751924037981011\n","Average Precision:  0.8872026346659112\n","Average Recall:  0.8796308563233888\n","F1 score: 0.8834005210378575\n","Grand Mean: 0.8888594251262987\n"]}]},{"cell_type":"markdown","source":["**Tri-gram+S2G Matrix Model**"],"metadata":{"id":"s_Kb6S7hXsVP"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s2g_3g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_matrix_3gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g_3g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g_3g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g_3g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Gm4eVlRXyxC","executionInfo":{"status":"ok","timestamp":1697877219735,"user_tz":-330,"elapsed":49287,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"6c766dac-bb58-4291-c811-36d6d478e6ca"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.5045 - accuracy: 0.3571 - val_loss: 0.3954 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3178 - accuracy: 0.6450 - val_loss: 0.3947 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2182 - accuracy: 0.7900 - val_loss: 0.4159 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1336 - accuracy: 0.8918 - val_loss: 0.4370 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0770 - accuracy: 0.9459 - val_loss: 0.4962 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0563 - accuracy: 0.9567 - val_loss: 0.5356 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0480 - accuracy: 0.9610 - val_loss: 0.6875 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0290 - accuracy: 0.9675 - val_loss: 0.7011 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0211 - accuracy: 0.9740 - val_loss: 0.6952 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0256 - accuracy: 0.9762 - val_loss: 0.6148 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0178 - accuracy: 0.9805 - val_loss: 0.7017 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 12/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0596 - accuracy: 0.9450\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0596 - accuracy: 0.9416 - val_loss: 0.7645 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0175 - accuracy: 0.9848 - val_loss: 0.7170 - val_accuracy: 0.5345 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9784 - val_loss: 0.7816 - val_accuracy: 0.5000 - lr: 5.0000e-04\n","Epoch 15/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0055 - accuracy: 0.9841Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0053 - accuracy: 0.9848 - val_loss: 0.7806 - val_accuracy: 0.5431 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.8247 - val_loss: 0.0570 - val_accuracy: 0.9828 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0779 - accuracy: 0.9416 - val_loss: 0.0677 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0408 - accuracy: 0.9632 - val_loss: 0.0550 - val_accuracy: 0.9741 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0339 - accuracy: 0.9610 - val_loss: 0.0773 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0373 - accuracy: 0.9719 - val_loss: 0.1040 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0370 - accuracy: 0.9481 - val_loss: 0.0992 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0133 - accuracy: 0.9762 - val_loss: 0.0898 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 8/30\n"," 99/116 [========================>.....] - ETA: 0s - loss: 0.0129 - accuracy: 0.9747\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0118 - accuracy: 0.9762 - val_loss: 0.1123 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0065 - accuracy: 0.9762 - val_loss: 0.1043 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0052 - accuracy: 0.9784 - val_loss: 0.1105 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0082 - accuracy: 0.9754Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0079 - accuracy: 0.9762 - val_loss: 0.1141 - val_accuracy: 0.9224 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1037 - accuracy: 0.9069 - val_loss: 0.0657 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0493 - accuracy: 0.9589 - val_loss: 0.0476 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0352 - accuracy: 0.9697 - val_loss: 0.0735 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0301 - accuracy: 0.9697 - val_loss: 0.0389 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0164 - accuracy: 0.9848 - val_loss: 0.0668 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0130 - accuracy: 0.9762 - val_loss: 0.0742 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0113 - accuracy: 0.9892 - val_loss: 0.0654 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0403 - accuracy: 0.9719 - val_loss: 0.0446 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0140 - accuracy: 0.9762 - val_loss: 0.0904 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0079 - accuracy: 0.9913 - val_loss: 0.0725 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0081 - accuracy: 0.9762 - val_loss: 0.0966 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0047 - accuracy: 0.9870 - val_loss: 0.1194 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0127 - accuracy: 0.9762 - val_loss: 0.1896 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0184 - accuracy: 0.9784 - val_loss: 0.1953 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 15/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0119 - accuracy: 0.9889\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0137 - accuracy: 0.9848 - val_loss: 0.1801 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0068 - accuracy: 0.9827 - val_loss: 0.1669 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0027 - accuracy: 0.9957 - val_loss: 0.1555 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 18/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.0048 - accuracy: 0.9883Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0046 - accuracy: 0.9870 - val_loss: 0.1792 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9590 - val_loss: 0.0061 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0236 - accuracy: 0.9762 - val_loss: 0.0056 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9784 - val_loss: 0.0095 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0150 - accuracy: 0.9849 - val_loss: 0.0131 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0110 - accuracy: 0.9870 - val_loss: 0.0114 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0065 - accuracy: 0.9914 - val_loss: 0.0235 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0078 - accuracy: 0.9784 - val_loss: 0.0202 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0021 - accuracy: 0.9849 - val_loss: 0.0268 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9870 - val_loss: 0.0199 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 10/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0033 - accuracy: 0.9887    \n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0055 - accuracy: 0.9870 - val_loss: 0.0418 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0028 - accuracy: 0.9849 - val_loss: 0.0189 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 7.0421e-04 - accuracy: 0.9870 - val_loss: 0.0180 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 13/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0010 - accuracy: 0.9848Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0010 - accuracy: 0.9849 - val_loss: 0.0172 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 7ms/step - loss: 0.0260 - accuracy: 0.9849 - val_loss: 0.0015 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0278 - accuracy: 0.9676 - val_loss: 0.0061 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0111 - accuracy: 0.9849 - val_loss: 0.0092 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0125 - accuracy: 0.9741 - val_loss: 0.0099 - val_accuracy: 1.0000 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0095 - accuracy: 0.9719 - val_loss: 0.0035 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0023 - accuracy: 0.9849 - val_loss: 0.0017 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0036 - accuracy: 0.9914 - val_loss: 0.0035 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9698 - val_loss: 0.0046 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.0032 - accuracy: 0.9762 - val_loss: 0.0109 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0565 - accuracy: 0.9525 - val_loss: 0.0769 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 11/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0073 - accuracy: 0.9817\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0071 - accuracy: 0.9784 - val_loss: 0.0455 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0013 - accuracy: 0.9762 - val_loss: 0.0459 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0031 - accuracy: 0.9827 - val_loss: 0.0444 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 14/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0012 - accuracy: 0.9784Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0012 - accuracy: 0.9806 - val_loss: 0.0438 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Average Accuracy:  0.8758020989505247\n","Accuracy:  0.9624017991004494\n","Average Normalized Accuracy:  0.8922113943028485\n","Average Precision:  0.9199856033224281\n","Average Recall:  0.8912295047928032\n","F1 score: 0.9053792782446156\n","Grand Mean: 0.9078349464522782\n"]}]},{"cell_type":"markdown","source":["TriGram S2G -LSTM"],"metadata":{"id":"ZCm1bq-Jadvu"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_lstms = keras.Sequential([\n","    keras.layers.Input(shape=(400,1)),\n","    keras.layers.LSTM(256, return_sequences=True, kernel_initializer = 'he_normal'),\n","    keras.layers.LSTM(128, return_sequences=True, kernel_initializer = 'he_normal'),  # Another LSTM layer with 64 units\n","    keras.layers.Flatten(),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(64, activation='relu', kernel_initializer = 'he_normal'),     # Fully connected layer\n","    keras.layers.Dense(5, activation='sigmoid')    # Output layer with sigmoid activation for multi-label classification\n","])\n","\n","train_features = np.array(df['s2g_matrix_3gram'].tolist())\n","train_features = train_features.reshape(-1, 400,1)\n","\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_lstms.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_lstms.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_lstms.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qK46j2M7agpE","executionInfo":{"status":"ok","timestamp":1697883686876,"user_tz":-330,"elapsed":414686,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"225a1b33-8e7d-4a27-e315-736f8c1658cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 15s 47ms/step - loss: 0.5219 - accuracy: 0.3680 - val_loss: 0.3846 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.3702 - accuracy: 0.5498 - val_loss: 0.4314 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.2597 - accuracy: 0.7489 - val_loss: 0.4195 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.1666 - accuracy: 0.8723 - val_loss: 0.6117 - val_accuracy: 0.4052 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.0665 - accuracy: 0.9524 - val_loss: 0.5916 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0390 - accuracy: 0.9654 - val_loss: 0.7482 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0244 - accuracy: 0.9697 - val_loss: 0.7408 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0111 - accuracy: 0.9783\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 5s 47ms/step - loss: 0.0111 - accuracy: 0.9762 - val_loss: 0.8186 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0028 - accuracy: 0.9675 - val_loss: 0.8635 - val_accuracy: 0.5259 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0013 - accuracy: 0.9740 - val_loss: 0.8761 - val_accuracy: 0.5259 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 9.8694e-04 - accuracy: 0.9719Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 5s 43ms/step - loss: 9.8694e-04 - accuracy: 0.9719 - val_loss: 0.9121 - val_accuracy: 0.4914 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 1s 13ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 10s 46ms/step - loss: 0.3973 - accuracy: 0.5216 - val_loss: 0.4233 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 5s 43ms/step - loss: 0.2799 - accuracy: 0.7121 - val_loss: 0.4212 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.1543 - accuracy: 0.8680 - val_loss: 0.4971 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0846 - accuracy: 0.9394 - val_loss: 0.6437 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 5s 45ms/step - loss: 0.0457 - accuracy: 0.9719 - val_loss: 0.7088 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0198 - accuracy: 0.9675 - val_loss: 0.7616 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0055 - accuracy: 0.9805 - val_loss: 0.8728 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 5s 44ms/step - loss: 0.0074 - accuracy: 0.9675 - val_loss: 0.7984 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0059 - accuracy: 0.9784 - val_loss: 0.8439 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.0030 - accuracy: 0.9762 - val_loss: 0.9157 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.0029 - accuracy: 0.9784 - val_loss: 1.0424 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0041 - accuracy: 0.9827 - val_loss: 0.9743 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 4s 37ms/step - loss: 4.9057e-04 - accuracy: 0.9740 - val_loss: 0.9845 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 5s 43ms/step - loss: 0.0020 - accuracy: 0.9762 - val_loss: 0.9828 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 4s 39ms/step - loss: 1.8212e-04 - accuracy: 0.9762 - val_loss: 1.0112 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 4s 39ms/step - loss: 1.2438e-04 - accuracy: 0.9762 - val_loss: 1.0313 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 5s 44ms/step - loss: 1.0319e-04 - accuracy: 0.9740 - val_loss: 1.0431 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 4s 37ms/step - loss: 8.3561e-05 - accuracy: 0.9762 - val_loss: 1.0518 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 4s 38ms/step - loss: 7.0676e-05 - accuracy: 0.9784 - val_loss: 1.0655 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 5s 43ms/step - loss: 6.2756e-05 - accuracy: 0.9762 - val_loss: 1.0799 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 21/30\n","115/116 [============================>.] - ETA: 0s - loss: 5.3641e-05 - accuracy: 0.9739\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 4s 38ms/step - loss: 5.3883e-05 - accuracy: 0.9719 - val_loss: 1.0871 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 4s 37ms/step - loss: 5.1518e-05 - accuracy: 0.9740 - val_loss: 1.0930 - val_accuracy: 0.5690 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 5s 42ms/step - loss: 4.4648e-05 - accuracy: 0.9762 - val_loss: 1.1005 - val_accuracy: 0.5690 - lr: 5.0000e-04\n","Epoch 24/30\n","115/116 [============================>.] - ETA: 0s - loss: 4.1257e-05 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 14.\n","116/116 [==============================] - 4s 38ms/step - loss: 4.1154e-05 - accuracy: 0.9762 - val_loss: 1.1073 - val_accuracy: 0.5603 - lr: 5.0000e-04\n","Epoch 24: early stopping\n","4/4 [==============================] - 1s 13ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 10s 52ms/step - loss: 0.1895 - accuracy: 0.8636 - val_loss: 0.0298 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0289 - accuracy: 0.9675 - val_loss: 0.0184 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0071 - accuracy: 0.9784 - val_loss: 0.0067 - val_accuracy: 0.9655 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 5s 44ms/step - loss: 0.0018 - accuracy: 0.9848 - val_loss: 0.0063 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.0015 - accuracy: 0.9827 - val_loss: 0.0041 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 4s 37ms/step - loss: 8.3039e-04 - accuracy: 0.9805 - val_loss: 0.0067 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 6s 49ms/step - loss: 3.7196e-04 - accuracy: 0.9784 - val_loss: 0.0045 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 4s 38ms/step - loss: 1.8604e-04 - accuracy: 0.9805 - val_loss: 0.0046 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 4s 39ms/step - loss: 1.3807e-04 - accuracy: 0.9805 - val_loss: 0.0041 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - ETA: 0s - loss: 1.0605e-04 - accuracy: 0.9870\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 5s 43ms/step - loss: 1.0605e-04 - accuracy: 0.9870 - val_loss: 0.0038 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 4s 37ms/step - loss: 9.8088e-05 - accuracy: 0.9827 - val_loss: 0.0038 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 4s 37ms/step - loss: 9.2436e-05 - accuracy: 0.9827 - val_loss: 0.0039 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - ETA: 0s - loss: 7.5667e-05 - accuracy: 0.9805Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 5s 42ms/step - loss: 7.5667e-05 - accuracy: 0.9805 - val_loss: 0.0039 - val_accuracy: 0.9569 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 1s 25ms/step\n","Epoch 1/30\n","116/116 [==============================] - 11s 48ms/step - loss: 0.0168 - accuracy: 0.9784 - val_loss: 0.0070 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0235 - accuracy: 0.9741 - val_loss: 0.0297 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 5s 44ms/step - loss: 0.0182 - accuracy: 0.9806 - val_loss: 0.0270 - val_accuracy: 0.9913 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0200 - accuracy: 0.9741 - val_loss: 0.0464 - val_accuracy: 0.9739 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0117 - accuracy: 0.9762 - val_loss: 0.0435 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0092 - accuracy: 0.9806 - val_loss: 0.1088 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0130 - accuracy: 0.9698 - val_loss: 0.1027 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.0141 - accuracy: 0.9741 - val_loss: 0.0869 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.0049 - accuracy: 0.9784 - val_loss: 0.1014 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0011 - accuracy: 0.9698\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0011 - accuracy: 0.9698 - val_loss: 0.0912 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 4s 38ms/step - loss: 6.4268e-04 - accuracy: 0.9719 - val_loss: 0.0717 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 5s 40ms/step - loss: 1.1253e-04 - accuracy: 0.9698 - val_loss: 0.0731 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13/30\n","115/116 [============================>.] - ETA: 0s - loss: 1.1647e-04 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 5s 39ms/step - loss: 1.1610e-04 - accuracy: 0.9676 - val_loss: 0.0743 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 1s 27ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 10s 45ms/step - loss: 0.0194 - accuracy: 0.9806 - val_loss: 0.0178 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0096 - accuracy: 0.9784 - val_loss: 0.0286 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0087 - accuracy: 0.9849 - val_loss: 0.0340 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0148 - accuracy: 0.9741 - val_loss: 0.0866 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0252 - accuracy: 0.9914 - val_loss: 0.0862 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0040 - accuracy: 0.9806 - val_loss: 0.0863 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0258 - accuracy: 0.9741 - val_loss: 0.0651 - val_accuracy: 0.9826 - lr: 0.0010\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0123 - accuracy: 0.9826\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0122 - accuracy: 0.9827 - val_loss: 0.0693 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0062 - accuracy: 0.9806 - val_loss: 0.0573 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 4s 39ms/step - loss: 3.0715e-04 - accuracy: 0.9827 - val_loss: 0.0514 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 1.9063e-04 - accuracy: 0.9848Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 4s 38ms/step - loss: 1.8955e-04 - accuracy: 0.9849 - val_loss: 0.0503 - val_accuracy: 0.9739 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 2s 18ms/step\n","Average Accuracy:  0.6929685157421289\n","Accuracy:  0.9254902548725632\n","Average Normalized Accuracy:  0.7197401299350326\n","Average Precision:  0.8096585395924152\n","Average Recall:  0.7405161915834297\n","F1 score: 0.7735453896441624\n","Grand Mean: 0.776986503561622\n"]}]},{"cell_type":"markdown","source":["TriGram S2G - Random Forest"],"metadata":{"id":"YOtHdAAbcYKs"}},{"cell_type":"code","source":["!pip install xgboost"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_cgPfLANnJ6l","executionInfo":{"status":"ok","timestamp":1697881324675,"user_tz":-330,"elapsed":5765,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"d3a06e73-71a1-468d-f46e-f20d883cbd41"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: xgboost in /usr/local/lib/python3.10/dist-packages (2.0.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from xgboost) (1.11.3)\n"]}]},{"cell_type":"code","source":["import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Define the XGBoost classifier\n","model_xgb = xgb.XGBClassifier()\n","\n","# Load your data and pr0.0.eprocess it\n","train_features = np.array(df['s2g_matrix_3gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Fit the XGBoost model to the training data\n","    model_xgb.fit(X_train, y_train)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_xgb.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rfp1KUpbm895","executionInfo":{"status":"ok","timestamp":1697881393004,"user_tz":-330,"elapsed":55885,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"ab331a02-7142-4f4f-bcdb-289d78ac246f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Average Accuracy:  0.29935532233883055\n","Accuracy:  0.812449775112443\n","Average Normalized Accuracy:  0.3682296351824088\n","Average Precision:  0.5623379979626854\n","Average Recall:  0.3322420263172347\n","F1 score: 0.41769838549365707\n","Grand Mean: 0.4653855237345432\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["TriGram S2G - KNN"],"metadata":{"id":"NSTzXDAsgZZv"}},{"cell_type":"code","source":["def calculate_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    # Initialize accuracy\n","    accuracy = 0\n","\n","    # Calculate accuracy for each instance\n","    for i in range(len(y_true)):\n","        # Calculate intersection and union\n","        intersection = np.sum(np.logical_and(y_true[i], y_pred[i]))\n","        union = np.sum(np.logical_or(y_true[i], y_pred[i]))\n","\n","        # Add to total accuracy\n","        accuracy += intersection / union\n","\n","    # Calculate average accuracy\n","    accuracy /= len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"0853cLvsiG1d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def norm_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array(y_pred)\n","\n","    acc = []\n","    # Loop over each instance\n","    for i in range(len(y_true)):\n","        # Calculate the number of correct predictions for this instance\n","        correct_predictions = np.sum(y_true[i] == y_pred[i])\n","        acc.append(correct_predictions/5)\n","\n","    # Calculate accuracy\n","    accuracy = sum(acc) / len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"Wg2kY0D8jP_8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","\n","# Define the k-NN classifier\n","model_knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_matrix_3gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Fit the k-NN model to the training data\n","    model_knn.fit(X_train, y_train)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_knn.predict(X_test)\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Da9WKSpFgfgS","executionInfo":{"status":"ok","timestamp":1697881149377,"user_tz":-330,"elapsed":769,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"dd3d3e23-ab51-49c1-b702-ed81d5b22261"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Average Accuracy:  0.4048125937031484\n","Accuracy:  0.8041349325337326\n","Average Normalized Accuracy:  0.413768115942029\n","Average Precision:  0.5252258790478929\n","Average Recall:  0.40724235445141643\n","F1 score: 0.45876999541226127\n","Grand Mean: 0.5023256451817467\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["**4-gram on S0G Matrix Model**"],"metadata":{"id":"uF3PmZJcY5_o"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s0g_4g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_matrix_4gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_4g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_4g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_4g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OudLF1YYYkgZ","executionInfo":{"status":"ok","timestamp":1697877680050,"user_tz":-330,"elapsed":54228,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"5bccbf17-b67a-4227-da8f-6ede78967791"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5111 - accuracy: 0.3550 - val_loss: 0.4340 - val_accuracy: 0.2931 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4739 - accuracy: 0.4069 - val_loss: 0.4365 - val_accuracy: 0.3017 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4612 - accuracy: 0.3593 - val_loss: 0.4358 - val_accuracy: 0.3017 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.3939 - val_loss: 0.4234 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4549 - accuracy: 0.3701 - val_loss: 0.4132 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.3831 - val_loss: 0.4282 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.3463 - val_loss: 0.4173 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.4372 - val_loss: 0.4162 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4472 - accuracy: 0.4004 - val_loss: 0.4213 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.3788 - val_loss: 0.4256 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 11/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.4489 - accuracy: 0.3689\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4482 - accuracy: 0.3831 - val_loss: 0.4276 - val_accuracy: 0.2845 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4435 - accuracy: 0.3961 - val_loss: 0.4107 - val_accuracy: 0.4569 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.3766 - val_loss: 0.4131 - val_accuracy: 0.4655 - lr: 5.0000e-04\n","Epoch 14/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.4409 - accuracy: 0.4159Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.4408 - accuracy: 0.4156 - val_loss: 0.4128 - val_accuracy: 0.4655 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 5ms/step - loss: 0.4473 - accuracy: 0.3636 - val_loss: 0.4702 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.3680 - val_loss: 0.4693 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.4156 - val_loss: 0.4789 - val_accuracy: 0.4052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.4026 - val_loss: 0.4615 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4346 - accuracy: 0.4134 - val_loss: 0.4744 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4355 - accuracy: 0.4069 - val_loss: 0.4617 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4364 - accuracy: 0.4069 - val_loss: 0.4662 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4369 - accuracy: 0.3680 - val_loss: 0.4674 - val_accuracy: 0.3707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4373 - accuracy: 0.3723 - val_loss: 0.4675 - val_accuracy: 0.3793 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.4113 - val_loss: 0.4866 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4309 - accuracy: 0.4264 - val_loss: 0.4632 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.4264 - val_loss: 0.4845 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 13/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.4290 - accuracy: 0.4292\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.4113 - val_loss: 0.4693 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.4307 - val_loss: 0.4694 - val_accuracy: 0.3966 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.4156 - val_loss: 0.4677 - val_accuracy: 0.3793 - lr: 5.0000e-04\n","Epoch 16/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.4237 - accuracy: 0.4432Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4239 - accuracy: 0.4481 - val_loss: 0.4693 - val_accuracy: 0.3621 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 2s 7ms/step - loss: 0.4385 - accuracy: 0.4394 - val_loss: 0.4441 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4427 - accuracy: 0.4091 - val_loss: 0.4471 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4345 - accuracy: 0.3896 - val_loss: 0.4591 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4330 - accuracy: 0.4286 - val_loss: 0.4574 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.4416 - val_loss: 0.4544 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4273 - accuracy: 0.4156 - val_loss: 0.4568 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.4286 - val_loss: 0.4470 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 8/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.4292 - accuracy: 0.4286\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4344 - accuracy: 0.4113 - val_loss: 0.4533 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4274 - accuracy: 0.4134 - val_loss: 0.4489 - val_accuracy: 0.3362 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.4221 - val_loss: 0.4507 - val_accuracy: 0.3362 - lr: 5.0000e-04\n","Epoch 11/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.4211 - accuracy: 0.4205Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4229 - accuracy: 0.4199 - val_loss: 0.4505 - val_accuracy: 0.3534 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 6ms/step - loss: 0.4495 - accuracy: 0.3737 - val_loss: 0.4157 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4445 - accuracy: 0.3974 - val_loss: 0.4147 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.3823 - val_loss: 0.4105 - val_accuracy: 0.4870 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.3996 - val_loss: 0.4084 - val_accuracy: 0.4174 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4471 - accuracy: 0.3909 - val_loss: 0.4230 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4437 - accuracy: 0.3952 - val_loss: 0.4069 - val_accuracy: 0.4174 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.4402 - accuracy: 0.4082 - val_loss: 0.4051 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.4423 - accuracy: 0.4212 - val_loss: 0.4109 - val_accuracy: 0.4435 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.4398 - accuracy: 0.4104 - val_loss: 0.4046 - val_accuracy: 0.4609 - lr: 0.0010\n","Epoch 10/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.4400 - accuracy: 0.3929\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.4388 - accuracy: 0.3952 - val_loss: 0.4123 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4372 - accuracy: 0.3974 - val_loss: 0.4083 - val_accuracy: 0.4174 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.4361 - accuracy: 0.4060 - val_loss: 0.4037 - val_accuracy: 0.4435 - lr: 5.0000e-04\n","Epoch 13/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.4339 - accuracy: 0.4018Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.4340 - accuracy: 0.4039 - val_loss: 0.4057 - val_accuracy: 0.4174 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 1s 6ms/step - loss: 0.4321 - accuracy: 0.4255 - val_loss: 0.4438 - val_accuracy: 0.4087 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4373 - accuracy: 0.3780 - val_loss: 0.4441 - val_accuracy: 0.3478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.4514 - val_loss: 0.4566 - val_accuracy: 0.3739 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.4147 - val_loss: 0.4483 - val_accuracy: 0.3130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4314 - accuracy: 0.4212 - val_loss: 0.4441 - val_accuracy: 0.3826 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4322 - accuracy: 0.4298 - val_loss: 0.4461 - val_accuracy: 0.3826 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4300 - accuracy: 0.4471 - val_loss: 0.4470 - val_accuracy: 0.3739 - lr: 0.0010\n","Epoch 8/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.4334 - accuracy: 0.4351\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4321 - accuracy: 0.4298 - val_loss: 0.4486 - val_accuracy: 0.3826 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.4471 - val_loss: 0.4427 - val_accuracy: 0.3826 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.4363 - val_loss: 0.4474 - val_accuracy: 0.3652 - lr: 5.0000e-04\n","Epoch 11/30\n","102/116 [=========================>....] - ETA: 0s - loss: 0.4281 - accuracy: 0.4240Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.4298 - val_loss: 0.4432 - val_accuracy: 0.3739 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 2ms/step\n","Average Accuracy:  0.015547226386806594\n","Accuracy:  0.7923868065967001\n","Average Normalized Accuracy:  0.015547226386806594\n","Average Precision:  0.2729388409272949\n","Average Recall:  0.015058756143244612\n","F1 score: 0.028542734309948223\n","Grand Mean: 0.19000359845846684\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["**4-gram on S1G Matrix Model**"],"metadata":{"id":"j7PYkTzaZg7O"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s1g_4g = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_matrix_4gram'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_4g.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 2\n","    model_s1g_4g.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_4g.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dorQiDUxZgiW","executionInfo":{"status":"ok","timestamp":1697877803703,"user_tz":-330,"elapsed":123688,"user":{"displayName":"GAGAN VADLAMUDI","userId":"07791040563744089753"}},"outputId":"b584fc62-7896-4c6e-8fe7-6a09fe3eca8f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.5021 - accuracy: 0.3550 - val_loss: 0.4304 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 2/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4754 - accuracy: 0.3571 - val_loss: 0.4193 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 3/30\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4709 - accuracy: 0.3571 - val_loss: 0.4342 - val_accuracy: 0.2672 - lr: 0.0010\n","Epoch 4/30\n","231/231 [==============================] - 1s 6ms/step - loss: 0.4575 - accuracy: 0.3961 - val_loss: 0.4271 - val_accuracy: 0.2845 - lr: 0.0010\n","Epoch 5/30\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4626 - accuracy: 0.3745 - val_loss: 0.4454 - val_accuracy: 0.2672 - lr: 0.0010\n","Epoch 6/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4590 - accuracy: 0.3745 - val_loss: 0.4338 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 7/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4541 - accuracy: 0.3745 - val_loss: 0.4284 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 8/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.3680 - val_loss: 0.4402 - val_accuracy: 0.2759 - lr: 0.0010\n","Epoch 9/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4480 - accuracy: 0.3615 - val_loss: 0.4474 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 10/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4536 - accuracy: 0.3745 - val_loss: 0.4236 - val_accuracy: 0.2845 - lr: 0.0010\n","Epoch 11/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4545 - accuracy: 0.3377 - val_loss: 0.4280 - val_accuracy: 0.2931 - lr: 0.0010\n","Epoch 12/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4495 - accuracy: 0.3766 - val_loss: 0.4404 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 13/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4457 - accuracy: 0.3745 - val_loss: 0.4328 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 14/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4506 - accuracy: 0.3788 - val_loss: 0.4180 - val_accuracy: 0.4052 - lr: 0.0010\n","Epoch 15/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4483 - accuracy: 0.3874 - val_loss: 0.4412 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 16/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4464 - accuracy: 0.4004 - val_loss: 0.4388 - val_accuracy: 0.2759 - lr: 0.0010\n","Epoch 17/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4438 - accuracy: 0.4113 - val_loss: 0.4443 - val_accuracy: 0.4569 - lr: 0.0010\n","Epoch 18/30\n","231/231 [==============================] - 1s 6ms/step - loss: 0.4466 - accuracy: 0.3831 - val_loss: 0.4291 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 19/30\n","231/231 [==============================] - 1s 6ms/step - loss: 0.4449 - accuracy: 0.3983 - val_loss: 0.4206 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 20/30\n","222/231 [===========================>..] - ETA: 0s - loss: 0.4440 - accuracy: 0.3986\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4444 - accuracy: 0.3961 - val_loss: 0.4254 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 21/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4406 - accuracy: 0.4069 - val_loss: 0.4224 - val_accuracy: 0.4741 - lr: 5.0000e-04\n","Epoch 22/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.3939 - val_loss: 0.4222 - val_accuracy: 0.4310 - lr: 5.0000e-04\n","Epoch 23/30\n","226/231 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.3717Restoring model weights from the end of the best epoch: 13.\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4378 - accuracy: 0.3745 - val_loss: 0.4184 - val_accuracy: 0.3966 - lr: 5.0000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["231/231 [==============================] - 2s 4ms/step - loss: 0.4417 - accuracy: 0.3636 - val_loss: 0.4696 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 2/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4397 - accuracy: 0.4048 - val_loss: 0.4619 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 3/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4368 - accuracy: 0.3831 - val_loss: 0.4767 - val_accuracy: 0.2759 - lr: 0.0010\n","Epoch 4/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4326 - accuracy: 0.3918 - val_loss: 0.4697 - val_accuracy: 0.3017 - lr: 0.0010\n","Epoch 5/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4376 - accuracy: 0.3766 - val_loss: 0.4741 - val_accuracy: 0.2759 - lr: 0.0010\n","Epoch 6/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.3831 - val_loss: 0.4726 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 7/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4374 - accuracy: 0.3961 - val_loss: 0.4668 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 8/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4316 - accuracy: 0.4048 - val_loss: 0.4651 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 9/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4283 - accuracy: 0.3831 - val_loss: 0.4754 - val_accuracy: 0.3621 - lr: 0.0010\n","Epoch 10/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4317 - accuracy: 0.3831 - val_loss: 0.4873 - val_accuracy: 0.3017 - lr: 0.0010\n","Epoch 11/30\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4306 - accuracy: 0.3983 - val_loss: 0.4665 - val_accuracy: 0.2759 - lr: 0.0010\n","Epoch 12/30\n","231/231 [==============================] - 2s 7ms/step - loss: 0.4336 - accuracy: 0.4156 - val_loss: 0.4681 - val_accuracy: 0.4052 - lr: 0.0010\n","Epoch 13/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4322 - accuracy: 0.3983 - val_loss: 0.4600 - val_accuracy: 0.3966 - lr: 0.0010\n","Epoch 14/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4259 - accuracy: 0.4069 - val_loss: 0.4646 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 15/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4303 - accuracy: 0.4069 - val_loss: 0.4767 - val_accuracy: 0.2845 - lr: 0.0010\n","Epoch 16/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4279 - accuracy: 0.3810 - val_loss: 0.4831 - val_accuracy: 0.3793 - lr: 0.0010\n","Epoch 17/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4294 - accuracy: 0.3788 - val_loss: 0.4674 - val_accuracy: 0.3793 - lr: 0.0010\n","Epoch 18/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4293 - accuracy: 0.3874 - val_loss: 0.4685 - val_accuracy: 0.4052 - lr: 0.0010\n","Epoch 19/30\n","230/231 [============================>.] - ETA: 0s - loss: 0.4245 - accuracy: 0.3978\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4249 - accuracy: 0.3961 - val_loss: 0.4651 - val_accuracy: 0.3879 - lr: 0.0010\n","Epoch 20/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4255 - accuracy: 0.4091 - val_loss: 0.4717 - val_accuracy: 0.3621 - lr: 5.0000e-04\n","Epoch 21/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4260 - accuracy: 0.4069 - val_loss: 0.4690 - val_accuracy: 0.3966 - lr: 5.0000e-04\n","Epoch 22/30\n","224/231 [============================>.] - ETA: 0s - loss: 0.4211 - accuracy: 0.4196Restoring model weights from the end of the best epoch: 12.\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4212 - accuracy: 0.4242 - val_loss: 0.4673 - val_accuracy: 0.3707 - lr: 5.0000e-04\n","Epoch 22: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["231/231 [==============================] - 2s 5ms/step - loss: 0.4345 - accuracy: 0.3896 - val_loss: 0.4501 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 2/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4334 - accuracy: 0.4199 - val_loss: 0.4533 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 3/30\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4324 - accuracy: 0.4091 - val_loss: 0.4504 - val_accuracy: 0.3276 - lr: 0.0010\n","Epoch 4/30\n","231/231 [==============================] - 1s 5ms/step - loss: 0.4301 - accuracy: 0.4156 - val_loss: 0.4511 - val_accuracy: 0.3276 - lr: 0.0010\n","Epoch 5/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4311 - accuracy: 0.4242 - val_loss: 0.4525 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 6/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4330 - accuracy: 0.4113 - val_loss: 0.4507 - val_accuracy: 0.3276 - lr: 0.0010\n","Epoch 7/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.4242 - val_loss: 0.4561 - val_accuracy: 0.3534 - lr: 0.0010\n","Epoch 8/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4302 - accuracy: 0.4199 - val_loss: 0.4498 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 9/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4341 - accuracy: 0.4221 - val_loss: 0.4497 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 10/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.4221 - val_loss: 0.4472 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 11/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.4221 - val_loss: 0.4547 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 12/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4282 - accuracy: 0.4242 - val_loss: 0.4485 - val_accuracy: 0.3362 - lr: 0.0010\n","Epoch 13/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4281 - accuracy: 0.4221 - val_loss: 0.4442 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 14/30\n","229/231 [============================>.] - ETA: 0s - loss: 0.4249 - accuracy: 0.4367\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4261 - accuracy: 0.4351 - val_loss: 0.4465 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 15/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4222 - accuracy: 0.4307 - val_loss: 0.4456 - val_accuracy: 0.3621 - lr: 5.0000e-04\n","Epoch 16/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4204 - accuracy: 0.4372 - val_loss: 0.4504 - val_accuracy: 0.3448 - lr: 5.0000e-04\n","Epoch 17/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4208 - accuracy: 0.4459 - val_loss: 0.4446 - val_accuracy: 0.3534 - lr: 5.0000e-04\n","Epoch 18/30\n","231/231 [==============================] - 1s 3ms/step - loss: 0.4218 - accuracy: 0.4242 - val_loss: 0.4447 - val_accuracy: 0.3448 - lr: 5.0000e-04\n","Epoch 19/30\n","231/231 [==============================] - 1s 6ms/step - loss: 0.4212 - accuracy: 0.4394 - val_loss: 0.4489 - val_accuracy: 0.3448 - lr: 5.0000e-04\n","Epoch 20/30\n","231/231 [==============================] - 1s 6ms/step - loss: 0.4201 - accuracy: 0.4481 - val_loss: 0.4459 - val_accuracy: 0.3534 - lr: 5.0000e-04\n","Epoch 21/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4193 - accuracy: 0.4286 - val_loss: 0.4463 - val_accuracy: 0.3448 - lr: 5.0000e-04\n","Epoch 22/30\n","212/231 [==========================>...] - ETA: 0s - loss: 0.4257 - accuracy: 0.4198\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4249 - accuracy: 0.4156 - val_loss: 0.4436 - val_accuracy: 0.3534 - lr: 5.0000e-04\n","Epoch 23/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4159 - accuracy: 0.4394 - val_loss: 0.4439 - val_accuracy: 0.3448 - lr: 2.5000e-04\n","Epoch 24/30\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4182 - accuracy: 0.4416 - val_loss: 0.4432 - val_accuracy: 0.3448 - lr: 2.5000e-04\n","Epoch 25/30\n","229/231 [============================>.] - ETA: 0s - loss: 0.4161 - accuracy: 0.4498Restoring model weights from the end of the best epoch: 15.\n","231/231 [==============================] - 1s 4ms/step - loss: 0.4162 - accuracy: 0.4502 - val_loss: 0.4434 - val_accuracy: 0.3448 - lr: 2.5000e-04\n","Epoch 25: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["232/232 [==============================] - 2s 4ms/step - loss: 0.4379 - accuracy: 0.4168 - val_loss: 0.4078 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 2/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4379 - accuracy: 0.4168 - val_loss: 0.4120 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 3/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4368 - accuracy: 0.4125 - val_loss: 0.4202 - val_accuracy: 0.3652 - lr: 0.0010\n","Epoch 4/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4372 - accuracy: 0.4039 - val_loss: 0.4281 - val_accuracy: 0.3565 - lr: 0.0010\n","Epoch 5/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4353 - accuracy: 0.4104 - val_loss: 0.4233 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 6/30\n","232/232 [==============================] - 2s 7ms/step - loss: 0.4356 - accuracy: 0.4082 - val_loss: 0.4181 - val_accuracy: 0.3739 - lr: 0.0010\n","Epoch 7/30\n","232/232 [==============================] - 1s 6ms/step - loss: 0.4359 - accuracy: 0.3909 - val_loss: 0.4053 - val_accuracy: 0.4522 - lr: 0.0010\n","Epoch 8/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4331 - accuracy: 0.4190 - val_loss: 0.4045 - val_accuracy: 0.4957 - lr: 0.0010\n","Epoch 9/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4317 - accuracy: 0.4600 - val_loss: 0.4249 - val_accuracy: 0.3565 - lr: 0.0010\n","Epoch 10/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4335 - accuracy: 0.3844 - val_loss: 0.4145 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 11/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4315 - accuracy: 0.4276 - val_loss: 0.4264 - val_accuracy: 0.3826 - lr: 0.0010\n","Epoch 12/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4320 - accuracy: 0.4104 - val_loss: 0.4156 - val_accuracy: 0.3739 - lr: 0.0010\n","Epoch 13/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4304 - accuracy: 0.4147 - val_loss: 0.4441 - val_accuracy: 0.3739 - lr: 0.0010\n","Epoch 14/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4323 - accuracy: 0.4233 - val_loss: 0.4305 - val_accuracy: 0.3652 - lr: 0.0010\n","Epoch 15/30\n","224/232 [===========================>..] - ETA: 0s - loss: 0.4364 - accuracy: 0.4174\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4327 - accuracy: 0.4190 - val_loss: 0.4232 - val_accuracy: 0.3391 - lr: 0.0010\n","Epoch 16/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4286 - accuracy: 0.4147 - val_loss: 0.4181 - val_accuracy: 0.4000 - lr: 5.0000e-04\n","Epoch 17/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4263 - accuracy: 0.4276 - val_loss: 0.4153 - val_accuracy: 0.4174 - lr: 5.0000e-04\n","Epoch 18/30\n","229/232 [============================>.] - ETA: 0s - loss: 0.4262 - accuracy: 0.4323Restoring model weights from the end of the best epoch: 8.\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4277 - accuracy: 0.4298 - val_loss: 0.4152 - val_accuracy: 0.4174 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 2ms/step\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["232/232 [==============================] - 2s 6ms/step - loss: 0.4205 - accuracy: 0.4687 - val_loss: 0.4442 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 2/30\n","232/232 [==============================] - 1s 6ms/step - loss: 0.4231 - accuracy: 0.4060 - val_loss: 0.4354 - val_accuracy: 0.4174 - lr: 0.0010\n","Epoch 3/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4214 - accuracy: 0.4320 - val_loss: 0.4386 - val_accuracy: 0.4087 - lr: 0.0010\n","Epoch 4/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4299 - accuracy: 0.4320 - val_loss: 0.4387 - val_accuracy: 0.4609 - lr: 0.0010\n","Epoch 5/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4297 - accuracy: 0.3996 - val_loss: 0.4416 - val_accuracy: 0.4087 - lr: 0.0010\n","Epoch 6/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4236 - accuracy: 0.4233 - val_loss: 0.4376 - val_accuracy: 0.4348 - lr: 0.0010\n","Epoch 7/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4252 - accuracy: 0.4255 - val_loss: 0.4432 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 8/30\n","232/232 [==============================] - 1s 5ms/step - loss: 0.4246 - accuracy: 0.4276 - val_loss: 0.4401 - val_accuracy: 0.4348 - lr: 0.0010\n","Epoch 9/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4210 - accuracy: 0.4363 - val_loss: 0.4384 - val_accuracy: 0.4000 - lr: 0.0010\n","Epoch 10/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4239 - accuracy: 0.4341 - val_loss: 0.4396 - val_accuracy: 0.3913 - lr: 0.0010\n","Epoch 11/30\n","229/232 [============================>.] - ETA: 0s - loss: 0.4263 - accuracy: 0.4127\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4266 - accuracy: 0.4125 - val_loss: 0.4401 - val_accuracy: 0.4348 - lr: 0.0010\n","Epoch 12/30\n","232/232 [==============================] - 1s 4ms/step - loss: 0.4179 - accuracy: 0.4536 - val_loss: 0.4423 - val_accuracy: 0.3913 - lr: 5.0000e-04\n","Epoch 13/30\n","232/232 [==============================] - 1s 3ms/step - loss: 0.4205 - accuracy: 0.4514 - val_loss: 0.4346 - val_accuracy: 0.4522 - lr: 5.0000e-04\n","Epoch 14/30\n","229/232 [============================>.] - ETA: 0s - loss: 0.4155 - accuracy: 0.4454Restoring model weights from the end of the best epoch: 4.\n","232/232 [==============================] - 1s 5ms/step - loss: 0.4152 - accuracy: 0.4471 - val_loss: 0.4352 - val_accuracy: 0.4000 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 6ms/step\n","Average Accuracy:  0.02077961019490255\n","Accuracy:  0.7923868065967001\n","Average Normalized Accuracy:  0.02077961019490255\n","Average Precision:  0.3342782238609566\n","Average Recall:  0.01982766930701719\n","F1 score: 0.03743489282234606\n","Grand Mean: 0.20424780216280417\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]}]}
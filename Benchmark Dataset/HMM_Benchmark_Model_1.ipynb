{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"15d06WjXUqjWR4ytMZ4whv8WWbxFHdQnk","timestamp":1697915057798}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FxzzOUnzW47y","executionInfo":{"status":"ok","timestamp":1697890031864,"user_tz":-330,"elapsed":25463,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"e1276acf-0403-4ad0-85ee-16601820fe8a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["import numpy as np\n","\n","def parse_hmm(fname):\n","    f = open(fname)\n","    line=f.readline()\n","    while line[0]!='#':\n","        line=f.readline()\n","    f.readline()\n","    f.readline()\n","    f.readline()\n","    f.readline()\n","    seq = []\n","    extras = np.zeros([0,10])\n","    prob = np.zeros([0,20])\n","    line = f.readline()\n","    while line[0:2]!='//':\n","        lineinfo = line.split()\n","        seq.append(lineinfo[0])\n","        probs_ = [2**(-float(lineinfo[i])/1000) if lineinfo[i]!='*' else 0. for i in range(2,22)]\n","        prob = np.concatenate((prob,np.matrix(probs_)),axis=0)\n","\n","        line = f.readline()\n","        lineinfo = line.split()\n","        extras_ = [2**(-float(lineinfo[i])/1000) if lineinfo[i]!='*' else 0. for i in range(0,10)]\n","        extras = np.concatenate((extras,np.matrix(extras_)),axis=0)\n","\n","        line = f.readline()\n","        assert len(line.strip())==0\n","\n","        line = f.readline()\n","    return (''.join(seq),prob,extras)"],"metadata":{"id":"qQWtKt5jW8ir"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## HMM Profile Extraction"],"metadata":{"id":"ffh5iCwzXeX9"}},{"cell_type":"code","source":["import pandas as pd\n","df = pd.read_csv('/content/drive/MyDrive/HDA/Benchmark_BinaryML.csv')"],"metadata":{"id":"Z0v3XYjZXKox"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","hmm_matrices = []\n","\n","for i in df['PDBid']:\n","    hmm_mat = parse_hmm(f'/content/drive/MyDrive/HDA/Benchmark_HMM/{i}.txt')\n","    hmm_arr = np.array(hmm_mat[1])\n","    hmm_matrices.append(hmm_arr)\n","\n","# Add the list of hmm_arr as a new column 'hmm_matrix' in the DataFrame\n","df['hmm_matrix'] = hmm_matrices"],"metadata":{"id":"kySlTdIxXRlJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Skipxgram Extraction"],"metadata":{"id":"iBokrvfLXocx"}},{"cell_type":"code","source":["import numpy as np\n","\n","def calculate_sxgbg_features(evolutionary_profile, X):\n","\n","    L, _ = evolutionary_profile.shape\n","    sxgbg_matrix = np.zeros((20, 20))\n","\n","    for i in range(20):\n","        for j in range(20):\n","            sxgbg_value = 0.0\n","\n","            for l in range(1,L - X):\n","                sxgbg_value += evolutionary_profile[l-1, i] * evolutionary_profile[l + X , j]\n","\n","            sxgbg_matrix[i, j] = sxgbg_value\n","\n","    return sxgbg_matrix"],"metadata":{"id":"HCyYGKMpXcco"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S0G Matrix"],"metadata":{"id":"ULzAfTllYFrS"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s0g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s0g_mat = calculate_sxgbg_features(i, 0)\n","    s0g_arr = np.array(s0g_mat)\n","    s0g_matrix.append(s0g_arr)\n","\n","df['s0g_matrix'] = s0g_matrix"],"metadata":{"id":"P3bqM6ZUXzq5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S1G Matrix"],"metadata":{"id":"gN9WPqh1YIj3"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s1g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s1g_mat = calculate_sxgbg_features(i, 1)\n","    s1g_arr = np.array(s1g_mat)\n","    s1g_matrix.append(s1g_arr)\n","\n","df['s1g_matrix'] = s1g_matrix"],"metadata":{"id":"lL9lPFGDX-60"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S2G Matrix"],"metadata":{"id":"JEbU3n52YMCb"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s2g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s2g_mat = calculate_sxgbg_features(i, 2)\n","    s2g_arr = np.array(s2g_mat)\n","    s2g_matrix.append(s2g_arr)\n","\n","df['s2g_matrix'] = s2g_matrix"],"metadata":{"id":"NOocfQpIX_wL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S3G Matrix"],"metadata":{"id":"XloXGYwhYOsy"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s3g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s3g_mat = calculate_sxgbg_features(i, 3)\n","    s3g_arr = np.array(s3g_mat)\n","    s3g_matrix.append(s3g_arr)\n","\n","df['s3g_matrix'] = s3g_matrix"],"metadata":{"id":"WpU6cz4OYAVd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S4G Matrix"],"metadata":{"id":"3mAX_CfuYQ4d"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s4g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s4g_mat = calculate_sxgbg_features(i, 4)\n","    s4g_arr = np.array(s4g_mat)\n","    s4g_matrix.append(s4g_arr)\n","\n","df['s4g_matrix'] = s4g_matrix"],"metadata":{"id":"BEHJobTTYC55"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S5G Matrix"],"metadata":{"id":"ze0GajZ0YS4D"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s5g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s5g_mat = calculate_sxgbg_features(i, 5)\n","    s5g_arr = np.array(s5g_mat)\n","    s5g_matrix.append(s5g_arr)\n","\n","df['s5g_matrix'] = s5g_matrix"],"metadata":{"id":"pXPVfSNGYDfs"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### S6G Matrix"],"metadata":{"id":"WUt5nwgnYVUn"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s6g_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s6g_mat = calculate_sxgbg_features(i, 6)\n","    s6g_arr = np.array(s6g_mat)\n","    s6g_matrix.append(s6g_arr)\n","\n","df['s6g_matrix'] = s6g_matrix"],"metadata":{"id":"zDH1dWExYD99"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Evaluation Metrics"],"metadata":{"id":"kcXHEqgpZD99"}},{"cell_type":"code","source":["def calculate_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    # Initialize accuracy\n","    accuracy = 0\n","\n","    # Calculate accuracy for each instance\n","    for i in range(len(y_true)):\n","        # Calculate intersection and union\n","        intersection = np.sum(np.logical_and(y_true[i], y_pred[i]))\n","        union = np.sum(np.logical_or(y_true[i], y_pred[i]))\n","\n","        # Add to total accuracy\n","        accuracy += intersection / union\n","\n","    # Calculate average accuracy\n","    accuracy /= len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"oqIY31Q4aOJK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","\n","def norm_accuracy(y_true, y_pred):\n","    # Ensure inputs are numpy arrays\n","    y_true = np.array(y_true)\n","    y_pred = np.array((y_pred>0.5).astype(int))\n","\n","    acc = []\n","    # Loop over each instance\n","    for i in range(len(y_true)):\n","        # Calculate the number of correct predictions for this instance\n","        print(y_true[i], y_pred[i])\n","        correct_predictions = np.sum(y_true[i] == y_pred[i])\n","        print(correct_predictions/5)\n","        acc.append(correct_predictions/5)\n","\n","    # Calculate accuracy\n","    accuracy = sum(acc) / len(y_true)\n","\n","    return accuracy"],"metadata":{"id":"yUxFza9MaRJY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Matrix Model"],"metadata":{"id":"ZasAhPpLaWUZ"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_s0g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FkEV6pfCZGdp","executionInfo":{"status":"ok","timestamp":1697813528906,"user_tz":-330,"elapsed":76048,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"14beea0b-8bf8-46a6-dffc-b8fda8f8fa53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 10ms/step - loss: 0.5071 - accuracy: 0.4242 - val_loss: 0.4567 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.4739 - accuracy: 0.4221 - val_loss: 0.4741 - val_accuracy: 0.2845 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4530 - accuracy: 0.4675 - val_loss: 0.4256 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4121 - accuracy: 0.5238 - val_loss: 0.4102 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.5498 - val_loss: 0.4684 - val_accuracy: 0.4138 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3974 - accuracy: 0.5649 - val_loss: 0.3856 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3739 - accuracy: 0.5844 - val_loss: 0.3832 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3485 - accuracy: 0.6320 - val_loss: 0.3917 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3579 - accuracy: 0.6039 - val_loss: 0.3872 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3361 - accuracy: 0.5996 - val_loss: 0.3400 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 11/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.3006 - accuracy: 0.6599\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2993 - accuracy: 0.6645 - val_loss: 0.3834 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2872 - accuracy: 0.6558 - val_loss: 0.3093 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2835 - accuracy: 0.6688 - val_loss: 0.3391 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 14/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.2782 - accuracy: 0.6560Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2795 - accuracy: 0.6537 - val_loss: 0.3212 - val_accuracy: 0.6379 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 1 1 0]\n","0.2\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.4122 - accuracy: 0.5368 - val_loss: 0.4503 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3895 - accuracy: 0.5498 - val_loss: 0.3893 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3696 - accuracy: 0.5909 - val_loss: 0.3656 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3399 - accuracy: 0.6039 - val_loss: 0.4043 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3428 - accuracy: 0.5866 - val_loss: 0.3384 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3219 - accuracy: 0.6277 - val_loss: 0.3703 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3368 - accuracy: 0.5866 - val_loss: 0.3699 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3063 - accuracy: 0.6645 - val_loss: 0.3253 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3043 - accuracy: 0.6494 - val_loss: 0.3602 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3040 - accuracy: 0.6385 - val_loss: 0.3527 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2781 - accuracy: 0.6905 - val_loss: 0.3667 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2741 - accuracy: 0.6818 - val_loss: 0.3135 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2644 - accuracy: 0.7056 - val_loss: 0.4341 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2849 - accuracy: 0.7035 - val_loss: 0.3277 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2617 - accuracy: 0.7078 - val_loss: 0.3551 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2629 - accuracy: 0.7100 - val_loss: 0.3427 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2538 - accuracy: 0.7229 - val_loss: 0.4148 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 0.7229 - val_loss: 0.4915 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 19/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.3311 - accuracy: 0.6717\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3308 - accuracy: 0.6710 - val_loss: 0.4056 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2410 - accuracy: 0.7511 - val_loss: 0.2976 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2210 - accuracy: 0.7879 - val_loss: 0.3553 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2068 - accuracy: 0.7835 - val_loss: 0.3670 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2342 - accuracy: 0.7576 - val_loss: 0.4043 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1988 - accuracy: 0.7944 - val_loss: 0.3212 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1908 - accuracy: 0.8052 - val_loss: 0.3630 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1768 - accuracy: 0.8182 - val_loss: 0.4078 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 27/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1737 - accuracy: 0.8102\n","Epoch 27: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1784 - accuracy: 0.8052 - val_loss: 0.4089 - val_accuracy: 0.6121 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1708 - accuracy: 0.8247 - val_loss: 0.4106 - val_accuracy: 0.7069 - lr: 2.5000e-04\n","Epoch 29/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1555 - accuracy: 0.8420 - val_loss: 0.3827 - val_accuracy: 0.7069 - lr: 2.5000e-04\n","Epoch 30/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1501 - accuracy: 0.8528 - val_loss: 0.3824 - val_accuracy: 0.6897 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 17ms/step - loss: 0.2652 - accuracy: 0.7749 - val_loss: 0.2427 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2082 - accuracy: 0.7879 - val_loss: 0.2091 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2130 - accuracy: 0.7944 - val_loss: 0.1995 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1854 - accuracy: 0.8139 - val_loss: 0.1987 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1776 - accuracy: 0.8182 - val_loss: 0.2223 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2008 - accuracy: 0.7965 - val_loss: 0.2395 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1834 - accuracy: 0.7987 - val_loss: 0.1974 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1811 - accuracy: 0.8139 - val_loss: 0.1822 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1922 - accuracy: 0.8117 - val_loss: 0.3188 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2568 - accuracy: 0.7576 - val_loss: 0.2529 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1934 - accuracy: 0.7987 - val_loss: 0.2285 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1852 - accuracy: 0.8117 - val_loss: 0.2214 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1548 - accuracy: 0.8485 - val_loss: 0.2609 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1811 - accuracy: 0.8312 - val_loss: 0.3732 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 15/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1552 - accuracy: 0.8522\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1552 - accuracy: 0.8528 - val_loss: 0.1966 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1204 - accuracy: 0.8766 - val_loss: 0.2181 - val_accuracy: 0.7845 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1210 - accuracy: 0.8918 - val_loss: 0.2101 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 18/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.1071 - accuracy: 0.8899Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1082 - accuracy: 0.8918 - val_loss: 0.2358 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2209 - accuracy: 0.7775 - val_loss: 0.2183 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2091 - accuracy: 0.8143 - val_loss: 0.1894 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2035 - accuracy: 0.7819 - val_loss: 0.1190 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1698 - accuracy: 0.8143 - val_loss: 0.1175 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1742 - accuracy: 0.8272 - val_loss: 0.1212 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1781 - accuracy: 0.8229 - val_loss: 0.1330 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1758 - accuracy: 0.8272 - val_loss: 0.1415 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1804 - accuracy: 0.7991 - val_loss: 0.1440 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1563 - accuracy: 0.8380 - val_loss: 0.0999 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 10/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1525 - accuracy: 0.8283\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1525 - accuracy: 0.8294 - val_loss: 0.1522 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1350 - accuracy: 0.8596 - val_loss: 0.0973 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1178 - accuracy: 0.8920 - val_loss: 0.0939 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 13/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1088 - accuracy: 0.9009Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1103 - accuracy: 0.8963 - val_loss: 0.1038 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1904 - accuracy: 0.8143 - val_loss: 0.1785 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1510 - accuracy: 0.8553 - val_loss: 0.2097 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1564 - accuracy: 0.8359 - val_loss: 0.1886 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1358 - accuracy: 0.8639 - val_loss: 0.2147 - val_accuracy: 0.7652 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1445 - accuracy: 0.8315 - val_loss: 0.2747 - val_accuracy: 0.7304 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1366 - accuracy: 0.8553 - val_loss: 0.2136 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1352 - accuracy: 0.8596 - val_loss: 0.2284 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1433 - accuracy: 0.8510\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1433 - accuracy: 0.8510 - val_loss: 0.2206 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1106 - accuracy: 0.8963 - val_loss: 0.1981 - val_accuracy: 0.7913 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0935 - accuracy: 0.9093 - val_loss: 0.2036 - val_accuracy: 0.7826 - lr: 5.0000e-04\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0957 - accuracy: 0.9093Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0946 - accuracy: 0.9093 - val_loss: 0.1747 - val_accuracy: 0.8174 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 1 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","Average Accuracy:  0.6249925037481259\n","Accuracy:  0.9059910044977503\n","Average Normalized Accuracy:  0.6454672663668166\n","Average Precision:  0.8371204770516465\n","Average Recall:  0.638159640614534\n","F1 score: 0.724223822159889\n","Grand Mean: 0.7293257857397936\n"]}]},{"cell_type":"markdown","source":["## S1G Matrix Model"],"metadata":{"id":"Lsm3iP4pbLbz"}},{"cell_type":"code","source":["# Define the model\n","model_s1g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WCqYbphJbNe9","executionInfo":{"status":"ok","timestamp":1697813772757,"user_tz":-330,"elapsed":172533,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"5de50ad4-0137-4be5-bac3-887ac8d81d19"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.5453 - accuracy: 0.3961 - val_loss: 0.4711 - val_accuracy: 0.4655 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4413 - accuracy: 0.5108 - val_loss: 0.3759 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.4242 - accuracy: 0.5216 - val_loss: 0.4209 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3692 - accuracy: 0.5779 - val_loss: 0.3673 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3793 - accuracy: 0.5714 - val_loss: 0.3231 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3477 - accuracy: 0.5866 - val_loss: 0.3158 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.3221 - accuracy: 0.6212 - val_loss: 0.3565 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3176 - accuracy: 0.6255 - val_loss: 0.3235 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3242 - accuracy: 0.6234 - val_loss: 0.3262 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2987 - accuracy: 0.6320 - val_loss: 0.3691 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.2900 - accuracy: 0.6775 - val_loss: 0.2930 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3345 - accuracy: 0.6320 - val_loss: 0.3943 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - ETA: 0s - loss: 0.2990 - accuracy: 0.6753\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2990 - accuracy: 0.6753 - val_loss: 0.3060 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2572 - accuracy: 0.6905 - val_loss: 0.2921 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.2483 - accuracy: 0.7403 - val_loss: 0.3212 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - ETA: 0s - loss: 0.2511 - accuracy: 0.7619Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2511 - accuracy: 0.7619 - val_loss: 0.2764 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.3532 - accuracy: 0.6104 - val_loss: 0.4111 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3283 - accuracy: 0.6407 - val_loss: 0.3078 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3394 - accuracy: 0.6017 - val_loss: 0.3247 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.3125 - accuracy: 0.6494 - val_loss: 0.3626 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.3089 - accuracy: 0.6082 - val_loss: 0.3629 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3630 - accuracy: 0.6190 - val_loss: 0.3500 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2843 - accuracy: 0.6688 - val_loss: 0.3637 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 2s 17ms/step - loss: 0.2985 - accuracy: 0.6602 - val_loss: 0.3551 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.6925\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 2s 13ms/step - loss: 0.2744 - accuracy: 0.6861 - val_loss: 0.3201 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.2408 - accuracy: 0.7359 - val_loss: 0.3351 - val_accuracy: 0.5948 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2300 - accuracy: 0.7381 - val_loss: 0.2725 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2246 - accuracy: 0.7684 - val_loss: 0.2835 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2249 - accuracy: 0.7597 - val_loss: 0.2948 - val_accuracy: 0.6207 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2159 - accuracy: 0.7792 - val_loss: 0.2752 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2054 - accuracy: 0.7857 - val_loss: 0.2672 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2089 - accuracy: 0.8009 - val_loss: 0.3114 - val_accuracy: 0.6034 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1996 - accuracy: 0.8182 - val_loss: 0.2912 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1952 - accuracy: 0.7965 - val_loss: 0.2527 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1880 - accuracy: 0.8030 - val_loss: 0.3153 - val_accuracy: 0.6379 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1969 - accuracy: 0.7857 - val_loss: 0.2598 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1689 - accuracy: 0.8333 - val_loss: 0.2349 - val_accuracy: 0.7586 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1723 - accuracy: 0.8333 - val_loss: 0.2793 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1845 - accuracy: 0.8095 - val_loss: 0.3201 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1639 - accuracy: 0.8268 - val_loss: 0.2592 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1566 - accuracy: 0.8506 - val_loss: 0.2610 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1478 - accuracy: 0.8593 - val_loss: 0.2728 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1634 - accuracy: 0.8398 - val_loss: 0.2412 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 28/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.1448 - accuracy: 0.8638\n","Epoch 28: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1434 - accuracy: 0.8636 - val_loss: 0.2410 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.8831 - val_loss: 0.2607 - val_accuracy: 0.7414 - lr: 2.5000e-04\n","Epoch 30/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1218 - accuracy: 0.9004 - val_loss: 0.2579 - val_accuracy: 0.6897 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.2192 - accuracy: 0.7771 - val_loss: 0.2303 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2033 - accuracy: 0.7965 - val_loss: 0.1665 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1972 - accuracy: 0.8074 - val_loss: 0.1950 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 2s 15ms/step - loss: 0.1802 - accuracy: 0.8117 - val_loss: 0.2611 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 3s 22ms/step - loss: 0.2263 - accuracy: 0.7900 - val_loss: 0.2480 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2093 - accuracy: 0.7749 - val_loss: 0.1921 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1809 - accuracy: 0.8290 - val_loss: 0.2172 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1721 - accuracy: 0.8117 - val_loss: 0.1790 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1861 - accuracy: 0.8074 - val_loss: 0.3015 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1775 - accuracy: 0.8182 - val_loss: 0.2253 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1476 - accuracy: 0.8463 - val_loss: 0.2937 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1664 - accuracy: 0.8268 - val_loss: 0.1900 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 13/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.1963 - accuracy: 0.8136\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1945 - accuracy: 0.8139 - val_loss: 0.1990 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1469 - accuracy: 0.8506 - val_loss: 0.2079 - val_accuracy: 0.8017 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1252 - accuracy: 0.8593 - val_loss: 0.1747 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1099 - accuracy: 0.8918 - val_loss: 0.1833 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1242 - accuracy: 0.8636 - val_loss: 0.1651 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1031 - accuracy: 0.9113 - val_loss: 0.1827 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1063 - accuracy: 0.9091 - val_loss: 0.1649 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1008 - accuracy: 0.8896 - val_loss: 0.2273 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1039 - accuracy: 0.8961 - val_loss: 0.2150 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 22/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0972 - accuracy: 0.8955\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0982 - accuracy: 0.8918 - val_loss: 0.1993 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0856 - accuracy: 0.9177 - val_loss: 0.1727 - val_accuracy: 0.8534 - lr: 2.5000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0876 - accuracy: 0.9134 - val_loss: 0.1689 - val_accuracy: 0.8621 - lr: 2.5000e-04\n","Epoch 25/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0737 - accuracy: 0.9307Restoring model weights from the end of the best epoch: 15.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0737 - accuracy: 0.9307 - val_loss: 0.1687 - val_accuracy: 0.8534 - lr: 2.5000e-04\n","Epoch 25: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 3s 12ms/step - loss: 0.1913 - accuracy: 0.8207 - val_loss: 0.1248 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1900 - accuracy: 0.8143 - val_loss: 0.1338 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1939 - accuracy: 0.7948 - val_loss: 0.1536 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1865 - accuracy: 0.8056 - val_loss: 0.1597 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1474 - accuracy: 0.8553 - val_loss: 0.1025 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1359 - accuracy: 0.8639 - val_loss: 0.0887 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1247 - accuracy: 0.8834 - val_loss: 0.1716 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1446 - accuracy: 0.8337 - val_loss: 0.1203 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1949 - accuracy: 0.7991 - val_loss: 0.1135 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1208 - accuracy: 0.8790 - val_loss: 0.1104 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1614 - accuracy: 0.8402 - val_loss: 0.1223 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1292 - accuracy: 0.8683 - val_loss: 0.1013 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 13/30\n","101/116 [=========================>....] - ETA: 0s - loss: 0.1369 - accuracy: 0.8540\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1374 - accuracy: 0.8596 - val_loss: 0.1725 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1161 - accuracy: 0.8877 - val_loss: 0.1188 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0975 - accuracy: 0.9071 - val_loss: 0.0993 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0972 - accuracy: 0.9071 - val_loss: 0.1020 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 2s 14ms/step - loss: 0.0882 - accuracy: 0.9114 - val_loss: 0.1534 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 2s 20ms/step - loss: 0.0869 - accuracy: 0.9093 - val_loss: 0.1308 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0941 - accuracy: 0.9114 - val_loss: 0.1074 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0804 - accuracy: 0.9287 - val_loss: 0.1120 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0811 - accuracy: 0.9179 - val_loss: 0.1083 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 22/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0835 - accuracy: 0.9204\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0844 - accuracy: 0.9179 - val_loss: 0.0994 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0656 - accuracy: 0.9395 - val_loss: 0.1296 - val_accuracy: 0.8696 - lr: 2.5000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0595 - accuracy: 0.9395 - val_loss: 0.1375 - val_accuracy: 0.8870 - lr: 2.5000e-04\n","Epoch 25/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0602 - accuracy: 0.9459Restoring model weights from the end of the best epoch: 15.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0601 - accuracy: 0.9438 - val_loss: 0.1346 - val_accuracy: 0.8783 - lr: 2.5000e-04\n","Epoch 25: early stopping\n","4/4 [==============================] - 0s 6ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.1391 - accuracy: 0.8661 - val_loss: 0.2984 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1372 - accuracy: 0.8747 - val_loss: 0.1639 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1684 - accuracy: 0.8380 - val_loss: 0.3054 - val_accuracy: 0.6609 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1159 - accuracy: 0.8726 - val_loss: 0.1341 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 2s 15ms/step - loss: 0.1546 - accuracy: 0.8510 - val_loss: 0.2434 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1160 - accuracy: 0.8769 - val_loss: 0.1830 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1216 - accuracy: 0.8769 - val_loss: 0.2517 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1173 - accuracy: 0.8877 - val_loss: 0.2243 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0986 - accuracy: 0.9006 - val_loss: 0.2293 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1022 - accuracy: 0.9050 - val_loss: 0.1754 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0979 - accuracy: 0.8985 - val_loss: 0.2188 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1127 - accuracy: 0.8985 - val_loss: 0.2299 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0937 - accuracy: 0.8985 - val_loss: 0.2024 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1278 - accuracy: 0.8704 - val_loss: 0.2205 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 15/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0859 - accuracy: 0.9159\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 11ms/step - loss: 0.0855 - accuracy: 0.9158 - val_loss: 0.1531 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 2s 15ms/step - loss: 0.0655 - accuracy: 0.9244 - val_loss: 0.2418 - val_accuracy: 0.8174 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.0707 - accuracy: 0.9136 - val_loss: 0.2150 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 18/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9430Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 11ms/step - loss: 0.0613 - accuracy: 0.9417 - val_loss: 0.1947 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 8ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","Average Accuracy:  0.7011244377811094\n","Accuracy:  0.9194752623688149\n","Average Normalized Accuracy:  0.7198975512243878\n","Average Precision:  0.8593544234584497\n","Average Recall:  0.7083725202754332\n","F1 score: 0.7765932214002136\n","Grand Mean: 0.7808029027514015\n"]}]},{"cell_type":"markdown","source":["## S2G Matrix Model"],"metadata":{"id":"en9uKQn3b0zH"}},{"cell_type":"code","source":["# Define the model\n","model_s2g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xGdchURLbpOK","executionInfo":{"status":"ok","timestamp":1697813850849,"user_tz":-330,"elapsed":76694,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"9535e8a5-1147-42f1-b47c-018bfecd8b0c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.5158 - accuracy: 0.4113 - val_loss: 0.4232 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4645 - accuracy: 0.5022 - val_loss: 0.4288 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4423 - accuracy: 0.5000 - val_loss: 0.4206 - val_accuracy: 0.4483 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3900 - accuracy: 0.5866 - val_loss: 0.4208 - val_accuracy: 0.4310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.3821 - accuracy: 0.5433 - val_loss: 0.3770 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.3759 - accuracy: 0.5823 - val_loss: 0.3541 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.3455 - accuracy: 0.6126 - val_loss: 0.3665 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3370 - accuracy: 0.6082 - val_loss: 0.3814 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.3318 - accuracy: 0.6364 - val_loss: 0.3491 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3090 - accuracy: 0.6472 - val_loss: 0.3638 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2900 - accuracy: 0.6948 - val_loss: 0.3308 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.3452 - accuracy: 0.6190 - val_loss: 0.3648 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3357 - accuracy: 0.6342 - val_loss: 0.3313 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2810 - accuracy: 0.6905 - val_loss: 0.3467 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2608 - accuracy: 0.7294 - val_loss: 0.3178 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2622 - accuracy: 0.7229 - val_loss: 0.2992 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2675 - accuracy: 0.7121 - val_loss: 0.3454 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2463 - accuracy: 0.7208 - val_loss: 0.3236 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2435 - accuracy: 0.7489 - val_loss: 0.3083 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.2337 - accuracy: 0.7468 - val_loss: 0.3147 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2409 - accuracy: 0.7511 - val_loss: 0.2894 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2118 - accuracy: 0.7857 - val_loss: 0.3254 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2012 - accuracy: 0.7944 - val_loss: 0.3034 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 24/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2033 - accuracy: 0.7684 - val_loss: 0.3504 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 25/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2047 - accuracy: 0.7944 - val_loss: 0.3310 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 26/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1872 - accuracy: 0.8074 - val_loss: 0.3556 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 27/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1938 - accuracy: 0.8052 - val_loss: 0.4468 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 28/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2314 - accuracy: 0.7489 - val_loss: 0.3476 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 29/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1880 - accuracy: 0.7922 - val_loss: 0.3005 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 30/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.1636 - accuracy: 0.8296\n","Epoch 30: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1666 - accuracy: 0.8268 - val_loss: 0.3126 - val_accuracy: 0.6983 - lr: 0.0010\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 1 0]\n","0.4\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 3s 14ms/step - loss: 0.2160 - accuracy: 0.7987 - val_loss: 0.2248 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.2256 - accuracy: 0.7706 - val_loss: 0.2172 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2009 - accuracy: 0.7879 - val_loss: 0.2046 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.2389 - accuracy: 0.7662 - val_loss: 0.2118 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2293 - accuracy: 0.7749 - val_loss: 0.2043 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1998 - accuracy: 0.7879 - val_loss: 0.1770 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1853 - accuracy: 0.8203 - val_loss: 0.1615 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1697 - accuracy: 0.8290 - val_loss: 0.2334 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1541 - accuracy: 0.8442 - val_loss: 0.1724 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1585 - accuracy: 0.8442 - val_loss: 0.1743 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1559 - accuracy: 0.8463 - val_loss: 0.1522 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1323 - accuracy: 0.8745 - val_loss: 0.1708 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1583 - accuracy: 0.8355 - val_loss: 0.1861 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 14/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.1500 - accuracy: 0.8389\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1449 - accuracy: 0.8442 - val_loss: 0.1492 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1171 - accuracy: 0.8918 - val_loss: 0.1842 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1163 - accuracy: 0.8853 - val_loss: 0.1529 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 17/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.1047 - accuracy: 0.8986Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.8983 - val_loss: 0.1689 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1854 - accuracy: 0.8030 - val_loss: 0.1756 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2031 - accuracy: 0.7922 - val_loss: 0.1457 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1811 - accuracy: 0.8117 - val_loss: 0.1697 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1575 - accuracy: 0.8377 - val_loss: 0.1799 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1678 - accuracy: 0.8030 - val_loss: 0.1898 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1772 - accuracy: 0.8333 - val_loss: 0.2857 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1938 - accuracy: 0.7987 - val_loss: 0.1774 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1738 - accuracy: 0.8355 - val_loss: 0.2199 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1609 - accuracy: 0.8420\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1609 - accuracy: 0.8420 - val_loss: 0.2556 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1294 - accuracy: 0.8701 - val_loss: 0.1870 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1230 - accuracy: 0.8701 - val_loss: 0.1633 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 12/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0963 - accuracy: 0.9005Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1035 - accuracy: 0.8918 - val_loss: 0.1909 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1917 - accuracy: 0.8186 - val_loss: 0.1545 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2113 - accuracy: 0.7883 - val_loss: 0.1506 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1705 - accuracy: 0.8272 - val_loss: 0.1855 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.8488 - val_loss: 0.1276 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2434 - accuracy: 0.7689 - val_loss: 0.2065 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2214 - accuracy: 0.7819 - val_loss: 0.1885 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1752 - accuracy: 0.8164 - val_loss: 0.1164 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1555 - accuracy: 0.8661 - val_loss: 0.1143 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1386 - accuracy: 0.8596 - val_loss: 0.1117 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1562 - accuracy: 0.8488 - val_loss: 0.1694 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1411 - accuracy: 0.8575 - val_loss: 0.1259 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1437 - accuracy: 0.8596 - val_loss: 0.2468 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1700 - accuracy: 0.8445 - val_loss: 0.1567 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1502 - accuracy: 0.8596 - val_loss: 0.1300 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 15/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.1187 - accuracy: 0.9000\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1191 - accuracy: 0.9006 - val_loss: 0.1510 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1080 - accuracy: 0.8920 - val_loss: 0.1722 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9136 - val_loss: 0.1229 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 18/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0970 - accuracy: 0.9099Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0990 - accuracy: 0.9093 - val_loss: 0.1362 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1703 - accuracy: 0.8380 - val_loss: 0.1370 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.8510 - val_loss: 0.2437 - val_accuracy: 0.6783 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1810 - accuracy: 0.8272 - val_loss: 0.2137 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1748 - accuracy: 0.8596 - val_loss: 0.2263 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1405 - accuracy: 0.8531 - val_loss: 0.1928 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1360 - accuracy: 0.8575 - val_loss: 0.3321 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1302 - accuracy: 0.8683 - val_loss: 0.2608 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.1306 - accuracy: 0.8817\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1314 - accuracy: 0.8790 - val_loss: 0.1781 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9028 - val_loss: 0.1732 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0949 - accuracy: 0.9006 - val_loss: 0.1666 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0915 - accuracy: 0.9179Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0915 - accuracy: 0.9179 - val_loss: 0.1879 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.7667166416791604\n","Accuracy:  0.9350314842578706\n","Average Normalized Accuracy:  0.7802873563218391\n","Average Precision:  0.9106814273470544\n","Average Recall:  0.7649365237873613\n","F1 score: 0.8314705447515068\n","Grand Mean: 0.831520663024132\n"]}]},{"cell_type":"markdown","source":["## S3G Matrix Model"],"metadata":{"id":"AjHed8xjb-1B"}},{"cell_type":"code","source":["# Define the model\n","model_s3g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s3g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s3g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s3g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s3g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JdYxc5pxb4-4","executionInfo":{"status":"ok","timestamp":1697813948559,"user_tz":-330,"elapsed":97713,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"f41001cf-048a-4578-a8c4-e06b24739382"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.5067 - accuracy: 0.4134 - val_loss: 0.4638 - val_accuracy: 0.3707 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4513 - accuracy: 0.4459 - val_loss: 0.4118 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4199 - accuracy: 0.5022 - val_loss: 0.4090 - val_accuracy: 0.4224 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4125 - accuracy: 0.5108 - val_loss: 0.3775 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3861 - accuracy: 0.5195 - val_loss: 0.3527 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3746 - accuracy: 0.5346 - val_loss: 0.3474 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3495 - accuracy: 0.5996 - val_loss: 0.3529 - val_accuracy: 0.5000 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3323 - accuracy: 0.6082 - val_loss: 0.3540 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3348 - accuracy: 0.5779 - val_loss: 0.3462 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3192 - accuracy: 0.5974 - val_loss: 0.3246 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3319 - accuracy: 0.5931 - val_loss: 0.3220 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3081 - accuracy: 0.6190 - val_loss: 0.3193 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3171 - accuracy: 0.6234 - val_loss: 0.3197 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3331 - accuracy: 0.6255 - val_loss: 0.3358 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3125 - accuracy: 0.6320 - val_loss: 0.3345 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3095 - accuracy: 0.6147 - val_loss: 0.3419 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2948 - accuracy: 0.6429 - val_loss: 0.3104 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2888 - accuracy: 0.6494 - val_loss: 0.3255 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3355 - accuracy: 0.6320 - val_loss: 0.3183 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3229 - accuracy: 0.6169 - val_loss: 0.3256 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2783 - accuracy: 0.6602 - val_loss: 0.3123 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2731 - accuracy: 0.6926 - val_loss: 0.3307 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2668 - accuracy: 0.6818 - val_loss: 0.3014 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 24/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2736 - accuracy: 0.7100 - val_loss: 0.2978 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 25/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2673 - accuracy: 0.6991 - val_loss: 0.2964 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 26/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2969 - accuracy: 0.6515 - val_loss: 0.3497 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 27/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3018 - accuracy: 0.6104 - val_loss: 0.3490 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 28/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2620 - accuracy: 0.6948 - val_loss: 0.2928 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 29/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2556 - accuracy: 0.6861 - val_loss: 0.3266 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 30/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2449 - accuracy: 0.7468 - val_loss: 0.3051 - val_accuracy: 0.6983 - lr: 0.0010\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 1 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2788 - accuracy: 0.7208 - val_loss: 0.2691 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2620 - accuracy: 0.7294 - val_loss: 0.3517 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2702 - accuracy: 0.7013 - val_loss: 0.2654 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2517 - accuracy: 0.7424 - val_loss: 0.2833 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2427 - accuracy: 0.7316 - val_loss: 0.3094 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2415 - accuracy: 0.7489 - val_loss: 0.2594 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2400 - accuracy: 0.7165 - val_loss: 0.2934 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2428 - accuracy: 0.7229 - val_loss: 0.3031 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2368 - accuracy: 0.7446 - val_loss: 0.2496 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2109 - accuracy: 0.7922 - val_loss: 0.3199 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2308 - accuracy: 0.7446 - val_loss: 0.3181 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2049 - accuracy: 0.7879 - val_loss: 0.2782 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 13/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.2024 - accuracy: 0.7935\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2034 - accuracy: 0.7900 - val_loss: 0.3364 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1934 - accuracy: 0.7922 - val_loss: 0.2101 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1813 - accuracy: 0.8074 - val_loss: 0.2298 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 16/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.1717 - accuracy: 0.8131Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1685 - accuracy: 0.8160 - val_loss: 0.2380 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.2960 - accuracy: 0.6537 - val_loss: 0.2967 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3081 - accuracy: 0.6364 - val_loss: 0.3079 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3279 - accuracy: 0.6255 - val_loss: 0.3657 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3099 - accuracy: 0.5866 - val_loss: 0.2979 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2903 - accuracy: 0.6364 - val_loss: 0.2733 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2725 - accuracy: 0.7273 - val_loss: 0.2632 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2558 - accuracy: 0.7078 - val_loss: 0.2804 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2407 - accuracy: 0.7359 - val_loss: 0.2611 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2331 - accuracy: 0.7186 - val_loss: 0.2727 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2284 - accuracy: 0.7359 - val_loss: 0.2553 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2370 - accuracy: 0.7316 - val_loss: 0.2672 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2387 - accuracy: 0.7424 - val_loss: 0.2875 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2147 - accuracy: 0.7446 - val_loss: 0.3539 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2078 - accuracy: 0.7749 - val_loss: 0.3344 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 15/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1997 - accuracy: 0.7793\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1991 - accuracy: 0.7792 - val_loss: 0.2759 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1875 - accuracy: 0.7922 - val_loss: 0.2361 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1666 - accuracy: 0.8225 - val_loss: 0.2627 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1648 - accuracy: 0.8160 - val_loss: 0.2384 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1643 - accuracy: 0.8139 - val_loss: 0.2412 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1607 - accuracy: 0.8225 - val_loss: 0.2164 - val_accuracy: 0.7586 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1547 - accuracy: 0.8398 - val_loss: 0.2678 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1676 - accuracy: 0.8290 - val_loss: 0.2438 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1509 - accuracy: 0.8333 - val_loss: 0.2530 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1565 - accuracy: 0.8463 - val_loss: 0.2649 - val_accuracy: 0.7586 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1483 - accuracy: 0.8398 - val_loss: 0.2386 - val_accuracy: 0.7845 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1535 - accuracy: 0.8355 - val_loss: 0.2529 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1395 - accuracy: 0.8506 - val_loss: 0.2646 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1347 - accuracy: 0.8485 - val_loss: 0.2715 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1570 - accuracy: 0.8268 - val_loss: 0.2611 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1479 - accuracy: 0.8442 - val_loss: 0.2154 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2334 - accuracy: 0.7343 - val_loss: 0.2079 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2132 - accuracy: 0.7624 - val_loss: 0.1108 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2161 - accuracy: 0.7451 - val_loss: 0.1565 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1980 - accuracy: 0.7775 - val_loss: 0.1295 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1960 - accuracy: 0.7840 - val_loss: 0.1873 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2107 - accuracy: 0.7775 - val_loss: 0.1343 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2049 - accuracy: 0.7754 - val_loss: 0.1680 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1912 - accuracy: 0.7862 - val_loss: 0.1032 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1833 - accuracy: 0.8078 - val_loss: 0.1061 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1798 - accuracy: 0.8056 - val_loss: 0.1823 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1770 - accuracy: 0.8251 - val_loss: 0.1172 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1654 - accuracy: 0.8229 - val_loss: 0.1256 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2001 - accuracy: 0.7970 - val_loss: 0.1175 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2201 - accuracy: 0.7667 - val_loss: 0.2386 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 15/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.2050 - accuracy: 0.7879\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2037 - accuracy: 0.7905 - val_loss: 0.1155 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1681 - accuracy: 0.8229 - val_loss: 0.1145 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1430 - accuracy: 0.8337 - val_loss: 0.1028 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 18/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1355 - accuracy: 0.8481Restoring model weights from the end of the best epoch: 8.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1391 - accuracy: 0.8423 - val_loss: 0.0968 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 18: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.1633 - accuracy: 0.8251 - val_loss: 0.2058 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2020 - accuracy: 0.7927 - val_loss: 0.2347 - val_accuracy: 0.6696 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1990 - accuracy: 0.7775 - val_loss: 0.2225 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1489 - accuracy: 0.8488 - val_loss: 0.1805 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1587 - accuracy: 0.8380 - val_loss: 0.2461 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1434 - accuracy: 0.8380 - val_loss: 0.2273 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1664 - accuracy: 0.8164 - val_loss: 0.2457 - val_accuracy: 0.7304 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2046 - accuracy: 0.7948 - val_loss: 0.2361 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.8164 - val_loss: 0.2357 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1723 - accuracy: 0.8315 - val_loss: 0.2352 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 11/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.1692 - accuracy: 0.8462\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.8488 - val_loss: 0.2220 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1650 - accuracy: 0.8099 - val_loss: 0.1995 - val_accuracy: 0.7652 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1348 - accuracy: 0.8553 - val_loss: 0.2223 - val_accuracy: 0.7652 - lr: 5.0000e-04\n","Epoch 14/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.1133 - accuracy: 0.8818Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1179 - accuracy: 0.8747 - val_loss: 0.2631 - val_accuracy: 0.7391 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","Average Accuracy:  0.7165817091454273\n","Accuracy:  0.9160119940029979\n","Average Normalized Accuracy:  0.7327386306846576\n","Average Precision:  0.8370185027879214\n","Average Recall:  0.7193406686289914\n","F1 score: 0.7737307178292864\n","Grand Mean: 0.7825703705132137\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["## S4G Matrix Model"],"metadata":{"id":"Wz7E6Uetca8S"}},{"cell_type":"code","source":["# Define the model\n","model_s4g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s4g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s4g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s4g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s4g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"E1uLQEFPcQuL","executionInfo":{"status":"ok","timestamp":1697814015533,"user_tz":-330,"elapsed":66996,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"958b9af9-ee98-48b8-985a-46a73dd16280"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.5487 - accuracy: 0.3831 - val_loss: 0.4524 - val_accuracy: 0.3448 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4478 - accuracy: 0.4935 - val_loss: 0.3860 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4253 - accuracy: 0.5108 - val_loss: 0.4012 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.4031 - accuracy: 0.5303 - val_loss: 0.3658 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3745 - accuracy: 0.5823 - val_loss: 0.3631 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3513 - accuracy: 0.5736 - val_loss: 0.3441 - val_accuracy: 0.5431 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3359 - accuracy: 0.5952 - val_loss: 0.3932 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3284 - accuracy: 0.6169 - val_loss: 0.3135 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2980 - accuracy: 0.6450 - val_loss: 0.3247 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3080 - accuracy: 0.6277 - val_loss: 0.3435 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3116 - accuracy: 0.6385 - val_loss: 0.3716 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2766 - accuracy: 0.6926 - val_loss: 0.3259 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2822 - accuracy: 0.6883 - val_loss: 0.3530 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2655 - accuracy: 0.6948 - val_loss: 0.3124 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2535 - accuracy: 0.7359 - val_loss: 0.3107 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2606 - accuracy: 0.7165 - val_loss: 0.3607 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2624 - accuracy: 0.7143 - val_loss: 0.4390 - val_accuracy: 0.5517 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2804 - accuracy: 0.6818 - val_loss: 0.3397 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2269 - accuracy: 0.7576 - val_loss: 0.3054 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2317 - accuracy: 0.7294 - val_loss: 0.3144 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2427 - accuracy: 0.7381 - val_loss: 0.3323 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - ETA: 0s - loss: 0.2270 - accuracy: 0.7532\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2270 - accuracy: 0.7532 - val_loss: 0.3933 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1833 - accuracy: 0.8052 - val_loss: 0.3059 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1865 - accuracy: 0.7857 - val_loss: 0.2905 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1732 - accuracy: 0.8203Restoring model weights from the end of the best epoch: 15.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1732 - accuracy: 0.8203 - val_loss: 0.2830 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 25: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.3002 - accuracy: 0.6905 - val_loss: 0.2519 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2900 - accuracy: 0.6797 - val_loss: 0.3315 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.7251 - val_loss: 0.2303 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2737 - accuracy: 0.7121 - val_loss: 0.2768 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2542 - accuracy: 0.7121 - val_loss: 0.2697 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2276 - accuracy: 0.7684 - val_loss: 0.2893 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2215 - accuracy: 0.7576 - val_loss: 0.2685 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2367 - accuracy: 0.7662 - val_loss: 0.3317 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2170 - accuracy: 0.7554 - val_loss: 0.2962 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 10/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.2100 - accuracy: 0.7703\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2115 - accuracy: 0.7662 - val_loss: 0.2849 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1844 - accuracy: 0.8117 - val_loss: 0.2631 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1783 - accuracy: 0.8160 - val_loss: 0.2183 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 13/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1627 - accuracy: 0.8401Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1673 - accuracy: 0.8355 - val_loss: 0.2756 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.2681 - accuracy: 0.7273 - val_loss: 0.2301 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2596 - accuracy: 0.7013 - val_loss: 0.2792 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2574 - accuracy: 0.7273 - val_loss: 0.3207 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3005 - accuracy: 0.6883 - val_loss: 0.3503 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2774 - accuracy: 0.6883 - val_loss: 0.2947 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2335 - accuracy: 0.7381 - val_loss: 0.2622 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.7576 - val_loss: 0.2634 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2051 - accuracy: 0.7684 - val_loss: 0.2695 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2022 - accuracy: 0.7706 - val_loss: 0.2604 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2132 - accuracy: 0.7554 - val_loss: 0.2278 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1981 - accuracy: 0.7619 - val_loss: 0.3055 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1867 - accuracy: 0.7965 - val_loss: 0.2488 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2010 - accuracy: 0.7727 - val_loss: 0.2545 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 14/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.1752 - accuracy: 0.7948\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1779 - accuracy: 0.7922 - val_loss: 0.2976 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1650 - accuracy: 0.8247 - val_loss: 0.4228 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1507 - accuracy: 0.8290 - val_loss: 0.2654 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 17/30\n","101/116 [=========================>....] - ETA: 0s - loss: 0.1428 - accuracy: 0.8317Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1493 - accuracy: 0.8333 - val_loss: 0.2416 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 1 0 0 0]\n","0.6\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 1 0 0 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 1 0 0 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 7ms/step - loss: 0.2600 - accuracy: 0.7171 - val_loss: 0.1647 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2277 - accuracy: 0.7408 - val_loss: 0.1835 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2325 - accuracy: 0.7451 - val_loss: 0.1504 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2378 - accuracy: 0.7408 - val_loss: 0.2164 - val_accuracy: 0.7826 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2458 - accuracy: 0.7214 - val_loss: 0.1719 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3121 - accuracy: 0.6782 - val_loss: 0.2418 - val_accuracy: 0.6696 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2381 - accuracy: 0.7279 - val_loss: 0.1843 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2174 - accuracy: 0.7819 - val_loss: 0.1619 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2308 - accuracy: 0.7495 - val_loss: 0.2567 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 10/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.2504 - accuracy: 0.7434\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2499 - accuracy: 0.7451 - val_loss: 0.1751 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.8207 - val_loss: 0.1403 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1661 - accuracy: 0.8143 - val_loss: 0.1771 - val_accuracy: 0.7913 - lr: 5.0000e-04\n","Epoch 13/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.8304Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1578 - accuracy: 0.8315 - val_loss: 0.2032 - val_accuracy: 0.7826 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2161 - accuracy: 0.7754 - val_loss: 0.2462 - val_accuracy: 0.7130 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1851 - accuracy: 0.8099 - val_loss: 0.2638 - val_accuracy: 0.6783 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2133 - accuracy: 0.7603 - val_loss: 0.2437 - val_accuracy: 0.6957 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1873 - accuracy: 0.8013 - val_loss: 0.2246 - val_accuracy: 0.7043 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1856 - accuracy: 0.7970 - val_loss: 0.2546 - val_accuracy: 0.6522 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.8359 - val_loss: 0.2499 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1769 - accuracy: 0.8013 - val_loss: 0.2609 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1867 - accuracy: 0.8121 - val_loss: 0.5163 - val_accuracy: 0.5913 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1984 - accuracy: 0.7948 - val_loss: 0.4215 - val_accuracy: 0.6087 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1664 - accuracy: 0.8143 - val_loss: 0.4451 - val_accuracy: 0.6000 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1585 - accuracy: 0.8402 - val_loss: 0.2663 - val_accuracy: 0.6957 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1703 - accuracy: 0.8402 - val_loss: 0.2678 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1603 - accuracy: 0.8467 - val_loss: 0.2531 - val_accuracy: 0.7652 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2149 - accuracy: 0.8099 - val_loss: 0.3641 - val_accuracy: 0.6348 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1558 - accuracy: 0.8467 - val_loss: 0.3299 - val_accuracy: 0.6957 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2063 - accuracy: 0.7754 - val_loss: 0.3501 - val_accuracy: 0.6522 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1626 - accuracy: 0.8294 - val_loss: 0.2808 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1705 - accuracy: 0.8143 - val_loss: 0.2883 - val_accuracy: 0.6348 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1553 - accuracy: 0.8531 - val_loss: 0.4353 - val_accuracy: 0.6174 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1745 - accuracy: 0.8121\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1745 - accuracy: 0.8121 - val_loss: 0.2858 - val_accuracy: 0.6696 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1200 - accuracy: 0.8790 - val_loss: 0.2827 - val_accuracy: 0.7391 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1189 - accuracy: 0.8812 - val_loss: 0.4263 - val_accuracy: 0.6522 - lr: 5.0000e-04\n","Epoch 23/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.1085 - accuracy: 0.8822Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.8790 - val_loss: 0.3201 - val_accuracy: 0.7217 - lr: 5.0000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","Average Accuracy:  0.6904947526236882\n","Accuracy:  0.904923538230884\n","Average Normalized Accuracy:  0.7075062468765617\n","Average Precision:  0.8106501135389863\n","Average Recall:  0.6960095323707566\n","F1 score: 0.7489683658446779\n","Grand Mean: 0.7597587582475924\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["## S5G Matrix Model"],"metadata":{"id":"1Zj7uaIMceME"}},{"cell_type":"code","source":["# Define the model\n","model_s5g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s5g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s5g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s5g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s5g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QB_KoJnwcV9H","executionInfo":{"status":"ok","timestamp":1697814094302,"user_tz":-330,"elapsed":78783,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"603bfbfd-a112-4ee4-d69d-334e88b16332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.5350 - accuracy: 0.4134 - val_loss: 0.4299 - val_accuracy: 0.3793 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4530 - accuracy: 0.4459 - val_loss: 0.4238 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.4365 - accuracy: 0.5130 - val_loss: 0.4182 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3966 - accuracy: 0.5606 - val_loss: 0.3597 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.3931 - accuracy: 0.5606 - val_loss: 0.3568 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3765 - accuracy: 0.5476 - val_loss: 0.3507 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3384 - accuracy: 0.6147 - val_loss: 0.3564 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3223 - accuracy: 0.6299 - val_loss: 0.3836 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3235 - accuracy: 0.6277 - val_loss: 0.3343 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3178 - accuracy: 0.6299 - val_loss: 0.3267 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3008 - accuracy: 0.6688 - val_loss: 0.3505 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2925 - accuracy: 0.6732 - val_loss: 0.4035 - val_accuracy: 0.5259 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2852 - accuracy: 0.6840 - val_loss: 0.3022 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2809 - accuracy: 0.6905 - val_loss: 0.3104 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2905 - accuracy: 0.6883 - val_loss: 0.3453 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2566 - accuracy: 0.7359 - val_loss: 0.3084 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2475 - accuracy: 0.7229 - val_loss: 0.3357 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2356 - accuracy: 0.7489 - val_loss: 0.3580 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2404 - accuracy: 0.7338 - val_loss: 0.3233 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2182 - accuracy: 0.7922 - val_loss: 0.3083 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 21/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.2351 - accuracy: 0.7500\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2347 - accuracy: 0.7489 - val_loss: 0.3437 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1928 - accuracy: 0.8030 - val_loss: 0.2905 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1778 - accuracy: 0.8182 - val_loss: 0.3196 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1863 - accuracy: 0.8182 - val_loss: 0.2976 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1712 - accuracy: 0.8290 - val_loss: 0.3512 - val_accuracy: 0.6466 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1672 - accuracy: 0.8420 - val_loss: 0.3900 - val_accuracy: 0.6293 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1749 - accuracy: 0.8268 - val_loss: 0.2879 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1615 - accuracy: 0.8593 - val_loss: 0.3381 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 29/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1498 - accuracy: 0.8528 - val_loss: 0.3302 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1488 - accuracy: 0.8506 - val_loss: 0.2877 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2208 - accuracy: 0.7792 - val_loss: 0.1985 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2015 - accuracy: 0.8030 - val_loss: 0.2567 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2155 - accuracy: 0.7749 - val_loss: 0.1533 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2349 - accuracy: 0.8160 - val_loss: 0.4552 - val_accuracy: 0.5690 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2517 - accuracy: 0.7511 - val_loss: 0.2418 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1860 - accuracy: 0.8225 - val_loss: 0.1568 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1793 - accuracy: 0.8333 - val_loss: 0.3062 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1858 - accuracy: 0.8247 - val_loss: 0.2637 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1743 - accuracy: 0.8117 - val_loss: 0.2211 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1680 - accuracy: 0.8377 - val_loss: 0.1607 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1722 - accuracy: 0.8420 - val_loss: 0.2709 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1618 - accuracy: 0.8268 - val_loss: 0.2071 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 13/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.1454 - accuracy: 0.8656\n","Epoch 13: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1641 - accuracy: 0.8463 - val_loss: 0.2784 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1580 - accuracy: 0.8377 - val_loss: 0.2055 - val_accuracy: 0.7759 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1340 - accuracy: 0.8874 - val_loss: 0.1768 - val_accuracy: 0.8190 - lr: 5.0000e-04\n","Epoch 16/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1141 - accuracy: 0.8941Restoring model weights from the end of the best epoch: 6.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1192 - accuracy: 0.8918 - val_loss: 0.1545 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 16: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1925 - accuracy: 0.7965 - val_loss: 0.1622 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2154 - accuracy: 0.8225 - val_loss: 0.2636 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1807 - accuracy: 0.8290 - val_loss: 0.1877 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1935 - accuracy: 0.8052 - val_loss: 0.1818 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1864 - accuracy: 0.8203 - val_loss: 0.1681 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1856 - accuracy: 0.8225 - val_loss: 0.2001 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1746 - accuracy: 0.8203 - val_loss: 0.1830 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1622 - accuracy: 0.8485 - val_loss: 0.2250 - val_accuracy: 0.7845 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1546 - accuracy: 0.8658 - val_loss: 0.6388 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1897 - accuracy: 0.8247 - val_loss: 0.1624 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1503 - accuracy: 0.8550 - val_loss: 0.1854 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1241 - accuracy: 0.8766 - val_loss: 0.2864 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1637 - accuracy: 0.8463 - val_loss: 0.2292 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2007 - accuracy: 0.8203 - val_loss: 0.2852 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1937 - accuracy: 0.7965 - val_loss: 0.2919 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1432 - accuracy: 0.8506 - val_loss: 0.1692 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1355 - accuracy: 0.8680 - val_loss: 0.1647 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1350 - accuracy: 0.8658 - val_loss: 0.1803 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1262 - accuracy: 0.8853 - val_loss: 0.1941 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1502 - accuracy: 0.8593 - val_loss: 0.2222 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1421 - accuracy: 0.8550 - val_loss: 0.2073 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 22/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1292 - accuracy: 0.8853 - val_loss: 0.2051 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1101 - accuracy: 0.8918 - val_loss: 0.2074 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 24/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.1165 - accuracy: 0.8853\n","Epoch 24: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.1134 - accuracy: 0.8896 - val_loss: 0.1897 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 25/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9069 - val_loss: 0.2632 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0926 - accuracy: 0.8939 - val_loss: 0.1937 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 27/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0776 - accuracy: 0.9261Restoring model weights from the end of the best epoch: 17.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9264 - val_loss: 0.3411 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 27: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1644 - accuracy: 0.8445 - val_loss: 0.1407 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1494 - accuracy: 0.8553 - val_loss: 0.2073 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1587 - accuracy: 0.8402 - val_loss: 0.1296 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1501 - accuracy: 0.8423 - val_loss: 0.1523 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1627 - accuracy: 0.8315 - val_loss: 0.1330 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1300 - accuracy: 0.8639 - val_loss: 0.1828 - val_accuracy: 0.7913 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1305 - accuracy: 0.8683 - val_loss: 0.0826 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1402 - accuracy: 0.8423 - val_loss: 0.1252 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1087 - accuracy: 0.8877 - val_loss: 0.1247 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1120 - accuracy: 0.8963 - val_loss: 0.1678 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1366 - accuracy: 0.8812 - val_loss: 0.4141 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1742 - accuracy: 0.8467 - val_loss: 0.1231 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1724 - accuracy: 0.8272 - val_loss: 0.1296 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 14/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1476 - accuracy: 0.8411\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1472 - accuracy: 0.8445 - val_loss: 0.1369 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1030 - accuracy: 0.9136 - val_loss: 0.1077 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0927 - accuracy: 0.9136 - val_loss: 0.1098 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 17/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0800 - accuracy: 0.9302Restoring model weights from the end of the best epoch: 7.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0819 - accuracy: 0.9266 - val_loss: 0.1173 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 17: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1640 - accuracy: 0.8488 - val_loss: 0.1824 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1385 - accuracy: 0.8618 - val_loss: 0.1946 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1433 - accuracy: 0.8661 - val_loss: 0.1609 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1150 - accuracy: 0.8920 - val_loss: 0.1036 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1384 - accuracy: 0.8683 - val_loss: 0.3670 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.8294 - val_loss: 0.1367 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1031 - accuracy: 0.9006 - val_loss: 0.1646 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1162 - accuracy: 0.8834 - val_loss: 0.1559 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1130 - accuracy: 0.8834 - val_loss: 0.1200 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1198 - accuracy: 0.8877 - val_loss: 0.1312 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1036 - accuracy: 0.9043\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1044 - accuracy: 0.9050 - val_loss: 0.1305 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0844 - accuracy: 0.9136 - val_loss: 0.1407 - val_accuracy: 0.8174 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0758 - accuracy: 0.9244 - val_loss: 0.1836 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 14/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0754 - accuracy: 0.9174Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0732 - accuracy: 0.9201 - val_loss: 0.1385 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8030284857571216\n","Accuracy:  0.9419550224887553\n","Average Normalized Accuracy:  0.8174612693653174\n","Average Precision:  0.9111974080136145\n","Average Recall:  0.8018969305411006\n","F1 score: 0.8530603226668555\n","Grand Mean: 0.854766573138794\n"]}]},{"cell_type":"markdown","source":["## S6G Matrix Model"],"metadata":{"id":"JlC0wh1QclCg"}},{"cell_type":"code","source":["# Define the model\n","model_s6g_1 = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s6g_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s6g_1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s6g_1.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s6g_1.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EuAunMY9clhs","executionInfo":{"status":"ok","timestamp":1697814185884,"user_tz":-330,"elapsed":90616,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"126f902e-b219-4ed2-b285-cb8dc5f1865a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.5822 - accuracy: 0.4264 - val_loss: 0.4148 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4555 - accuracy: 0.5216 - val_loss: 0.4029 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4327 - accuracy: 0.5303 - val_loss: 0.3993 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.4067 - accuracy: 0.5411 - val_loss: 0.3998 - val_accuracy: 0.4741 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.4013 - accuracy: 0.5238 - val_loss: 0.3424 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3883 - accuracy: 0.5693 - val_loss: 0.3506 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3776 - accuracy: 0.5476 - val_loss: 0.3346 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3410 - accuracy: 0.5779 - val_loss: 0.3211 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.6190 - val_loss: 0.2971 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.3253 - accuracy: 0.6385 - val_loss: 0.3571 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2999 - accuracy: 0.6558 - val_loss: 0.3068 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3030 - accuracy: 0.6277 - val_loss: 0.2864 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2999 - accuracy: 0.6537 - val_loss: 0.2978 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2859 - accuracy: 0.6883 - val_loss: 0.3347 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2757 - accuracy: 0.6861 - val_loss: 0.2745 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2790 - accuracy: 0.6861 - val_loss: 0.2946 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3117 - accuracy: 0.6558 - val_loss: 0.3182 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2583 - accuracy: 0.7208 - val_loss: 0.2826 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2368 - accuracy: 0.7597 - val_loss: 0.2911 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2483 - accuracy: 0.7338 - val_loss: 0.3077 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2211 - accuracy: 0.7727 - val_loss: 0.2768 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 22/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.2117 - accuracy: 0.7675\n","Epoch 22: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2103 - accuracy: 0.7684 - val_loss: 0.3216 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 23/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1975 - accuracy: 0.7922 - val_loss: 0.3486 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2438 - accuracy: 0.7359 - val_loss: 0.2671 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 25/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1833 - accuracy: 0.8411Restoring model weights from the end of the best epoch: 15.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1818 - accuracy: 0.8420 - val_loss: 0.3396 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 25: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.2837 - accuracy: 0.6840 - val_loss: 0.3616 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.3000 - accuracy: 0.6688 - val_loss: 0.2927 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2988 - accuracy: 0.6840 - val_loss: 0.2681 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2598 - accuracy: 0.7121 - val_loss: 0.2444 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2508 - accuracy: 0.7338 - val_loss: 0.2314 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2464 - accuracy: 0.7078 - val_loss: 0.2317 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2357 - accuracy: 0.7381 - val_loss: 0.2782 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2970 - accuracy: 0.6840 - val_loss: 0.2719 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2643 - accuracy: 0.7100 - val_loss: 0.2740 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2531 - accuracy: 0.7359 - val_loss: 0.3187 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2298 - accuracy: 0.7597 - val_loss: 0.2785 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 12/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.2126 - accuracy: 0.7818\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2166 - accuracy: 0.7749 - val_loss: 0.2822 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1956 - accuracy: 0.7749 - val_loss: 0.2318 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1775 - accuracy: 0.8268 - val_loss: 0.2345 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 15/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.1857 - accuracy: 0.7928Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1863 - accuracy: 0.7900 - val_loss: 0.2578 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.2601 - accuracy: 0.7294 - val_loss: 0.5203 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2682 - accuracy: 0.7013 - val_loss: 0.2814 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2342 - accuracy: 0.7446 - val_loss: 0.2370 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2369 - accuracy: 0.7489 - val_loss: 0.2413 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2207 - accuracy: 0.7662 - val_loss: 0.2506 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2377 - accuracy: 0.7532 - val_loss: 0.3204 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2327 - accuracy: 0.7532 - val_loss: 0.2877 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2281 - accuracy: 0.7381 - val_loss: 0.2524 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2004 - accuracy: 0.8009 - val_loss: 0.2272 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1794 - accuracy: 0.8009 - val_loss: 0.2234 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1775 - accuracy: 0.8074 - val_loss: 0.2574 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1923 - accuracy: 0.7814 - val_loss: 0.2909 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2649 - accuracy: 0.7121 - val_loss: 0.3332 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3122 - accuracy: 0.6861 - val_loss: 0.3032 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2076 - accuracy: 0.7792 - val_loss: 0.3257 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 16/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.2090 - accuracy: 0.7948\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2066 - accuracy: 0.8052 - val_loss: 0.2355 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1663 - accuracy: 0.8290 - val_loss: 0.2367 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1530 - accuracy: 0.8506 - val_loss: 0.2480 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 19/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1454 - accuracy: 0.8630Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1456 - accuracy: 0.8636 - val_loss: 0.2514 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 1 0 0 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 4s 13ms/step - loss: 0.2365 - accuracy: 0.7300 - val_loss: 0.1505 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2475 - accuracy: 0.7473 - val_loss: 0.1848 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2625 - accuracy: 0.7408 - val_loss: 0.1583 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2187 - accuracy: 0.7559 - val_loss: 0.1875 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2028 - accuracy: 0.7927 - val_loss: 0.1406 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2023 - accuracy: 0.8035 - val_loss: 0.1397 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1954 - accuracy: 0.7905 - val_loss: 0.1624 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1918 - accuracy: 0.8078 - val_loss: 0.1322 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 2s 16ms/step - loss: 0.1970 - accuracy: 0.8013 - val_loss: 0.1418 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 2s 15ms/step - loss: 0.1804 - accuracy: 0.8229 - val_loss: 0.1302 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1765 - accuracy: 0.8272 - val_loss: 0.2104 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 12/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.2163 - accuracy: 0.7924\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2128 - accuracy: 0.7970 - val_loss: 0.2589 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1619 - accuracy: 0.8402 - val_loss: 0.1430 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1511 - accuracy: 0.8510 - val_loss: 0.1806 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 15/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1380 - accuracy: 0.8804Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1377 - accuracy: 0.8812 - val_loss: 0.1502 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 10ms/step - loss: 0.2149 - accuracy: 0.7905 - val_loss: 0.2100 - val_accuracy: 0.7652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1760 - accuracy: 0.8467 - val_loss: 0.2341 - val_accuracy: 0.7217 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1732 - accuracy: 0.8229 - val_loss: 0.2995 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1694 - accuracy: 0.8337 - val_loss: 0.1875 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1741 - accuracy: 0.8488 - val_loss: 0.2842 - val_accuracy: 0.6783 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1613 - accuracy: 0.8315 - val_loss: 0.2283 - val_accuracy: 0.7391 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1639 - accuracy: 0.8402 - val_loss: 0.2067 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1655 - accuracy: 0.8272 - val_loss: 0.2202 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1562 - accuracy: 0.8575 - val_loss: 0.3293 - val_accuracy: 0.7043 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1757 - accuracy: 0.8251 - val_loss: 0.2245 - val_accuracy: 0.7478 - lr: 0.0010\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.1682 - accuracy: 0.8407\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1693 - accuracy: 0.8402 - val_loss: 0.2623 - val_accuracy: 0.6870 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.8877 - val_loss: 0.2199 - val_accuracy: 0.7826 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1094 - accuracy: 0.8942 - val_loss: 0.2290 - val_accuracy: 0.7478 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - ETA: 0s - loss: 0.1089 - accuracy: 0.8942Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1089 - accuracy: 0.8942 - val_loss: 0.2373 - val_accuracy: 0.8000 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","Average Accuracy:  0.6508395802098951\n","Accuracy:  0.9087256371814085\n","Average Normalized Accuracy:  0.6687356321839081\n","Average Precision:  0.8565395472394947\n","Average Recall:  0.6592755366835472\n","F1 score: 0.7450718437707143\n","Grand Mean: 0.7481979628781614\n"]}]},{"cell_type":"markdown","source":["# Standardizing SkipGram"],"metadata":{"id":"P_mQUI-Be9za"}},{"cell_type":"code","source":["# standardize the sxgbg_matrix\n","import numpy as np\n","\n","def calculate_sxgbg_stan_features(evolutionary_profile, X):\n","    L, _ = evolutionary_profile.shape\n","    sxgbg_matrix = np.zeros((20, 20))\n","\n","    for i in range(20):\n","        for j in range(20):\n","            sxgbg_value = 0.0\n","\n","            for l in range(1, L - X):\n","                sxgbg_value += evolutionary_profile[l - 1, i] * evolutionary_profile[l + X, j]\n","\n","            sxgbg_matrix[i, j] = sxgbg_value\n","\n","    # Standardize the sxgbg_matrix (z-score normalization)\n","    mean = np.mean(sxgbg_matrix)\n","    std = np.std(sxgbg_matrix)\n","\n","    if std != 0:\n","        sxgbg_matrix = (sxgbg_matrix - mean) / std\n","    else:\n","        sxgbg_matrix = np.zeros_like(sxgbg_matrix)  # Handle the case of zero standard deviation\n","\n","    return sxgbg_matrix"],"metadata":{"id":"_6Ir9uBOfBeF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Stan"],"metadata":{"id":"O3fP4RaxfJWk"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s0g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s0g_mat = calculate_sxgbg_stan_features(i, 0)\n","    s0g_arr = np.array(s0g_mat)\n","    s0g_stan_matrix.append(s0g_arr)\n","\n","df['s0g_stan_matrix'] = s0g_stan_matrix"],"metadata":{"id":"6GOdizvWfCNk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S1G Stan"],"metadata":{"id":"o45MENkxfSjV"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s1g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s1g_mat = calculate_sxgbg_stan_features(i, 1)\n","    s1g_arr = np.array(s1g_mat)\n","    s1g_stan_matrix.append(s1g_arr)\n","\n","df['s1g_stan_matrix'] = s1g_stan_matrix"],"metadata":{"id":"K8UEDzpffR4A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S2G Stan"],"metadata":{"id":"Ou_4eSXLfhmX"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s2g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s2g_mat = calculate_sxgbg_stan_features(i, 2)\n","    s2g_arr = np.array(s2g_mat)\n","    s2g_stan_matrix.append(s2g_arr)\n","\n","df['s2g_stan_matrix'] = s2g_stan_matrix"],"metadata":{"id":"rZqYeKImfax9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S3G Stan"],"metadata":{"id":"cH5KByK2fpsT"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s3g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s3g_mat = calculate_sxgbg_stan_features(i, 3)\n","    s3g_arr = np.array(s3g_mat)\n","    s3g_stan_matrix.append(s3g_arr)\n","\n","df['s3g_stan_matrix'] = s3g_stan_matrix"],"metadata":{"id":"zU1ctHJefjYf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S4G Stan"],"metadata":{"id":"8-8iUCqKfyVk"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s4g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s4g_mat = calculate_sxgbg_stan_features(i, 4)\n","    s4g_arr = np.array(s4g_mat)\n","    s4g_stan_matrix.append(s4g_arr)\n","\n","df['s4g_stan_matrix'] = s4g_stan_matrix"],"metadata":{"id":"7awNJJx9fsIq"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S5G Stan"],"metadata":{"id":"enK9ZSyYf2oJ"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s5g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s5g_mat = calculate_sxgbg_stan_features(i, 5)\n","    s5g_arr = np.array(s5g_mat)\n","    s5g_stan_matrix.append(s5g_arr)\n","\n","df['s5g_stan_matrix'] = s5g_stan_matrix"],"metadata":{"id":"x2iGPewVf19F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S6G Stan"],"metadata":{"id":"oA0OrXLuf_Iv"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Create an empty list to store hmm_arr for each PDBid\n","s6g_stan_matrix = []\n","\n","for i in df['hmm_matrix']:\n","    s6g_mat = calculate_sxgbg_stan_features(i, 6)\n","    s6g_arr = np.array(s6g_mat)\n","    s6g_stan_matrix.append(s6g_arr)\n","\n","df['s6g_stan_matrix'] = s6g_stan_matrix"],"metadata":{"id":"2Vssn4gOf4q9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## S0G Stan Matrix Model"],"metadata":{"id":"rD59vdL8g12Z"}},{"cell_type":"code","source":["# Define the model\n","model_s0g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s0g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s0g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s0g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s0g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZrwlgOdEgKKT","executionInfo":{"status":"ok","timestamp":1697812934035,"user_tz":-330,"elapsed":116095,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"17e8f52e-ede6-419a-b8f3-3f3a35c2b278"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 13ms/step - loss: 0.4216 - accuracy: 0.4827 - val_loss: 0.3858 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.3349 - accuracy: 0.6082 - val_loss: 0.4075 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 2s 16ms/step - loss: 0.3076 - accuracy: 0.6667 - val_loss: 0.3237 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 2s 14ms/step - loss: 0.2592 - accuracy: 0.7165 - val_loss: 0.3150 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2459 - accuracy: 0.7597 - val_loss: 0.2958 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2109 - accuracy: 0.8052 - val_loss: 0.2871 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2057 - accuracy: 0.7835 - val_loss: 0.3243 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1807 - accuracy: 0.8420 - val_loss: 0.2800 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1565 - accuracy: 0.8615 - val_loss: 0.2896 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 10ms/step - loss: 0.1510 - accuracy: 0.8636 - val_loss: 0.2802 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1368 - accuracy: 0.8853 - val_loss: 0.3141 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1214 - accuracy: 0.8961 - val_loss: 0.3468 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1277 - accuracy: 0.8896 - val_loss: 0.3015 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0928 - accuracy: 0.9221 - val_loss: 0.3100 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1026 - accuracy: 0.9156 - val_loss: 0.3659 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 2s 17ms/step - loss: 0.0998 - accuracy: 0.9156 - val_loss: 0.3259 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 2s 14ms/step - loss: 0.0790 - accuracy: 0.9177 - val_loss: 0.4059 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 18/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.0704 - accuracy: 0.9221 - val_loss: 0.3281 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0708 - accuracy: 0.9329 - val_loss: 0.3227 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 20/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9348\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0681 - accuracy: 0.9351 - val_loss: 0.4556 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 21/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0511 - accuracy: 0.9524 - val_loss: 0.3684 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0301 - accuracy: 0.9654 - val_loss: 0.4030 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 23/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0257 - accuracy: 0.9587Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0257 - accuracy: 0.9589 - val_loss: 0.4260 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 1]\n","0.4\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 1 0]\n","0.4\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 4s 14ms/step - loss: 0.1735 - accuracy: 0.8420 - val_loss: 0.1107 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 2s 18ms/step - loss: 0.1556 - accuracy: 0.8528 - val_loss: 0.0904 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 2s 18ms/step - loss: 0.1129 - accuracy: 0.8961 - val_loss: 0.1152 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.1003 - accuracy: 0.9026 - val_loss: 0.1441 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1079 - accuracy: 0.8961 - val_loss: 0.0892 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0947 - accuracy: 0.9069 - val_loss: 0.0962 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1026 - accuracy: 0.9091 - val_loss: 0.1209 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0707 - accuracy: 0.9264 - val_loss: 0.1184 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 9/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0693 - accuracy: 0.9263\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0713 - accuracy: 0.9264 - val_loss: 0.2213 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0566 - accuracy: 0.9416 - val_loss: 0.1483 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9654 - val_loss: 0.1253 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 12/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0430 - accuracy: 0.9550Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0426 - accuracy: 0.9567 - val_loss: 0.1459 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 4s 23ms/step - loss: 0.1269 - accuracy: 0.8766 - val_loss: 0.1214 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.1079 - accuracy: 0.8961 - val_loss: 0.1521 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0943 - accuracy: 0.9134 - val_loss: 0.1220 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1050 - accuracy: 0.8961 - val_loss: 0.1315 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0756 - accuracy: 0.9113 - val_loss: 0.1750 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0837 - accuracy: 0.9091 - val_loss: 0.1357 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0857 - accuracy: 0.9221 - val_loss: 0.1300 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0635 - accuracy: 0.9502 - val_loss: 0.1572 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0689 - accuracy: 0.9351 - val_loss: 0.1486 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 10/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0425 - accuracy: 0.9535\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0425 - accuracy: 0.9545 - val_loss: 0.1557 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0380 - accuracy: 0.9632 - val_loss: 0.1755 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0278 - accuracy: 0.9805 - val_loss: 0.1676 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 13/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0226 - accuracy: 0.9777Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0222 - accuracy: 0.9784 - val_loss: 0.1584 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 10ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 4s 13ms/step - loss: 0.1132 - accuracy: 0.8834 - val_loss: 0.0607 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0971 - accuracy: 0.9028 - val_loss: 0.0665 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0938 - accuracy: 0.9201 - val_loss: 0.1062 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1046 - accuracy: 0.9006 - val_loss: 0.1051 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0781 - accuracy: 0.9287 - val_loss: 0.0982 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0654 - accuracy: 0.9395 - val_loss: 0.1155 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0651 - accuracy: 0.9287 - val_loss: 0.1016 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 8/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0879 - accuracy: 0.9136\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0878 - accuracy: 0.9114 - val_loss: 0.0762 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0501 - accuracy: 0.9590 - val_loss: 0.0614 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0358 - accuracy: 0.9676 - val_loss: 0.0634 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 11/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0323 - accuracy: 0.9646Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 10ms/step - loss: 0.0316 - accuracy: 0.9654 - val_loss: 0.1033 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 15ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 5s 12ms/step - loss: 0.1138 - accuracy: 0.9006 - val_loss: 0.0880 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0878 - accuracy: 0.9050 - val_loss: 0.1082 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0857 - accuracy: 0.9266 - val_loss: 0.0889 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0709 - accuracy: 0.9395 - val_loss: 0.0857 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0652 - accuracy: 0.9374 - val_loss: 0.1005 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0510 - accuracy: 0.9417 - val_loss: 0.0983 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0544 - accuracy: 0.9460 - val_loss: 0.1905 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0641 - accuracy: 0.9374 - val_loss: 0.1510 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0650 - accuracy: 0.9287 - val_loss: 0.1798 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0494 - accuracy: 0.9546 - val_loss: 0.1361 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0464 - accuracy: 0.9438\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0464 - accuracy: 0.9438 - val_loss: 0.2079 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.0361 - accuracy: 0.9633 - val_loss: 0.2039 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.0182 - accuracy: 0.9741 - val_loss: 0.1931 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 14/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0163 - accuracy: 0.9739Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 12ms/step - loss: 0.0162 - accuracy: 0.9741 - val_loss: 0.1878 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8496851574212894\n","Accuracy:  0.9540509745127433\n","Average Normalized Accuracy:  0.8649725137431284\n","Average Precision:  0.9210741810331967\n","Average Recall:  0.8565046617899789\n","F1 score: 0.8876166962657713\n","Grand Mean: 0.8889840307943513\n"]}]},{"cell_type":"markdown","source":["## S1G Stan Matrix Model"],"metadata":{"id":"Wdu9UxNshPwF"}},{"cell_type":"code","source":["# Define the model\n","model_s1g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s1g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s1g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s1g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s1g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3fqQtZnjhDV6","executionInfo":{"status":"ok","timestamp":1697813009411,"user_tz":-330,"elapsed":75379,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"cc7d13dd-eba7-4bde-e870-505dd437b386"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.4061 - accuracy: 0.4892 - val_loss: 0.3667 - val_accuracy: 0.4828 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3441 - accuracy: 0.5952 - val_loss: 0.3301 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.3014 - accuracy: 0.6775 - val_loss: 0.3316 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 12ms/step - loss: 0.2639 - accuracy: 0.6926 - val_loss: 0.2860 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2346 - accuracy: 0.7554 - val_loss: 0.2788 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 11ms/step - loss: 0.2304 - accuracy: 0.7554 - val_loss: 0.2892 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1938 - accuracy: 0.8095 - val_loss: 0.3267 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2053 - accuracy: 0.7792 - val_loss: 0.2920 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1692 - accuracy: 0.8485 - val_loss: 0.2693 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1578 - accuracy: 0.8420 - val_loss: 0.2901 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1312 - accuracy: 0.8701 - val_loss: 0.3198 - val_accuracy: 0.6724 - lr: 0.0010\n","Epoch 12/30\n","107/116 [==========================>...] - ETA: 0s - loss: 0.1362 - accuracy: 0.8762\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1285 - accuracy: 0.8853 - val_loss: 0.3549 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0915 - accuracy: 0.9026 - val_loss: 0.3019 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0788 - accuracy: 0.9113 - val_loss: 0.2798 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 15/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0625 - accuracy: 0.9442Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9372 - val_loss: 0.3324 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 1 0]\n","0.4\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2420 - accuracy: 0.7359 - val_loss: 0.1960 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2007 - accuracy: 0.7944 - val_loss: 0.2353 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1872 - accuracy: 0.7987 - val_loss: 0.2256 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1525 - accuracy: 0.8485 - val_loss: 0.2285 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1411 - accuracy: 0.8506 - val_loss: 0.2405 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1522 - accuracy: 0.8333 - val_loss: 0.2295 - val_accuracy: 0.7586 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1332 - accuracy: 0.8745 - val_loss: 0.2578 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 8/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1135 - accuracy: 0.8843\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1217 - accuracy: 0.8788 - val_loss: 0.2599 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0902 - accuracy: 0.9134 - val_loss: 0.2284 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0706 - accuracy: 0.9177 - val_loss: 0.2144 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9286 - val_loss: 0.2644 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9242 - val_loss: 0.2817 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0657 - accuracy: 0.9177 - val_loss: 0.2533 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9394 - val_loss: 0.2814 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0500 - accuracy: 0.9416 - val_loss: 0.3320 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 16/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9292\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0510 - accuracy: 0.9307 - val_loss: 0.2411 - val_accuracy: 0.7500 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0364 - accuracy: 0.9545 - val_loss: 0.2541 - val_accuracy: 0.7672 - lr: 2.5000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0299 - accuracy: 0.9610 - val_loss: 0.2697 - val_accuracy: 0.7414 - lr: 2.5000e-04\n","Epoch 19/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0267 - accuracy: 0.9653Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 2s 13ms/step - loss: 0.0271 - accuracy: 0.9654 - val_loss: 0.2598 - val_accuracy: 0.7672 - lr: 2.5000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1491 - accuracy: 0.8615 - val_loss: 0.1589 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.8680 - val_loss: 0.1076 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1078 - accuracy: 0.8939 - val_loss: 0.2268 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1053 - accuracy: 0.9004 - val_loss: 0.1434 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1065 - accuracy: 0.8874 - val_loss: 0.1331 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1103 - accuracy: 0.9026 - val_loss: 0.1628 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0887 - accuracy: 0.9069 - val_loss: 0.1275 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0873 - accuracy: 0.9156 - val_loss: 0.1398 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0683 - accuracy: 0.9358\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0680 - accuracy: 0.9372 - val_loss: 0.1680 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0529 - accuracy: 0.9545 - val_loss: 0.1401 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0398 - accuracy: 0.9589 - val_loss: 0.1354 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 12/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0375 - accuracy: 0.9583Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0357 - accuracy: 0.9610 - val_loss: 0.1800 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1404 - accuracy: 0.8618 - val_loss: 0.0920 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1191 - accuracy: 0.9006 - val_loss: 0.1241 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.8942 - val_loss: 0.1120 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1141 - accuracy: 0.8747 - val_loss: 0.1799 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0952 - accuracy: 0.8963 - val_loss: 0.0805 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0945 - accuracy: 0.9114 - val_loss: 0.1266 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0710 - accuracy: 0.9287 - val_loss: 0.1028 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1041 - accuracy: 0.9093 - val_loss: 0.1974 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0714 - accuracy: 0.9201 - val_loss: 0.1566 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0710 - accuracy: 0.9266 - val_loss: 0.1657 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0549 - accuracy: 0.9395 - val_loss: 0.0787 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 12/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0493 - accuracy: 0.9409\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0491 - accuracy: 0.9417 - val_loss: 0.1004 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0380 - accuracy: 0.9525 - val_loss: 0.1437 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9590 - val_loss: 0.1910 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 15/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0213 - accuracy: 0.9727Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0215 - accuracy: 0.9741 - val_loss: 0.1306 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.1100 - accuracy: 0.8942 - val_loss: 0.1073 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0954 - accuracy: 0.9071 - val_loss: 0.0877 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0812 - accuracy: 0.9266 - val_loss: 0.0990 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9244 - val_loss: 0.1102 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0698 - accuracy: 0.9352 - val_loss: 0.1687 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0665 - accuracy: 0.9503 - val_loss: 0.0917 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0509 - accuracy: 0.9417 - val_loss: 0.1094 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9330 - val_loss: 0.1576 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 9/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0589 - accuracy: 0.9292\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0614 - accuracy: 0.9309 - val_loss: 0.1748 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9525 - val_loss: 0.1394 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0230 - accuracy: 0.9654 - val_loss: 0.1492 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0224 - accuracy: 0.9698 - val_loss: 0.1314 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9676 - val_loss: 0.1264 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0193 - accuracy: 0.9676 - val_loss: 0.1369 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0147 - accuracy: 0.9719 - val_loss: 0.1560 - val_accuracy: 0.8783 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0149 - accuracy: 0.9784 - val_loss: 0.1548 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0161 - accuracy: 0.9676 - val_loss: 0.2249 - val_accuracy: 0.8087 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0233 - accuracy: 0.9698 - val_loss: 0.1526 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 19/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0127 - accuracy: 0.9676\n","Epoch 19: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0126 - accuracy: 0.9698 - val_loss: 0.1907 - val_accuracy: 0.8696 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0103 - accuracy: 0.9698 - val_loss: 0.1545 - val_accuracy: 0.8783 - lr: 2.5000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0069 - accuracy: 0.9741 - val_loss: 0.1423 - val_accuracy: 0.8870 - lr: 2.5000e-04\n","Epoch 22/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9741Restoring model weights from the end of the best epoch: 12.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0060 - accuracy: 0.9741 - val_loss: 0.1665 - val_accuracy: 0.8783 - lr: 2.5000e-04\n","Epoch 22: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 1 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.7753823088455772\n","Accuracy:  0.9346836581709143\n","Average Normalized Accuracy:  0.8076311844077961\n","Average Precision:  0.8663471069930202\n","Average Recall:  0.8178596621176067\n","F1 score: 0.841405420281073\n","Grand Mean: 0.8405515568026646\n"]}]},{"cell_type":"markdown","source":["## S2G Stan Matrix Model"],"metadata":{"id":"rpUjtyQ0hYYf"}},{"cell_type":"code","source":["# Define the model\n","model_s2g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s2g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s2g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s2g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s2g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jEc9ZxmlhGJH","executionInfo":{"status":"ok","timestamp":1697813073262,"user_tz":-330,"elapsed":63856,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"98b0ec1f-41e2-4ed5-9800-9e7b90579b25"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.4158 - accuracy: 0.4848 - val_loss: 0.3475 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3314 - accuracy: 0.6061 - val_loss: 0.3391 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2869 - accuracy: 0.7056 - val_loss: 0.3460 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2814 - accuracy: 0.7100 - val_loss: 0.3943 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2457 - accuracy: 0.7294 - val_loss: 0.4304 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2204 - accuracy: 0.7684 - val_loss: 0.3429 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1916 - accuracy: 0.8074 - val_loss: 0.3238 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1842 - accuracy: 0.8117 - val_loss: 0.3106 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1798 - accuracy: 0.8290 - val_loss: 0.3247 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1681 - accuracy: 0.8268 - val_loss: 0.2928 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.8615 - val_loss: 0.3211 - val_accuracy: 0.7328 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1444 - accuracy: 0.8550 - val_loss: 0.3345 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1311 - accuracy: 0.8766 - val_loss: 0.3315 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1068 - accuracy: 0.9048 - val_loss: 0.3832 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1069 - accuracy: 0.8961 - val_loss: 0.3701 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0881 - accuracy: 0.9177 - val_loss: 0.4454 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0865 - accuracy: 0.9264 - val_loss: 0.4227 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 18/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0864 - accuracy: 0.9119\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9026 - val_loss: 0.3671 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0621 - accuracy: 0.9567 - val_loss: 0.4193 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0461 - accuracy: 0.9632 - val_loss: 0.4280 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 21/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0426 - accuracy: 0.9653Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0420 - accuracy: 0.9654 - val_loss: 0.4523 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.2043 - accuracy: 0.7900 - val_loss: 0.1381 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.8333 - val_loss: 0.1485 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1346 - accuracy: 0.8550 - val_loss: 0.1223 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1221 - accuracy: 0.8723 - val_loss: 0.1915 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1218 - accuracy: 0.8723 - val_loss: 0.1606 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0954 - accuracy: 0.9026 - val_loss: 0.1246 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1025 - accuracy: 0.8983 - val_loss: 0.1808 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0888 - accuracy: 0.9069 - val_loss: 0.2106 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0965 - accuracy: 0.9069 - val_loss: 0.1413 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 10/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0854 - accuracy: 0.9243\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9221 - val_loss: 0.1995 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0616 - accuracy: 0.9459 - val_loss: 0.1361 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0451 - accuracy: 0.9589 - val_loss: 0.1552 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 13/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0398 - accuracy: 0.9572Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0399 - accuracy: 0.9589 - val_loss: 0.1840 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1422 - accuracy: 0.8442 - val_loss: 0.1391 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1253 - accuracy: 0.8788 - val_loss: 0.4933 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1304 - accuracy: 0.8788 - val_loss: 0.1153 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1017 - accuracy: 0.8983 - val_loss: 0.1666 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0985 - accuracy: 0.8896 - val_loss: 0.1570 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0909 - accuracy: 0.9113 - val_loss: 0.2457 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0916 - accuracy: 0.9177 - val_loss: 0.1386 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0835 - accuracy: 0.9026 - val_loss: 0.1454 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0750 - accuracy: 0.9221 - val_loss: 0.1265 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 10/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0664 - accuracy: 0.9327\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0711 - accuracy: 0.9307 - val_loss: 0.2152 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0608 - accuracy: 0.9394 - val_loss: 0.1276 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0394 - accuracy: 0.9610 - val_loss: 0.1219 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0351 - accuracy: 0.9632 - val_loss: 0.1263 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9632 - val_loss: 0.1525 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0275 - accuracy: 0.9654 - val_loss: 0.1603 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0263 - accuracy: 0.9654 - val_loss: 0.1439 - val_accuracy: 0.8448 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9654 - val_loss: 0.1850 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0281 - accuracy: 0.9654 - val_loss: 0.1491 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0240 - accuracy: 0.9675 - val_loss: 0.1780 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 20/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0195 - accuracy: 0.9605\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0193 - accuracy: 0.9610 - val_loss: 0.1930 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0231 - accuracy: 0.9740 - val_loss: 0.1559 - val_accuracy: 0.8621 - lr: 2.5000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0106 - accuracy: 0.9740 - val_loss: 0.1722 - val_accuracy: 0.8534 - lr: 2.5000e-04\n","Epoch 23/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0091 - accuracy: 0.9823Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0089 - accuracy: 0.9827 - val_loss: 0.1928 - val_accuracy: 0.8362 - lr: 2.5000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1126 - accuracy: 0.9179 - val_loss: 0.0690 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0833 - accuracy: 0.9201 - val_loss: 0.0457 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0664 - accuracy: 0.9417 - val_loss: 0.1077 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0778 - accuracy: 0.9266 - val_loss: 0.0761 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0474 - accuracy: 0.9417 - val_loss: 0.0885 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0594 - accuracy: 0.9374 - val_loss: 0.0694 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0544 - accuracy: 0.9525 - val_loss: 0.1379 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0795 - accuracy: 0.9244 - val_loss: 0.0865 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0594 - accuracy: 0.9314\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0586 - accuracy: 0.9330 - val_loss: 0.1216 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9568 - val_loss: 0.0725 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0248 - accuracy: 0.9762 - val_loss: 0.0666 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 12/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0190 - accuracy: 0.9745Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0208 - accuracy: 0.9698 - val_loss: 0.0836 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0927 - accuracy: 0.9006 - val_loss: 0.0957 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0687 - accuracy: 0.9330 - val_loss: 0.0602 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0660 - accuracy: 0.9266 - val_loss: 0.1037 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0678 - accuracy: 0.9330 - val_loss: 0.1161 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0506 - accuracy: 0.9417 - val_loss: 0.0886 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0497 - accuracy: 0.9525 - val_loss: 0.0653 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0562 - accuracy: 0.9287 - val_loss: 0.1121 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0474 - accuracy: 0.9503 - val_loss: 0.0896 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0386 - accuracy: 0.9500\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0375 - accuracy: 0.9525 - val_loss: 0.0708 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0214 - accuracy: 0.9719 - val_loss: 0.0661 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0174 - accuracy: 0.9741 - val_loss: 0.0864 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12/30\n","103/116 [=========================>....] - ETA: 0s - loss: 0.0202 - accuracy: 0.9709Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0186 - accuracy: 0.9719 - val_loss: 0.1144 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8359520239880058\n","Accuracy:  0.9533853073463266\n","Average Normalized Accuracy:  0.8543903048475763\n","Average Precision:  0.9152667520216395\n","Average Recall:  0.8567606485364209\n","F1 score: 0.8850478675430508\n","Grand Mean: 0.8834671507138366\n"]}]},{"cell_type":"markdown","source":["## S3G Stan Matrix Model"],"metadata":{"id":"67ZpxwcJhlVB"}},{"cell_type":"code","source":["# Define the model\n","model_s3g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s3g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s3g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s3g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s3g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Q5CEDkxXhHLu","executionInfo":{"status":"ok","timestamp":1697813134491,"user_tz":-330,"elapsed":61232,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"f68fc8d0-1330-4d75-cb87-6e13e99542be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.4436 - accuracy: 0.4610 - val_loss: 0.3591 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 2s 15ms/step - loss: 0.3412 - accuracy: 0.6320 - val_loss: 0.3475 - val_accuracy: 0.5345 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3081 - accuracy: 0.6190 - val_loss: 0.2901 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2612 - accuracy: 0.7121 - val_loss: 0.4022 - val_accuracy: 0.5603 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2460 - accuracy: 0.7359 - val_loss: 0.3135 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.2267 - accuracy: 0.7706 - val_loss: 0.3746 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2108 - accuracy: 0.7879 - val_loss: 0.2979 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1733 - accuracy: 0.8506 - val_loss: 0.2846 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1840 - accuracy: 0.8225 - val_loss: 0.2855 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1455 - accuracy: 0.8636 - val_loss: 0.3134 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1504 - accuracy: 0.8701 - val_loss: 0.3098 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1290 - accuracy: 0.8766 - val_loss: 0.2776 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1061 - accuracy: 0.9091 - val_loss: 0.3050 - val_accuracy: 0.7414 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1222 - accuracy: 0.8745 - val_loss: 0.3040 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1159 - accuracy: 0.8961 - val_loss: 0.3403 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 16/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9043\n","Epoch 16: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1003 - accuracy: 0.9048 - val_loss: 0.4152 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0699 - accuracy: 0.9394 - val_loss: 0.3145 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0597 - accuracy: 0.9416 - val_loss: 0.3305 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 19/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0672 - accuracy: 0.9197Restoring model weights from the end of the best epoch: 9.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0654 - accuracy: 0.9221 - val_loss: 0.3328 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 19: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1958 - accuracy: 0.8160 - val_loss: 0.3133 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1830 - accuracy: 0.7987 - val_loss: 0.1211 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1486 - accuracy: 0.8593 - val_loss: 0.2256 - val_accuracy: 0.7672 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1597 - accuracy: 0.8485 - val_loss: 0.1797 - val_accuracy: 0.7931 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1226 - accuracy: 0.9004 - val_loss: 0.1717 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.8939 - val_loss: 0.2088 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0924 - accuracy: 0.9242 - val_loss: 0.1696 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1008 - accuracy: 0.9048 - val_loss: 0.1468 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 9/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0885 - accuracy: 0.9152\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0872 - accuracy: 0.9177 - val_loss: 0.1755 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9177 - val_loss: 0.1909 - val_accuracy: 0.7672 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0503 - accuracy: 0.9545 - val_loss: 0.1669 - val_accuracy: 0.8103 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0525 - accuracy: 0.9416Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0525 - accuracy: 0.9416 - val_loss: 0.1826 - val_accuracy: 0.7931 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 8ms/step - loss: 0.1595 - accuracy: 0.8420 - val_loss: 0.1414 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1424 - accuracy: 0.8398 - val_loss: 0.1827 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1383 - accuracy: 0.8658 - val_loss: 0.1586 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.8939 - val_loss: 0.1642 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1193 - accuracy: 0.8918 - val_loss: 0.1607 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1061 - accuracy: 0.8918 - val_loss: 0.1799 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0910 - accuracy: 0.9069 - val_loss: 0.1734 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0978 - accuracy: 0.9074\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1029 - accuracy: 0.9004 - val_loss: 0.1526 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0675 - accuracy: 0.9372 - val_loss: 0.1841 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0518 - accuracy: 0.9567 - val_loss: 0.1739 - val_accuracy: 0.8276 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0417 - accuracy: 0.9719Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0417 - accuracy: 0.9719 - val_loss: 0.1705 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1553 - accuracy: 0.8402 - val_loss: 0.1087 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1596 - accuracy: 0.8423 - val_loss: 0.1201 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1386 - accuracy: 0.8467 - val_loss: 0.1302 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1101 - accuracy: 0.8877 - val_loss: 0.1254 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1093 - accuracy: 0.8920 - val_loss: 0.0987 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1112 - accuracy: 0.9050 - val_loss: 0.1403 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 2s 14ms/step - loss: 0.0857 - accuracy: 0.9114 - val_loss: 0.1178 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 8/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0840 - accuracy: 0.9219\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0836 - accuracy: 0.9222 - val_loss: 0.1566 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0636 - accuracy: 0.9330 - val_loss: 0.1305 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0489 - accuracy: 0.9546 - val_loss: 0.1293 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 11/30\n","104/116 [=========================>....] - ETA: 0s - loss: 0.0479 - accuracy: 0.9543Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0492 - accuracy: 0.9568 - val_loss: 0.1364 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1437 - accuracy: 0.8596 - val_loss: 0.1572 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1260 - accuracy: 0.8812 - val_loss: 0.1707 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1266 - accuracy: 0.8855 - val_loss: 0.1931 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1083 - accuracy: 0.8985 - val_loss: 0.1600 - val_accuracy: 0.8348 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0854 - accuracy: 0.9179 - val_loss: 0.1825 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0737 - accuracy: 0.9201 - val_loss: 0.1808 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0845 - accuracy: 0.9222 - val_loss: 0.1935 - val_accuracy: 0.8087 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9179 - val_loss: 0.2206 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0831 - accuracy: 0.9222 - val_loss: 0.2934 - val_accuracy: 0.7043 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0709 - accuracy: 0.9352 - val_loss: 0.2515 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0567 - accuracy: 0.9460\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0567 - accuracy: 0.9460 - val_loss: 0.2917 - val_accuracy: 0.7565 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0497 - accuracy: 0.9482 - val_loss: 0.2433 - val_accuracy: 0.8087 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0312 - accuracy: 0.9546 - val_loss: 0.2536 - val_accuracy: 0.7826 - lr: 5.0000e-04\n","Epoch 14/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0279 - accuracy: 0.9605Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0277 - accuracy: 0.9611 - val_loss: 0.2719 - val_accuracy: 0.7478 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.7683058470764618\n","Accuracy:  0.9374002998500744\n","Average Normalized Accuracy:  0.787056471764118\n","Average Precision:  0.9125989620569965\n","Average Recall:  0.7770813153081159\n","F1 score: 0.8394056689706316\n","Grand Mean: 0.836974760837733\n"]}]},{"cell_type":"markdown","source":["## S4G Stan Matrix Model"],"metadata":{"id":"mRzR808Thu9h"}},{"cell_type":"code","source":["# Define the model\n","model_s4g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s4g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s4g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s4g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s4g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"okX5aJI7hIJb","executionInfo":{"status":"ok","timestamp":1697813197868,"user_tz":-330,"elapsed":62042,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"b047fb26-ef74-4f45-ad95-9fdc0ee120a6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.4307 - accuracy: 0.4654 - val_loss: 0.3379 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3455 - accuracy: 0.6126 - val_loss: 0.3181 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.3057 - accuracy: 0.6580 - val_loss: 0.3024 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.2644 - accuracy: 0.7121 - val_loss: 0.3381 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2237 - accuracy: 0.7597 - val_loss: 0.3310 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1940 - accuracy: 0.8030 - val_loss: 0.3401 - val_accuracy: 0.6466 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.2176 - accuracy: 0.7489 - val_loss: 0.3186 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1813 - accuracy: 0.8377 - val_loss: 0.2959 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 9/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.1549 - accuracy: 0.8588\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1550 - accuracy: 0.8550 - val_loss: 0.3564 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1336 - accuracy: 0.8939 - val_loss: 0.3082 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1063 - accuracy: 0.8918 - val_loss: 0.3145 - val_accuracy: 0.6552 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9177 - val_loss: 0.3296 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0998 - accuracy: 0.9069 - val_loss: 0.3227 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0830 - accuracy: 0.9286 - val_loss: 0.3727 - val_accuracy: 0.6466 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0804 - accuracy: 0.9134 - val_loss: 0.3444 - val_accuracy: 0.6983 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9351 - val_loss: 0.3253 - val_accuracy: 0.6466 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0663 - accuracy: 0.9351 - val_loss: 0.3463 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0684 - accuracy: 0.9264 - val_loss: 0.3860 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0592 - accuracy: 0.9329 - val_loss: 0.3697 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 20/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0596 - accuracy: 0.9472\n","Epoch 20: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0603 - accuracy: 0.9416 - val_loss: 0.3664 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0409 - accuracy: 0.9632 - val_loss: 0.3892 - val_accuracy: 0.6552 - lr: 2.5000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0359 - accuracy: 0.9632 - val_loss: 0.3934 - val_accuracy: 0.6724 - lr: 2.5000e-04\n","Epoch 23/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0341 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 13.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0340 - accuracy: 0.9762 - val_loss: 0.4079 - val_accuracy: 0.6810 - lr: 2.5000e-04\n","Epoch 23: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 1 0 0 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.2015 - accuracy: 0.7900 - val_loss: 0.1257 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1447 - accuracy: 0.8571 - val_loss: 0.1115 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1333 - accuracy: 0.8658 - val_loss: 0.1388 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1494 - accuracy: 0.8593 - val_loss: 0.2062 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1144 - accuracy: 0.8918 - val_loss: 0.1723 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1099 - accuracy: 0.8961 - val_loss: 0.1550 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.1058 - accuracy: 0.8983 - val_loss: 0.1692 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0795 - accuracy: 0.9199\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0795 - accuracy: 0.9199 - val_loss: 0.1570 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0612 - accuracy: 0.9329 - val_loss: 0.1172 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0527 - accuracy: 0.9416 - val_loss: 0.1410 - val_accuracy: 0.8534 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9416Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0456 - accuracy: 0.9416 - val_loss: 0.1302 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1526 - accuracy: 0.8571 - val_loss: 0.1337 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1461 - accuracy: 0.8528 - val_loss: 0.1127 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1175 - accuracy: 0.8831 - val_loss: 0.1371 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1107 - accuracy: 0.8961 - val_loss: 0.1111 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9004 - val_loss: 0.1388 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0915 - accuracy: 0.9004 - val_loss: 0.1386 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0829 - accuracy: 0.9199 - val_loss: 0.1443 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1092 - accuracy: 0.8918 - val_loss: 0.1516 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0805 - accuracy: 0.9242 - val_loss: 0.2031 - val_accuracy: 0.8362 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0845 - accuracy: 0.9286 - val_loss: 0.1901 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0711 - accuracy: 0.9372\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0711 - accuracy: 0.9372 - val_loss: 0.2129 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0501 - accuracy: 0.9481 - val_loss: 0.1712 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0362 - accuracy: 0.9589 - val_loss: 0.1599 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 14/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0322 - accuracy: 0.9630Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0319 - accuracy: 0.9610 - val_loss: 0.1612 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1379 - accuracy: 0.8834 - val_loss: 0.0976 - val_accuracy: 0.8783 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1115 - accuracy: 0.9050 - val_loss: 0.0824 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1050 - accuracy: 0.9093 - val_loss: 0.0998 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1036 - accuracy: 0.9028 - val_loss: 0.0720 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0998 - accuracy: 0.9028 - val_loss: 0.1008 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0832 - accuracy: 0.9179 - val_loss: 0.0923 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0781 - accuracy: 0.9287 - val_loss: 0.1453 - val_accuracy: 0.8174 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0794 - accuracy: 0.9266 - val_loss: 0.0853 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 9/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0795 - accuracy: 0.9167\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0800 - accuracy: 0.9158 - val_loss: 0.1247 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0477 - accuracy: 0.9525 - val_loss: 0.0969 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9719 - val_loss: 0.0863 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9741 - val_loss: 0.0979 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0364 - accuracy: 0.9633 - val_loss: 0.0954 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0342 - accuracy: 0.9590 - val_loss: 0.1439 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0350 - accuracy: 0.9698 - val_loss: 0.1749 - val_accuracy: 0.8522 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9806 - val_loss: 0.2141 - val_accuracy: 0.8261 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0221 - accuracy: 0.9698 - val_loss: 0.1230 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 18/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0173 - accuracy: 0.9762\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0182 - accuracy: 0.9784 - val_loss: 0.1848 - val_accuracy: 0.8609 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0132 - accuracy: 0.9870 - val_loss: 0.1052 - val_accuracy: 0.8870 - lr: 2.5000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0103 - accuracy: 0.9827 - val_loss: 0.1172 - val_accuracy: 0.8783 - lr: 2.5000e-04\n","Epoch 21/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0112 - accuracy: 0.9779Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0113 - accuracy: 0.9784 - val_loss: 0.1426 - val_accuracy: 0.8870 - lr: 2.5000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.0835 - accuracy: 0.9179 - val_loss: 0.0496 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0833 - accuracy: 0.9201 - val_loss: 0.0666 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0781 - accuracy: 0.9330 - val_loss: 0.0843 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0690 - accuracy: 0.9244 - val_loss: 0.1058 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9244 - val_loss: 0.0922 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0476 - accuracy: 0.9460 - val_loss: 0.1384 - val_accuracy: 0.8435 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0686 - accuracy: 0.9266 - val_loss: 0.2618 - val_accuracy: 0.7739 - lr: 0.0010\n","Epoch 8/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0802 - accuracy: 0.9289\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9309 - val_loss: 0.0726 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0310 - accuracy: 0.9568 - val_loss: 0.0883 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0245 - accuracy: 0.9654 - val_loss: 0.1062 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0231 - accuracy: 0.9717Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0229 - accuracy: 0.9719 - val_loss: 0.0934 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8290104947526238\n","Accuracy:  0.9492173913043475\n","Average Normalized Accuracy:  0.8445877061469265\n","Average Precision:  0.9116878443879838\n","Average Recall:  0.8383927350497288\n","F1 score: 0.8735054538044343\n","Grand Mean: 0.8744002709076741\n"]}]},{"cell_type":"markdown","source":["## S5G Stan Matrix Model"],"metadata":{"id":"uB-yyawBiAiV"}},{"cell_type":"code","source":["# Define the model\n","model_s5g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s5g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s5g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s5g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s5g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UPB49B3ChMbY","executionInfo":{"status":"ok","timestamp":1697813271412,"user_tz":-330,"elapsed":73562,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"a89b74c3-7dd0-4bbe-d595-447fee6077c2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.4611 - accuracy: 0.4286 - val_loss: 0.3748 - val_accuracy: 0.5172 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.3272 - accuracy: 0.6407 - val_loss: 0.3354 - val_accuracy: 0.6034 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.2935 - accuracy: 0.6797 - val_loss: 0.4702 - val_accuracy: 0.4914 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2622 - accuracy: 0.7100 - val_loss: 0.3179 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2272 - accuracy: 0.7554 - val_loss: 0.2893 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2280 - accuracy: 0.7511 - val_loss: 0.2691 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.1949 - accuracy: 0.8095 - val_loss: 0.3348 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1776 - accuracy: 0.8333 - val_loss: 0.3085 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1634 - accuracy: 0.8571 - val_loss: 0.2728 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1592 - accuracy: 0.8355 - val_loss: 0.2706 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1376 - accuracy: 0.8723 - val_loss: 0.2546 - val_accuracy: 0.7241 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1257 - accuracy: 0.8636 - val_loss: 0.3289 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1249 - accuracy: 0.8874 - val_loss: 0.2814 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1198 - accuracy: 0.8788 - val_loss: 0.2980 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 15/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1015 - accuracy: 0.8961 - val_loss: 0.3292 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1007 - accuracy: 0.8896 - val_loss: 0.3100 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0947 - accuracy: 0.9091 - val_loss: 0.3630 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 18/30\n","106/116 [==========================>...] - ETA: 0s - loss: 0.0757 - accuracy: 0.9245\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0825 - accuracy: 0.9091 - val_loss: 0.3038 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0619 - accuracy: 0.9394 - val_loss: 0.3117 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0462 - accuracy: 0.9524 - val_loss: 0.3210 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0392 - accuracy: 0.9589 - val_loss: 0.3424 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0453 - accuracy: 0.9307 - val_loss: 0.3018 - val_accuracy: 0.7414 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0374 - accuracy: 0.9654 - val_loss: 0.3684 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9394 - val_loss: 0.3331 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0315 - accuracy: 0.9589 - val_loss: 0.3691 - val_accuracy: 0.7155 - lr: 5.0000e-04\n","Epoch 26/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.0272 - accuracy: 0.9740 - val_loss: 0.3927 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 27/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0389 - accuracy: 0.9481 - val_loss: 0.3731 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 28/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0275 - accuracy: 0.9654 - val_loss: 0.3623 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 29/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0296 - accuracy: 0.9671\n","Epoch 29: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0293 - accuracy: 0.9675 - val_loss: 0.3888 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 30/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0177 - accuracy: 0.9784 - val_loss: 0.3819 - val_accuracy: 0.7414 - lr: 2.5000e-04\n","4/4 [==============================] - 0s 3ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1528 - accuracy: 0.8636 - val_loss: 0.0902 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1033 - accuracy: 0.9004 - val_loss: 0.0515 - val_accuracy: 0.9828 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1148 - accuracy: 0.8701 - val_loss: 0.0966 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0675 - accuracy: 0.9329 - val_loss: 0.0867 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0689 - accuracy: 0.9199 - val_loss: 0.0579 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0709 - accuracy: 0.9242 - val_loss: 0.1569 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0576 - accuracy: 0.9394 - val_loss: 0.0612 - val_accuracy: 0.9483 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0681 - accuracy: 0.9264 - val_loss: 0.1621 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 9/30\n","109/116 [===========================>..] - ETA: 0s - loss: 0.0901 - accuracy: 0.9128\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9048 - val_loss: 0.2116 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0527 - accuracy: 0.9545 - val_loss: 0.0792 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0255 - accuracy: 0.9784 - val_loss: 0.0625 - val_accuracy: 0.9655 - lr: 5.0000e-04\n","Epoch 12/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0228 - accuracy: 0.9754Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0240 - accuracy: 0.9740 - val_loss: 0.0804 - val_accuracy: 0.9397 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 9ms/step - loss: 0.1084 - accuracy: 0.9113 - val_loss: 0.0779 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1048 - accuracy: 0.9004 - val_loss: 0.0602 - val_accuracy: 0.9569 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.1026 - accuracy: 0.9026 - val_loss: 0.1303 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0816 - accuracy: 0.9113 - val_loss: 0.0846 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0792 - accuracy: 0.9221 - val_loss: 0.2107 - val_accuracy: 0.7759 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0784 - accuracy: 0.9221 - val_loss: 0.0825 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0541 - accuracy: 0.9416 - val_loss: 0.0760 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9524 - val_loss: 0.0978 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 9/30\n","102/116 [=========================>....] - ETA: 0s - loss: 0.0577 - accuracy: 0.9314\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0527 - accuracy: 0.9394 - val_loss: 0.0886 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0279 - accuracy: 0.9697 - val_loss: 0.0743 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0224 - accuracy: 0.9740 - val_loss: 0.0679 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 12/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0201 - accuracy: 0.9775Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0223 - accuracy: 0.9762 - val_loss: 0.0606 - val_accuracy: 0.9310 - lr: 5.0000e-04\n","Epoch 12: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0926 - accuracy: 0.9071 - val_loss: 0.0629 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0930 - accuracy: 0.9050 - val_loss: 0.0552 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0718 - accuracy: 0.9136 - val_loss: 0.1047 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0711 - accuracy: 0.9460 - val_loss: 0.0407 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0557 - accuracy: 0.9482 - val_loss: 0.0824 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0416 - accuracy: 0.9741 - val_loss: 0.0333 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0511 - accuracy: 0.9525 - val_loss: 0.0420 - val_accuracy: 0.9478 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0623 - accuracy: 0.9438 - val_loss: 0.0880 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0586 - accuracy: 0.9438 - val_loss: 0.0724 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0610 - accuracy: 0.9309 - val_loss: 0.0651 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 11/30\n","102/116 [=========================>....] - ETA: 0s - loss: 0.0387 - accuracy: 0.9534\n","Epoch 11: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0411 - accuracy: 0.9525 - val_loss: 0.0959 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0349 - accuracy: 0.9503 - val_loss: 0.0747 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0179 - accuracy: 0.9784 - val_loss: 0.0588 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 14/30\n","108/116 [==========================>...] - ETA: 0s - loss: 0.0146 - accuracy: 0.9792Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0140 - accuracy: 0.9806 - val_loss: 0.0458 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 14: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 5ms/step - loss: 0.0873 - accuracy: 0.9158 - val_loss: 0.1471 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0647 - accuracy: 0.9330 - val_loss: 0.0461 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0560 - accuracy: 0.9374 - val_loss: 0.0637 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0573 - accuracy: 0.9395 - val_loss: 0.0672 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0933 - accuracy: 0.9028 - val_loss: 0.1600 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0597 - accuracy: 0.9395 - val_loss: 0.0861 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9568 - val_loss: 0.0879 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0463 - accuracy: 0.9460 - val_loss: 0.1693 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 9/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0782 - accuracy: 0.9286\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0877 - accuracy: 0.9222 - val_loss: 0.1629 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0450 - accuracy: 0.9568 - val_loss: 0.0563 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0204 - accuracy: 0.9784 - val_loss: 0.0509 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0170 - accuracy: 0.9762 - val_loss: 0.0501 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0157 - accuracy: 0.9762 - val_loss: 0.0603 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 6ms/step - loss: 0.0178 - accuracy: 0.9719 - val_loss: 0.0716 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0150 - accuracy: 0.9784 - val_loss: 0.0541 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 16/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0121 - accuracy: 0.9806 - val_loss: 0.0682 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0175 - accuracy: 0.9741 - val_loss: 0.1635 - val_accuracy: 0.8348 - lr: 5.0000e-04\n","Epoch 18/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0306 - accuracy: 0.9636\n","Epoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0292 - accuracy: 0.9654 - val_loss: 0.0615 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0091 - accuracy: 0.9806 - val_loss: 0.0527 - val_accuracy: 0.9478 - lr: 2.5000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0083 - accuracy: 0.9827 - val_loss: 0.0591 - val_accuracy: 0.9304 - lr: 2.5000e-04\n","Epoch 21/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0066 - accuracy: 0.9761Restoring model weights from the end of the best epoch: 11.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0070 - accuracy: 0.9762 - val_loss: 0.0563 - val_accuracy: 0.9478 - lr: 2.5000e-04\n","Epoch 21: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.873928035982009\n","Accuracy:  0.9633913043478259\n","Average Normalized Accuracy:  0.8906196901549226\n","Average Precision:  0.9382442696479874\n","Average Recall:  0.8834549835912024\n","F1 score: 0.910025707451468\n","Grand Mean: 0.9099439985292359\n"]}]},{"cell_type":"markdown","source":["## S5G Stan Matrix LSTM Model"],"metadata":{"id":"_f8WJz0eIFnu"}},{"cell_type":"code","source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow import keras\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import KFold\n","from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n","\n","# Define the model\n","model_lstmsn = keras.Sequential([\n","    keras.layers.Input(shape=(400,1)),\n","    keras.layers.LSTM(256, return_sequences=True, kernel_initializer = 'he_normal'),\n","    keras.layers.LSTM(128, return_sequences=True, kernel_initializer = 'he_normal'),  # Another LSTM layer with 64 units\n","    keras.layers.Flatten(),\n","    keras.layers.Dropout(0.3),\n","    keras.layers.Dense(64, activation='relu', kernel_initializer = 'he_normal'),     # Fully connected layer\n","    keras.layers.Dense(5, activation='sigmoid')    # Output layer with sigmoid activation for multi-label classification\n","])\n","\n","train_features = np.array(df['s5g_stan_matrix'].tolist())\n","train_features = train_features.reshape(-1, 400,1)\n","\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_lstmsn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=7, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=4, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_lstmsn.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_lstmsn.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eKR5NaoUIJMB","executionInfo":{"status":"ok","timestamp":1697890861934,"user_tz":-330,"elapsed":354445,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"d7fdf68e-56d3-4dd1-e319-6b1f1c7be5e9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 16s 49ms/step - loss: 0.5222 - accuracy: 0.4437 - val_loss: 0.3927 - val_accuracy: 0.5086 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.3944 - accuracy: 0.5195 - val_loss: 0.3519 - val_accuracy: 0.5776 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.3671 - accuracy: 0.5823 - val_loss: 0.3428 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.3353 - accuracy: 0.6082 - val_loss: 0.3354 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.3201 - accuracy: 0.6494 - val_loss: 0.3282 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.2908 - accuracy: 0.6861 - val_loss: 0.3097 - val_accuracy: 0.6638 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.2555 - accuracy: 0.7165 - val_loss: 0.3058 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.2313 - accuracy: 0.7511 - val_loss: 0.3299 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 9/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.2098 - accuracy: 0.7717\n","Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 5s 39ms/step - loss: 0.2096 - accuracy: 0.7727 - val_loss: 0.3434 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 5s 43ms/step - loss: 0.1745 - accuracy: 0.8030 - val_loss: 0.3277 - val_accuracy: 0.6897 - lr: 5.0000e-04\n","Epoch 11/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.1568 - accuracy: 0.8225 - val_loss: 0.3539 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.1366 - accuracy: 0.8550 - val_loss: 0.3611 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 13/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.1125 - accuracy: 0.8745 - val_loss: 0.3737 - val_accuracy: 0.6810 - lr: 5.0000e-04\n","Epoch 14/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1099 - accuracy: 0.8717\n","Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 4s 37ms/step - loss: 0.1099 - accuracy: 0.8723 - val_loss: 0.3959 - val_accuracy: 0.6466 - lr: 5.0000e-04\n","Epoch 15/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0791 - accuracy: 0.9242 - val_loss: 0.4375 - val_accuracy: 0.6638 - lr: 2.5000e-04\n","Epoch 16/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0622 - accuracy: 0.9459 - val_loss: 0.4339 - val_accuracy: 0.6810 - lr: 2.5000e-04\n","Epoch 17/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0513 - accuracy: 0.9502 - val_loss: 0.4941 - val_accuracy: 0.7069 - lr: 2.5000e-04\n","Epoch 18/30\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0471 - accuracy: 0.9437 - val_loss: 0.4787 - val_accuracy: 0.6983 - lr: 2.5000e-04\n","Epoch 19/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0455 - accuracy: 0.9502 - val_loss: 0.4939 - val_accuracy: 0.6983 - lr: 2.5000e-04\n","Epoch 20/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0351 - accuracy: 0.9502 - val_loss: 0.4893 - val_accuracy: 0.6810 - lr: 2.5000e-04\n","Epoch 21/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0330 - accuracy: 0.9565\n","Epoch 21: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0329 - accuracy: 0.9567 - val_loss: 0.4930 - val_accuracy: 0.6810 - lr: 2.5000e-04\n","Epoch 22/30\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0331 - accuracy: 0.9567 - val_loss: 0.5020 - val_accuracy: 0.7069 - lr: 1.2500e-04\n","Epoch 23/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0262 - accuracy: 0.9567 - val_loss: 0.5179 - val_accuracy: 0.6983 - lr: 1.2500e-04\n","Epoch 24/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0248 - accuracy: 0.9565Restoring model weights from the end of the best epoch: 17.\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0247 - accuracy: 0.9567 - val_loss: 0.5413 - val_accuracy: 0.6983 - lr: 1.2500e-04\n","Epoch 24: early stopping\n","4/4 [==============================] - 1s 28ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 9s 46ms/step - loss: 0.2128 - accuracy: 0.8247 - val_loss: 0.0974 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 5s 43ms/step - loss: 0.1262 - accuracy: 0.8766 - val_loss: 0.1077 - val_accuracy: 0.9397 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.1322 - accuracy: 0.8788 - val_loss: 0.1602 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0895 - accuracy: 0.9177 - val_loss: 0.1239 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.0617 - accuracy: 0.9394 - val_loss: 0.1584 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 6/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0689 - accuracy: 0.9326\n","Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0687 - accuracy: 0.9329 - val_loss: 0.1051 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0372 - accuracy: 0.9610 - val_loss: 0.1141 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 8/30\n","116/116 [==============================] - 5s 43ms/step - loss: 0.0269 - accuracy: 0.9545 - val_loss: 0.1120 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 9/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0242 - accuracy: 0.9543Restoring model weights from the end of the best epoch: 2.\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0241 - accuracy: 0.9545 - val_loss: 0.1140 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 9: early stopping\n","4/4 [==============================] - 1s 15ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [1 1 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 11s 47ms/step - loss: 0.1369 - accuracy: 0.8831 - val_loss: 0.1206 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.0788 - accuracy: 0.9286 - val_loss: 0.1204 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0808 - accuracy: 0.9286 - val_loss: 0.1387 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 5s 40ms/step - loss: 0.0629 - accuracy: 0.9437 - val_loss: 0.1249 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0524 - accuracy: 0.9351 - val_loss: 0.1763 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0588 - accuracy: 0.9329 - val_loss: 0.2319 - val_accuracy: 0.7500 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 4s 39ms/step - loss: 0.0514 - accuracy: 0.9437 - val_loss: 0.1865 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0247 - accuracy: 0.9719\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 6s 51ms/step - loss: 0.0247 - accuracy: 0.9719 - val_loss: 0.2389 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 8s 65ms/step - loss: 0.0190 - accuracy: 0.9675 - val_loss: 0.1789 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0123 - accuracy: 0.9697 - val_loss: 0.1852 - val_accuracy: 0.8621 - lr: 5.0000e-04\n","Epoch 11/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0118 - accuracy: 0.9739Restoring model weights from the end of the best epoch: 4.\n","116/116 [==============================] - 5s 39ms/step - loss: 0.0117 - accuracy: 0.9740 - val_loss: 0.1698 - val_accuracy: 0.8879 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 1s 16ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 1 0 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 10s 47ms/step - loss: 0.0916 - accuracy: 0.9244 - val_loss: 0.0486 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 5s 46ms/step - loss: 0.0506 - accuracy: 0.9374 - val_loss: 0.0424 - val_accuracy: 0.9304 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0529 - accuracy: 0.9503 - val_loss: 0.0364 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0450 - accuracy: 0.9503 - val_loss: 0.0472 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 5/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0405 - accuracy: 0.9565\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0403 - accuracy: 0.9568 - val_loss: 0.1036 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0308 - accuracy: 0.9611 - val_loss: 0.0577 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 7/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0190 - accuracy: 0.9654 - val_loss: 0.0508 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0151 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0150 - accuracy: 0.9676 - val_loss: 0.0497 - val_accuracy: 0.9391 - lr: 5.0000e-04\n","Epoch 8: early stopping\n","4/4 [==============================] - 1s 26ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [1 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["116/116 [==============================] - 10s 51ms/step - loss: 0.0819 - accuracy: 0.9158 - val_loss: 0.0400 - val_accuracy: 0.9652 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0525 - accuracy: 0.9503 - val_loss: 0.0459 - val_accuracy: 0.9565 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0399 - accuracy: 0.9568 - val_loss: 0.0604 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 5s 41ms/step - loss: 0.0343 - accuracy: 0.9546 - val_loss: 0.1036 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0658 - accuracy: 0.9391\n","Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0654 - accuracy: 0.9395 - val_loss: 0.1003 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 4s 37ms/step - loss: 0.0343 - accuracy: 0.9525 - val_loss: 0.0733 - val_accuracy: 0.9217 - lr: 5.0000e-04\n","Epoch 7/30\n","116/116 [==============================] - 5s 42ms/step - loss: 0.0213 - accuracy: 0.9590 - val_loss: 0.0715 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 8/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.0180 - accuracy: 0.9674Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 4s 38ms/step - loss: 0.0179 - accuracy: 0.9676 - val_loss: 0.1009 - val_accuracy: 0.9478 - lr: 5.0000e-04\n","Epoch 8: early stopping\n","4/4 [==============================] - 1s 26ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [1 1 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 1 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 1 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8204947526236882\n","Accuracy:  0.9516821589205394\n","Average Normalized Accuracy:  0.8469965017491254\n","Average Precision:  0.9027617892050859\n","Average Recall:  0.8534389098892656\n","F1 score: 0.8774077332575747\n","Grand Mean: 0.8754636409408799\n"]}]},{"cell_type":"markdown","source":["## S5G Stan XGBoost Matrix Model"],"metadata":{"id":"9fsx2WuMMtzs"}},{"cell_type":"code","source":["import numpy as np\n","import xgboost as xgb\n","from sklearn.model_selection import KFold\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","\n","# Define the XGBoost classifier\n","model_xgb = xgb.XGBClassifier()\n","\n","# Load your data and pr0.0.eprocess it\n","train_features = np.array(df['s5g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Fit the XGBoost model to the training data\n","    model_xgb.fit(X_train, y_train)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_xgb.predict(X_test)\n","\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vqiACsNzMsIE","executionInfo":{"status":"ok","timestamp":1697891322344,"user_tz":-330,"elapsed":42590,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"1653b600-0af0-4fb1-d19d-7d01846b9c7c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 1 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 1 0]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 1 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 1 0 1 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","Average Accuracy:  0.5570014992503748\n","Accuracy:  0.8823298350824581\n","Average Normalized Accuracy:  0.578073463268366\n","Average Precision:  0.7995585855160792\n","Average Recall:  0.5784891953609408\n","F1 score: 0.6712916768165477\n","Grand Mean: 0.6777907092157943\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"markdown","source":["## S5G Stan KNN Matrix Model"],"metadata":{"id":"Z53f_Be-MiUH"}},{"cell_type":"code","source":["import numpy as np\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score\n","from sklearn.model_selection import KFold\n","\n","# Define the k-NN classifier\n","model_knn = KNeighborsClassifier(n_neighbors=5)  # You can adjust the number of neighbors (k) as needed\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s5g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Fit the k-NN model to the training data\n","    model_knn.fit(X_train, y_train)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_knn.predict(X_test)\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, y_pred)\n","    precision = precision_score(y_test, y_pred, average='weighted')\n","    recall = recall_score(y_test, y_pred, average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy+avg_precision+avg_recall+f1+avg_acc_norm++avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9GrHLf7YMnJJ","executionInfo":{"status":"ok","timestamp":1697891377532,"user_tz":-330,"elapsed":2136,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"bb0389c8-be41-4b29-b483-56e7f9203f56"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 1 0]\n","0.4\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 1]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 1]\n","0.4\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [0 0 0 1 0]\n","0.6\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 1 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","Average Accuracy:  0.5293103448275862\n","Accuracy:  0.8501469265367311\n","Average Normalized Accuracy:  0.5428735632183908\n","Average Precision:  0.7110118301629844\n","Average Recall:  0.5353844819402984\n","F1 score: 0.610824497230523\n","Grand Mean: 0.6299252739860856\n"]}]},{"cell_type":"markdown","source":["## S6G Stan Matrix Model"],"metadata":{"id":"i_eM-FWOiJVW"}},{"cell_type":"code","source":["# Define the model\n","model_s6g_stan = keras.Sequential([\n","    keras.layers.Input(shape=(None, 400)),\n","    keras.layers.Dense(400, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(100, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(25, activation='relu',kernel_initializer='he_normal'),\n","    keras.layers.Dense(5, activation='sigmoid')\n","])\n","\n","# Load your data and preprocess it\n","train_features = np.array(df['s6g_stan_matrix'].tolist())\n","train_labels = np.array(df[['envelope', 'lumen', 'plastoglobule', 'stroma', 'thylakoid_membrane']].values)\n","\n","train_features = train_features.reshape(-1, 400)\n","\n","# Initialize K-Fold cross-validator\n","kf = KFold(n_splits=5)\n","\n","# Initialize a list to store accuracy scores\n","accuracy_scores = []\n","precision_scores = []\n","recall_scores = []\n","acc_scores = []\n","acc_norm = []\n","\n","# Iterate over each sample for LOOCV\n","for train_index, test_index in kf.split(train_features):\n","    X_train, X_test = train_features[train_index], train_features[test_index]\n","    y_train, y_test = train_labels[train_index], train_labels[test_index]\n","\n","    # Compile the model and set up callbacks (as in your code)\n","    model_s6g_stan.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","    early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0.00005, patience=10, verbose=1, restore_best_weights=True)\n","    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=7, min_lr=1e-6, verbose=1)\n","    callbacks = [early_stopping, lr_scheduler]\n","\n","    batch_size = 4\n","    model_s6g_stan.fit(X_train, y_train, epochs=30, validation_data=(X_test, y_test), batch_size=batch_size, callbacks=callbacks)\n","\n","    # Make predictions on the current test sample\n","    y_pred = model_s6g_stan.predict(X_test)\n","\n","\n","    # Calculate and store the accuracy for this fold\n","    accuracy = accuracy_score(y_test, (y_pred > 0.5).astype(int))\n","    precision = precision_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    recall = recall_score(y_test, (y_pred > 0.5).astype(int), average='weighted')\n","    accuracy_scores.append(accuracy)\n","    precision_scores.append(precision)\n","    recall_scores.append(recall)\n","    acc_scores.append(norm_accuracy(y_test, y_pred))\n","    acc_norm.append(calculate_accuracy(y_test, y_pred))\n","\n","# Calculate the average accuracy across all folds\n","average_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n","avg_precision = sum(precision_scores) / len(precision_scores)\n","avg_acc_norm = sum(acc_norm)/len(acc_norm)\n","avg_recall = sum(recall_scores) / len(recall_scores)\n","avg_acc = sum(acc_scores)/len(acc_scores)\n","f1 = 2 * (avg_precision * avg_recall) / (avg_precision + avg_recall)\n","grand_mean=(average_accuracy + avg_precision + avg_recall + f1 + avg_acc_norm + avg_acc)/6\n","# Print the average accuracy\n","print(\"Average Accuracy: \", average_accuracy)\n","print(\"Accuracy: \", avg_acc)\n","print(\"Average Normalized Accuracy: \", avg_acc_norm)\n","print(\"Average Precision: \", avg_precision)\n","print(\"Average Recall: \", avg_recall)\n","print('F1 score:', f1)\n","print('Grand Mean:', grand_mean)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"thv6y-T0hNRv","executionInfo":{"status":"ok","timestamp":1697813336832,"user_tz":-330,"elapsed":65424,"user":{"displayName":"PEDDISETTY VENKATA SAI PRANAY IIIT Dharwad","userId":"08897901337530658803"}},"outputId":"80ee9fae-b074-465d-b3ba-a6fb104680c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 3s 11ms/step - loss: 0.4130 - accuracy: 0.4762 - val_loss: 0.3344 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.3450 - accuracy: 0.5909 - val_loss: 0.3067 - val_accuracy: 0.6552 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.2927 - accuracy: 0.6645 - val_loss: 0.3298 - val_accuracy: 0.6121 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 9ms/step - loss: 0.2698 - accuracy: 0.7078 - val_loss: 0.2835 - val_accuracy: 0.6983 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2317 - accuracy: 0.7749 - val_loss: 0.3321 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.2155 - accuracy: 0.7727 - val_loss: 0.3373 - val_accuracy: 0.6379 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1903 - accuracy: 0.8052 - val_loss: 0.4494 - val_accuracy: 0.5862 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1834 - accuracy: 0.8009 - val_loss: 0.3030 - val_accuracy: 0.7155 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1606 - accuracy: 0.8290 - val_loss: 0.3142 - val_accuracy: 0.6207 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1517 - accuracy: 0.8463 - val_loss: 0.3196 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1544 - accuracy: 0.8398 - val_loss: 0.3469 - val_accuracy: 0.6897 - lr: 0.0010\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1338 - accuracy: 0.8853 - val_loss: 0.5178 - val_accuracy: 0.5948 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.1331 - accuracy: 0.8810 - val_loss: 0.3686 - val_accuracy: 0.6810 - lr: 0.0010\n","Epoch 14/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.8961 - val_loss: 0.3500 - val_accuracy: 0.7069 - lr: 0.0010\n","Epoch 15/30\n","115/116 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.8848\n","Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1134 - accuracy: 0.8853 - val_loss: 0.3886 - val_accuracy: 0.6293 - lr: 0.0010\n","Epoch 16/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0738 - accuracy: 0.9264 - val_loss: 0.3656 - val_accuracy: 0.7328 - lr: 5.0000e-04\n","Epoch 17/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0636 - accuracy: 0.9416 - val_loss: 0.4422 - val_accuracy: 0.6293 - lr: 5.0000e-04\n","Epoch 18/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0590 - accuracy: 0.9416 - val_loss: 0.4251 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 19/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9567 - val_loss: 0.4330 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 20/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0432 - accuracy: 0.9394 - val_loss: 0.4404 - val_accuracy: 0.6724 - lr: 5.0000e-04\n","Epoch 21/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0478 - accuracy: 0.9459 - val_loss: 0.4289 - val_accuracy: 0.7241 - lr: 5.0000e-04\n","Epoch 22/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0436 - accuracy: 0.9502 - val_loss: 0.5789 - val_accuracy: 0.6638 - lr: 5.0000e-04\n","Epoch 23/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9437\n","Epoch 23: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0448 - accuracy: 0.9437 - val_loss: 0.4419 - val_accuracy: 0.7069 - lr: 5.0000e-04\n","Epoch 24/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0251 - accuracy: 0.9719 - val_loss: 0.4822 - val_accuracy: 0.6983 - lr: 2.5000e-04\n","Epoch 25/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9740 - val_loss: 0.5050 - val_accuracy: 0.7155 - lr: 2.5000e-04\n","Epoch 26/30\n","111/116 [===========================>..] - ETA: 0s - loss: 0.0205 - accuracy: 0.9730Restoring model weights from the end of the best epoch: 16.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0199 - accuracy: 0.9740 - val_loss: 0.5151 - val_accuracy: 0.7241 - lr: 2.5000e-04\n","Epoch 26: early stopping\n","4/4 [==============================] - 0s 5ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 1 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 1] [0 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 1 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 1]\n","0.4\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 1 0 0 0]\n","0.6\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [0 0 1 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1599 - accuracy: 0.8593 - val_loss: 0.1026 - val_accuracy: 0.9138 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1328 - accuracy: 0.8398 - val_loss: 0.1541 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.1300 - accuracy: 0.8680 - val_loss: 0.0885 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.1073 - accuracy: 0.9026 - val_loss: 0.0864 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0869 - accuracy: 0.9156 - val_loss: 0.1407 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0858 - accuracy: 0.9026 - val_loss: 0.1564 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0830 - accuracy: 0.8983 - val_loss: 0.1207 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0939 - accuracy: 0.8831 - val_loss: 0.1258 - val_accuracy: 0.8276 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0733 - accuracy: 0.9329 - val_loss: 0.1001 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 10/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.9181\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0684 - accuracy: 0.9177 - val_loss: 0.1235 - val_accuracy: 0.8879 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0448 - accuracy: 0.9437 - val_loss: 0.1040 - val_accuracy: 0.9052 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0393 - accuracy: 0.9524 - val_loss: 0.1112 - val_accuracy: 0.9138 - lr: 5.0000e-04\n","Epoch 13/30\n","114/116 [============================>.] - ETA: 0s - loss: 0.0349 - accuracy: 0.9496Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0347 - accuracy: 0.9502 - val_loss: 0.0983 - val_accuracy: 0.8966 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 3ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 1 0]\n","0.8\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 1] [0 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 10ms/step - loss: 0.1272 - accuracy: 0.8723 - val_loss: 0.1009 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0966 - accuracy: 0.9199 - val_loss: 0.1453 - val_accuracy: 0.8448 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0949 - accuracy: 0.9004 - val_loss: 0.1310 - val_accuracy: 0.8621 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0970 - accuracy: 0.8961 - val_loss: 0.1047 - val_accuracy: 0.8793 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0835 - accuracy: 0.9199 - val_loss: 0.0888 - val_accuracy: 0.9224 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0809 - accuracy: 0.9069 - val_loss: 0.1770 - val_accuracy: 0.8103 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0857 - accuracy: 0.9177 - val_loss: 0.1740 - val_accuracy: 0.8534 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0824 - accuracy: 0.9113 - val_loss: 0.1409 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0784 - accuracy: 0.9242 - val_loss: 0.1633 - val_accuracy: 0.8017 - lr: 0.0010\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0502 - accuracy: 0.9481 - val_loss: 0.1339 - val_accuracy: 0.9052 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0783 - accuracy: 0.9307 - val_loss: 0.1129 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 12/30\n","105/116 [==========================>...] - ETA: 0s - loss: 0.0668 - accuracy: 0.9310\n","Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0656 - accuracy: 0.9307 - val_loss: 0.1727 - val_accuracy: 0.8190 - lr: 0.0010\n","Epoch 13/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0438 - accuracy: 0.9545 - val_loss: 0.1284 - val_accuracy: 0.8707 - lr: 5.0000e-04\n","Epoch 14/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0258 - accuracy: 0.9610 - val_loss: 0.1306 - val_accuracy: 0.8793 - lr: 5.0000e-04\n","Epoch 15/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0237 - accuracy: 0.9773Restoring model weights from the end of the best epoch: 5.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0236 - accuracy: 0.9762 - val_loss: 0.1869 - val_accuracy: 0.8362 - lr: 5.0000e-04\n","Epoch 15: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 1 0] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 1] [0 0 0 1 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 1 0 0] [0 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [0 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.1139 - accuracy: 0.9006 - val_loss: 0.0667 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0916 - accuracy: 0.9071 - val_loss: 0.0487 - val_accuracy: 0.9217 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0996 - accuracy: 0.9050 - val_loss: 0.0495 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0637 - accuracy: 0.9287 - val_loss: 0.0737 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0633 - accuracy: 0.9374 - val_loss: 0.1290 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0749 - accuracy: 0.9266 - val_loss: 0.1564 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0845 - accuracy: 0.9201 - val_loss: 0.1329 - val_accuracy: 0.8870 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - 1s 7ms/step - loss: 0.0542 - accuracy: 0.9438 - val_loss: 0.2031 - val_accuracy: 0.8000 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0540 - accuracy: 0.9417 - val_loss: 0.1976 - val_accuracy: 0.8609 - lr: 0.0010\n","Epoch 10/30\n","113/116 [============================>.] - ETA: 0s - loss: 0.0964 - accuracy: 0.8960\n","Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0955 - accuracy: 0.8963 - val_loss: 0.1460 - val_accuracy: 0.8957 - lr: 0.0010\n","Epoch 11/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0477 - accuracy: 0.9482 - val_loss: 0.0703 - val_accuracy: 0.9304 - lr: 5.0000e-04\n","Epoch 12/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0314 - accuracy: 0.9611 - val_loss: 0.1203 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 13/30\n","112/116 [===========================>..] - ETA: 0s - loss: 0.0265 - accuracy: 0.9732Restoring model weights from the end of the best epoch: 3.\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0258 - accuracy: 0.9741 - val_loss: 0.1307 - val_accuracy: 0.8957 - lr: 5.0000e-04\n","Epoch 13: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 0]\n","0.6\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","116/116 [==============================] - 2s 6ms/step - loss: 0.0885 - accuracy: 0.9028 - val_loss: 0.0574 - val_accuracy: 0.9391 - lr: 0.0010\n","Epoch 2/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0701 - accuracy: 0.9266 - val_loss: 0.1311 - val_accuracy: 0.8522 - lr: 0.0010\n","Epoch 3/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0956 - accuracy: 0.8920 - val_loss: 0.1520 - val_accuracy: 0.8261 - lr: 0.0010\n","Epoch 4/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0765 - accuracy: 0.9136 - val_loss: 0.0999 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 5/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0681 - accuracy: 0.9244 - val_loss: 0.0900 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 6/30\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0540 - accuracy: 0.9568 - val_loss: 0.0846 - val_accuracy: 0.9130 - lr: 0.0010\n","Epoch 7/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0508 - accuracy: 0.9374 - val_loss: 0.0947 - val_accuracy: 0.9043 - lr: 0.0010\n","Epoch 8/30\n","116/116 [==============================] - ETA: 0s - loss: 0.0511 - accuracy: 0.9482\n","Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n","116/116 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9482 - val_loss: 0.1537 - val_accuracy: 0.8696 - lr: 0.0010\n","Epoch 9/30\n","116/116 [==============================] - 0s 4ms/step - loss: 0.0351 - accuracy: 0.9482 - val_loss: 0.1190 - val_accuracy: 0.8870 - lr: 5.0000e-04\n","Epoch 10/30\n","116/116 [==============================] - 1s 5ms/step - loss: 0.0302 - accuracy: 0.9525 - val_loss: 0.1020 - val_accuracy: 0.9130 - lr: 5.0000e-04\n","Epoch 11/30\n","110/116 [===========================>..] - ETA: 0s - loss: 0.0218 - accuracy: 0.9591Restoring model weights from the end of the best epoch: 1.\n","116/116 [==============================] - 1s 8ms/step - loss: 0.0212 - accuracy: 0.9611 - val_loss: 0.0916 - val_accuracy: 0.9043 - lr: 5.0000e-04\n","Epoch 11: early stopping\n","4/4 [==============================] - 0s 4ms/step\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [1 0 0 0 1]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 1 0] [1 0 0 1 0]\n","0.8\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 1] [1 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [0 0 0 1 0]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 1 0] [1 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 1 1] [1 0 0 1 0]\n","0.8\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 0 1]\n","0.6\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 1 0 0 0] [0 1 0 0 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 1 0 0] [0 0 0 0 0]\n","0.8\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 1 0 0] [1 0 0 0 0]\n","0.6\n","[1 0 0 0 0] [1 0 0 0 0]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 0 0 1] [0 0 0 0 1]\n","1.0\n","[0 0 0 1 0] [0 0 0 1 0]\n","1.0\n","[0 0 1 0 0] [0 0 1 0 0]\n","1.0\n","Average Accuracy:  0.8566716641679161\n","Accuracy:  0.9575202398800597\n","Average Normalized Accuracy:  0.8759720139930035\n","Average Precision:  0.9227582180657852\n","Average Recall:  0.8750316685241529\n","F1 score: 0.8982614366910714\n","Grand Mean: 0.8977025402203314\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"Cc6JkuzbiWCp"},"execution_count":null,"outputs":[]}]}